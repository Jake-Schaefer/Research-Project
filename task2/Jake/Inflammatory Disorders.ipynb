{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Gold standard curation: Preprocessing and single-step regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this stage of gold standard curation, we will do the data preprocessing, selection, and single-step regression for the 153 traits in our question set. This file shows the reference steps using the trait \"Breast Cancer\" as an example. The workflow consists of the following steps:\n",
    "\n",
    "1. Preprocess all the cohorts related to this trait. Each cohort should be converted to a tabular form and saved to a csv file, with columns being genetic factors, the trait, and age, gender if available;\n",
    "2. If there exists at least one cohort with age or gender information, conduct regression analysis with genetic features together with age or gender as the regressors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:25.927828954Z",
     "start_time": "2024-01-10T21:37:25.311064788Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils import *\n",
    "\n",
    "# Set your preferred name\n",
    "USER = \"Jake\"\n",
    "# Set the data and output directories\n",
    "DATA_ROOT = '/Users/jacob/Documents'\n",
    "OUTPUT_ROOT = '/Users/jacob/Documents/output'\n",
    "TRAIT = 'Inflammatory Disorders'\n",
    "\n",
    "OUTPUT_DIR = os.path.join(OUTPUT_ROOT, USER, '-'.join(TRAIT.split()))\n",
    "JSON_PATH = os.path.join(OUTPUT_DIR, \"cohort_info.json\")\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Gene symbol normalization may take 1-2 minutes. You may set it to False for debugging.\n",
    "NORMALIZE_GENE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils.py has been loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import mygene\n",
    "import re\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Callable, Optional, List, Tuple, Union, Any\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LogisticRegression\n",
    "from sparse_lmm import VariableSelection\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "print(\"utils.py has been loaded\")\n",
    "def geo_get_relevant_filepaths(cohort_dir):\n",
    "    \"\"\"Find the file paths of a SOFT file and a matrix file from the given data directory of a cohort.\n",
    "    If there are multiple SOFT files or matrix files, simply choose the first one. Used for the GEO dataset.\n",
    "    \"\"\"\n",
    "    files = os.listdir(cohort_dir)\n",
    "    soft_files = [f for f in files if 'soft' in f.lower()]\n",
    "    matrix_files = [f for f in files if 'matrix' in f.lower()]\n",
    "    assert len(soft_files) > 0 and len(matrix_files) > 0\n",
    "    soft_file_path = os.path.join(cohort_dir, soft_files[0])\n",
    "    matrix_file_path = os.path.join(cohort_dir, matrix_files[0])\n",
    "\n",
    "    return soft_file_path, matrix_file_path\n",
    "\n",
    "\n",
    "def xena_get_relevant_filepaths(cohort_dir):\n",
    "    \"\"\"Find the file paths of a clinical file and a genetic file from the given data directory of a cohort.\n",
    "    If there are multiple clinical or genetic data files, simply choose the first one. Used for the TCGA Xena dataset.\n",
    "    \"\"\"\n",
    "    files = os.listdir(cohort_dir)\n",
    "    clinical_files = [f for f in files if 'clinicalmatrix' in f.lower()]\n",
    "    genetic_files = [f for f in files if 'pancan' in f.lower()]\n",
    "    clinical_file_path = os.path.join(cohort_dir, clinical_files[0])\n",
    "    genetic_file_path = os.path.join(cohort_dir, genetic_files[0])\n",
    "    return clinical_file_path, genetic_file_path\n",
    "\n",
    "def line_generator(source, source_type):\n",
    "    \"\"\"Generator that yields lines from a file or a string.\n",
    "\n",
    "    Parameters:\n",
    "    - source: File path or string content.\n",
    "    - source_type: 'file' or 'string'.\n",
    "    \"\"\"\n",
    "    if source_type == 'file':\n",
    "        with gzip.open(source, 'rt') as f:\n",
    "            for line in f:\n",
    "                yield line.strip()\n",
    "    elif source_type == 'string':\n",
    "        for line in source.split('\\n'):\n",
    "            yield line.strip()\n",
    "    else:\n",
    "        raise ValueError(\"source_type must be 'file' or 'string'\")\n",
    "\n",
    "\n",
    "def filter_content_by_prefix(\n",
    "    source: str,\n",
    "    prefixes_a: List[str],\n",
    "    prefixes_b: Optional[List[str]] = None,\n",
    "    unselect: bool = False,\n",
    "    source_type: str = 'file',\n",
    "    return_df_a: bool = True,\n",
    "    return_df_b: bool = True\n",
    ") -> Tuple[Union[str, pd.DataFrame], Optional[Union[str, pd.DataFrame]]]:\n",
    "    \"\"\"\n",
    "    Filters rows from a file or a list of strings based on specified prefixes.\n",
    "\n",
    "    Parameters:\n",
    "    - source (str): File path or string content to filter.\n",
    "    - prefixes_a (List[str]): Primary list of prefixes to filter by.\n",
    "    - prefixes_b (Optional[List[str]]): Optional secondary list of prefixes to filter by.\n",
    "    - unselect (bool): If True, selects rows that do not start with the specified prefixes.\n",
    "    - source_type (str): 'file' if source is a file path, 'string' if source is a string of text.\n",
    "    - return_df_a (bool): If True, returns filtered content for prefixes_a as a pandas DataFrame.\n",
    "    - return_df_b (bool): If True, and if prefixes_b is provided, returns filtered content for prefixes_b as a pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple: A tuple where the first element is the filtered content for prefixes_a, and the second element is the filtered content for prefixes_b.\n",
    "    \"\"\"\n",
    "    filtered_lines_a = []\n",
    "    filtered_lines_b = []\n",
    "    prefix_set_a = set(prefixes_a)\n",
    "    if prefixes_b is not None:\n",
    "        prefix_set_b = set(prefixes_b)\n",
    "\n",
    "    # Use generator to get lines\n",
    "    for line in line_generator(source, source_type):\n",
    "        matched_a = any(line.startswith(prefix) for prefix in prefix_set_a)\n",
    "        if matched_a != unselect:\n",
    "            filtered_lines_a.append(line)\n",
    "        if prefixes_b is not None:\n",
    "            matched_b = any(line.startswith(prefix) for prefix in prefix_set_b)\n",
    "            if matched_b != unselect:\n",
    "                filtered_lines_b.append(line)\n",
    "\n",
    "    filtered_content_a = '\\n'.join(filtered_lines_a)\n",
    "    if return_df_a:\n",
    "        filtered_content_a = pd.read_csv(io.StringIO(filtered_content_a), delimiter='\\t', low_memory=False, on_bad_lines='skip')\n",
    "    filtered_content_b = None\n",
    "    if filtered_lines_b:\n",
    "        filtered_content_b = '\\n'.join(filtered_lines_b)\n",
    "        if return_df_b:\n",
    "            filtered_content_b = pd.read_csv(io.StringIO(filtered_content_b), delimiter='\\t', low_memory=False, on_bad_lines='skip')\n",
    "\n",
    "    return filtered_content_a, filtered_content_b\n",
    "\n",
    "\n",
    "def get_background_and_clinical_data(file_path,\n",
    "                                     prefixes_a=['!Series_title', '!Series_summary', '!Series_overall_design'],\n",
    "                                     prefixes_b=['!Sample_geo_accession', '!Sample_characteristics_ch1']):\n",
    "    \"\"\"Extract from a matrix file the background information about the dataset, and sample characteristics data\"\"\"\n",
    "    background_info, clinical_data = filter_content_by_prefix(file_path, prefixes_a, prefixes_b, unselect=False,\n",
    "                                                              source_type='file',\n",
    "                                                              return_df_a=False, return_df_b=True)\n",
    "    return background_info, clinical_data\n",
    "\n",
    "\n",
    "def get_gene_annotation(file_path, prefixes=['^', '!', '#']):\n",
    "    \"\"\"Extract from a SOFT file the gene annotation data\"\"\"\n",
    "    gene_metadata = filter_content_by_prefix(file_path, prefixes_a=prefixes, unselect=True, source_type='file',\n",
    "                                             return_df_a=True)\n",
    "    return gene_metadata[0]\n",
    "\n",
    "\n",
    "def get_gene_mapping(annotation, prob_col, gene_col):\n",
    "    \"\"\"Process the gene annotation to get the mapping between gene names and gene probes.\n",
    "    \"\"\"\n",
    "    mapping_data = annotation.loc[:, [prob_col, gene_col]]\n",
    "    mapping_data = mapping_data.dropna()\n",
    "    mapping_data = mapping_data.rename(columns={gene_col: 'Gene'}).astype({'ID': 'str'})\n",
    "\n",
    "    return mapping_data\n",
    "\n",
    "\n",
    "def get_genetic_data(file_path):\n",
    "    \"\"\"Read the gene expression data into a dataframe, and adjust its format\"\"\"\n",
    "    genetic_data = pd.read_csv(file_path, compression='gzip', skiprows=52, comment='!', delimiter='\\t')\n",
    "    genetic_data = genetic_data.dropna()\n",
    "    genetic_data = genetic_data.rename(columns={'ID_REF': 'ID'}).astype({'ID': 'str'})\n",
    "    genetic_data.set_index('ID', inplace=True)\n",
    "\n",
    "    return genetic_data\n",
    "\n",
    "\n",
    "def apply_gene_mapping(expression_df, mapping_df):\n",
    "    \"\"\"\n",
    "    Converts measured data about gene probes into gene expression data.\n",
    "    Handles the potential many-to-many relationship between probes and genes.\n",
    "\n",
    "    Parameters:\n",
    "    expression_df (DataFrame): A DataFrame with gene expression data, indexed by 'ID'.\n",
    "    mapping_df (DataFrame): A DataFrame mapping 'ID' to 'Gene', with 'ID' as a column.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame with mean gene expression values, indexed by 'Gene'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a regex pattern for splitting gene names\n",
    "    split_pattern = r';|\\|+|/{2,}|,|\\[|\\]|\\(|\\)'\n",
    "\n",
    "    # Split the 'Gene' column in 'mapping_df' using the regex pattern\n",
    "    mapping_df['Gene'] = mapping_df['Gene'].str.split(split_pattern)\n",
    "    mapping_df = mapping_df.explode('Gene')\n",
    "\n",
    "    # Set 'ID' as the index of 'mapping_df' for merging\n",
    "    mapping_df.set_index('ID', inplace=True)\n",
    "\n",
    "    # Merge 'mapping_df' with 'expression_df' by their indices\n",
    "    merged_df = mapping_df.join(expression_df)\n",
    "\n",
    "    # Group by 'Gene' and calculate the mean expression values\n",
    "    gene_expression_df = merged_df.groupby('Gene').mean().dropna()\n",
    "\n",
    "    return gene_expression_df\n",
    "\n",
    "\n",
    "def normalize_gene_symbols(gene_symbols, batch_size=1000):\n",
    "    \"\"\"Normalize human gene symbols in batches using the 'mygenes' library\"\"\"\n",
    "    mg = mygene.MyGeneInfo()\n",
    "    normalized_genes = {}\n",
    "\n",
    "    # Process in batches\n",
    "    for i in range(0, len(gene_symbols), batch_size):\n",
    "        batch = gene_symbols[i:i + batch_size]\n",
    "        results = mg.querymany(batch, scopes='symbol', fields='symbol', species='human', verbose=False)\n",
    "\n",
    "        # Update the normalized_genes dictionary with results from this batch\n",
    "        for gene in results:\n",
    "            normalized_genes[gene['query']] = gene.get('symbol', None)\n",
    "\n",
    "    # Return the normalized symbols in the same order as the input\n",
    "    return [normalized_genes.get(symbol) for symbol in gene_symbols]\n",
    "\n",
    "\n",
    "def normalize_gene_symbols_in_index(gene_df):\n",
    "    \"\"\"Normalize the human gene symbols at the index of a dataframe, and replace the index with its normalized version.\n",
    "    Remove the rows where the index failed to be normalized.\"\"\"\n",
    "    normalized_gene_list = normalize_gene_symbols(gene_df.index.tolist())\n",
    "    assert len(normalized_gene_list) == len(gene_df.index)\n",
    "    gene_df.index = normalized_gene_list\n",
    "    gene_df = gene_df[gene_df.index.notnull()]\n",
    "    return gene_df\n",
    "\n",
    "\n",
    "def get_feature_data(clinical_df, row_id, feature, convert_fn):\n",
    "    \"\"\"select the row corresponding to a feature in the sample characteristics dataframe, and convert the feature into\n",
    "    a binary or continuous variable\"\"\"\n",
    "    clinical_df = clinical_df.iloc[row_id:row_id + 1].drop(columns=['!Sample_geo_accession'], errors='ignore')\n",
    "    clinical_df.index = [feature]\n",
    "    clinical_df = clinical_df.applymap(convert_fn)\n",
    "\n",
    "    return clinical_df\n",
    "\n",
    "\n",
    "def plot_numeric_distribution(df, column):\n",
    "    \"\"\"Plot the distribution of a numeric variable stored in the given column of a dataframe\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[column], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {column.capitalize()}')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_categorical_distribution(df, column):\n",
    "    \"\"\"Plot the distribution of a categorical variable stored in the given column of a dataframe\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(y=column, data=df, order=df[column].value_counts().index)\n",
    "    plt.title(f'Distribution of {column.capitalize()}')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def analyze_distributions(df, numerical_columns, categorical_columns):\n",
    "    \"\"\"Plot the distribution of the numerical and categorical variables stored in given columns of a dataframe\"\"\"\n",
    "    for col in numerical_columns:\n",
    "        plot_numeric_distribution(df, col)\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        plot_categorical_distribution(df, col)\n",
    "\n",
    "\n",
    "def normalize_data(X_train, X_test=None):\n",
    "    \"\"\"Compute the mean and standard deviation statistics of the training data, use them to normalize the training data,\n",
    "    and optionally the test data\"\"\"\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    std = np.std(X_train, axis=0)\n",
    "\n",
    "    # Handling columns with std = 0\n",
    "    std_no_zero = np.where(std == 0, 1, std)\n",
    "\n",
    "    # Normalize X_train\n",
    "    X_train_normalized = (X_train - mean) / std_no_zero\n",
    "    # Set normalized values to 0 where std was 0\n",
    "    X_train_normalized[:, std == 0] = 0\n",
    "\n",
    "    if X_test is not None:\n",
    "        X_test_normalized = (X_test - mean) / std_no_zero\n",
    "        X_test_normalized[:, std == 0] = 0\n",
    "    else:\n",
    "        X_test_normalized = None\n",
    "\n",
    "    return X_train_normalized, X_test_normalized\n",
    "\n",
    "\n",
    "class ResidualizationRegressor:\n",
    "    def __init__(self, regression_model_constructor, params=None):\n",
    "        if params is None:\n",
    "            params = {}\n",
    "        self.regression_model = regression_model_constructor(**params)\n",
    "        self.beta_Z = None  # Coefficients for regression of Y on Z\n",
    "        self.beta_X = None  # Coefficients for regression of residual on X\n",
    "        self.neg_log_p_values = None  # Negative logarithm of p-values\n",
    "        self.p_values = None  # Actual p-values\n",
    "\n",
    "    def _reshape_data(self, data):\n",
    "        \"\"\"\n",
    "        Reshape the data to ensure it's in the correct format (2D array).\n",
    "\n",
    "        :param data: The input data (can be 1D or 2D array).\n",
    "        :return: Reshaped 2D array.\n",
    "        \"\"\"\n",
    "        if data.ndim == 1:\n",
    "            return data.reshape(-1, 1)\n",
    "        return data\n",
    "\n",
    "    def _reshape_output(self, data):\n",
    "        \"\"\"\n",
    "        Reshape the output data to ensure it's in the correct format (1D array).\n",
    "\n",
    "        :param data: The output data (can be 1D or 2D array).\n",
    "        :return: Reshaped 1D array.\n",
    "        \"\"\"\n",
    "        if data.ndim == 2 and data.shape[1] == 1:\n",
    "            return data.ravel()\n",
    "        return data\n",
    "\n",
    "    def fit(self, X, Y, Z):\n",
    "        X = self._reshape_data(X)\n",
    "        Y = self._reshape_data(Y)\n",
    "        Z = self._reshape_data(Z)\n",
    "\n",
    "        # Step 1: Linear regression of Y on Z\n",
    "        Z_ones = np.column_stack((np.ones(Z.shape[0]), Z))\n",
    "        self.beta_Z = np.linalg.pinv(Z_ones.T @ Z_ones) @ Z_ones.T @ Y\n",
    "        Y_hat = Z_ones @ self.beta_Z\n",
    "        e_Y = Y - Y_hat  # Residual of Y\n",
    "\n",
    "        # Step 2: Regress the residual on X using the included regression model\n",
    "        self.regression_model.fit(X, e_Y)\n",
    "\n",
    "        # Obtain coefficients from the regression model\n",
    "        if hasattr(self.regression_model, 'coef_'):\n",
    "            self.beta_X = self.regression_model.coef_\n",
    "        elif hasattr(self.regression_model, 'getBeta'):\n",
    "            beta_output = self.regression_model.getBeta()\n",
    "            self.beta_X = self._reshape_output(beta_output)\n",
    "\n",
    "        # Obtain negative logarithm of p-values, if available\n",
    "        if hasattr(self.regression_model, 'getNegLogP'):\n",
    "            neg_log_p_output = self.regression_model.getNegLogP()\n",
    "            if neg_log_p_output is not None:\n",
    "                self.neg_log_p_values = self._reshape_output(neg_log_p_output)\n",
    "                self.p_values = np.exp(-self.neg_log_p_values)\n",
    "                # Concatenate the p-values of Z and X. The p-values of Z were not computed, mark with NaN.\n",
    "                p_values_Z = np.full(Z.shape[1], np.nan)\n",
    "                self.p_values = np.concatenate((p_values_Z, self.p_values))\n",
    "\n",
    "    def predict(self, X, Z):\n",
    "        X = self._reshape_data(X)\n",
    "        Z = self._reshape_data(Z)\n",
    "\n",
    "        Z_ones = np.column_stack((np.ones(Z.shape[0]), Z))\n",
    "        ZX = np.column_stack((Z, X))\n",
    "        combined_beta = np.concatenate((self.beta_Z[1:].ravel(), self.beta_X.ravel()))\n",
    "        return ZX @ combined_beta + self.beta_Z[0]\n",
    "\n",
    "    def get_coefficients(self):\n",
    "        return np.concatenate((self.beta_Z[1:].ravel(), self.beta_X.ravel()))\n",
    "\n",
    "    def get_p_values(self):\n",
    "        return self.p_values\n",
    "\n",
    "\n",
    "def cross_validation(X, Y, Z, model_constructor, model_params, k=5, target_type='binary'):\n",
    "    assert target_type in ['binary', 'continuous'], \"The target type must be chosen from 'binary' or 'continuous'\"\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    fold_size = len(X) // k\n",
    "    performances = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Split data into train and test based on the current fold\n",
    "        test_indices = indices[i * fold_size: (i + 1) * fold_size]\n",
    "        train_indices = np.setdiff1d(indices, test_indices)\n",
    "\n",
    "        X_train, X_test = X[train_indices], X[test_indices]\n",
    "        Y_train, Y_test = Y[train_indices], Y[test_indices]\n",
    "        Z_train, Z_test = Z[train_indices], Z[test_indices]\n",
    "\n",
    "        normalized_X_train, normalized_X_test = normalize_data(X_train, X_test)\n",
    "        normalized_Z_train, normalized_Z_test = normalize_data(Z_train, Z_test)\n",
    "\n",
    "        # model = model_constructor(**model_params)\n",
    "        model = ResidualizationRegressor(model_constructor, model_params)\n",
    "        model.fit(normalized_X_train, Y_train, normalized_Z_train)\n",
    "        predictions = model.predict(normalized_X_test, normalized_Z_test)\n",
    "\n",
    "        if target_type == 'binary':\n",
    "            predictions = (predictions > 0.5).astype(int)\n",
    "            Y_test = (Y_test > 0.5).astype(int)\n",
    "            performance = accuracy_score(Y_test, predictions)\n",
    "        elif target_type == 'continuous':\n",
    "            performance = mean_squared_error(Y_test, predictions)\n",
    "\n",
    "        performances.append(performance)\n",
    "\n",
    "    cv_mean = np.mean(performances)\n",
    "    cv_std = np.std(performances)\n",
    "\n",
    "    if target_type == 'binary':\n",
    "        print(f'The cross-validation accuracy is {(cv_mean * 100):.2f}% ± {(cv_std * 100):.2f}%')\n",
    "    else:\n",
    "        print(f'The cross-validation MSE is {(cv_mean * 100):.2f} ± {(cv_std * 100):.2f}')\n",
    "\n",
    "    return cv_mean, cv_std\n",
    "\n",
    "\n",
    "def get_feature_related_genes(file_path, feature, normalize):\n",
    "    \"\"\"Read a csv file into a dataframe about gene-trait association, and get the gene symbols related to a given\n",
    "    trait\"\"\"\n",
    "    related_gene_df = pd.read_csv(file_path)\n",
    "    related_gene_df = related_gene_df.loc[:, ['Disease Name', 'Corresponding_Gene_Symbol']].set_index('Disease Name')\n",
    "    feature_related_genes = related_gene_df.loc[feature].tolist()[0].strip().split(',')\n",
    "    feature_related_genes = [gn.strip() for gn in feature_related_genes]\n",
    "    if normalize:\n",
    "        feature_related_genes = normalize_gene_symbols(feature_related_genes)\n",
    "\n",
    "    return feature_related_genes\n",
    "\n",
    "\n",
    "def get_gene_regressors(trait, trait_df, condition_df, related_genes):\n",
    "    \"\"\"Find the appropriate genes for two-step regression. Compare the indices of two dataframes to find the genes\n",
    "    in common, and select those that are known to be related to a trait\"\"\"\n",
    "    gene_regressors = None\n",
    "    genes_in_trait_data = set(trait_df.columns) - {'Age', 'Gender', trait}\n",
    "    genes_in_condition_data = set(condition_df.columns) - {'Age', 'Gender', trait}\n",
    "\n",
    "    common_genes_across_data = genes_in_trait_data.intersection(genes_in_condition_data)\n",
    "    if len(common_genes_across_data) == 0:\n",
    "        #print(\"The trait and condition datasets have no genes in common. Please try other datasets\")\n",
    "        return None\n",
    "    else:\n",
    "        ##print(\n",
    "            ## f\"The trait and condition datasets have {len(common_genes_across_data)} genes in common, such as {list(common_genes_across_data)[:10]}.\")\n",
    "        common_genes = [g for g in related_genes if g in common_genes_across_data]\n",
    "        if len(common_genes) > 0:\n",
    "            gene_regressors = list(common_genes)[:10]\n",
    "            #print(\n",
    "                #f\"Found {len(common_genes)} candidate genes that can be used in two-step regression analysis, such as {gene_regressors[:10]}.\")\n",
    "        else:\n",
    "            #print(\n",
    "                #f\"The condition and trait datasets have common genes, but among them we didn't find indicator genes for the condition\")\n",
    "            return None\n",
    "\n",
    "    return gene_regressors\n",
    "\n",
    "\n",
    "def normalize_trait(trait):\n",
    "    trait = '-'.join(trait.split())\n",
    "    normalized_trait = ''.join(trait.split(\"'\"))\n",
    "    return normalized_trait\n",
    "\n",
    "def interpret_result(model: Any, feature_names: List[str], trait: str, condition: str,\n",
    "                     threshold: float = 0.05, save_output: bool = True,\n",
    "                     output_dir: str = './output', model_id: int = 1) -> None:\n",
    "    \"\"\"This function interprets and reports the result of a trained linear regression model, where the regressor\n",
    "    consists of one variable about condition and multiple variables about genetic factors.\n",
    "    The function extracts coefficients and p-values from the model, and identifies the significant genes based on\n",
    "    p-values or non-zero coefficients, depending on the availability of p-values.\n",
    "\n",
    "    Parameters:\n",
    "    model (Any): The trained regression Model.\n",
    "    feature_names (List[str]): A list of feature names corresponding to the model's coefficients.\n",
    "    trait (str): The target trait of interest.\n",
    "    condition (str): The specific condition to examine within the model.\n",
    "    threshold (float): Significance level for p-value correction. Defaults to 0.05.\n",
    "    save_output (bool): Flag to determine whether to save the output to a file. Defaults to True.\n",
    "    output_dir (str): Directory path where output files are saved. Defaults to './output'.\n",
    "    model_id (int): The index of the model, 1 or 2.\n",
    "\n",
    "    Returns:\n",
    "    None: This function does not return anything but prints and optionally saves the output.\n",
    "    \"\"\"\n",
    "    coefficients = model.get_coefficients().reshape(-1).tolist()\n",
    "    p_values = model.get_p_values()\n",
    "    if p_values is None:\n",
    "        regression_df = pd.DataFrame({\n",
    "            'Variable': feature_names,\n",
    "            'Coefficient': coefficients\n",
    "        })\n",
    "    else:\n",
    "        regression_df = pd.DataFrame({\n",
    "            'Variable': feature_names,\n",
    "            'Coefficient': coefficients,\n",
    "            'p_value': p_values.reshape(-1).tolist()\n",
    "        })\n",
    "\n",
    "    condition_effect = regression_df[regression_df['Variable'] == condition].iloc[0]\n",
    "\n",
    "    print(f\"Effect of the condition on the target variable:\")\n",
    "    print(f\"Variable: {condition}\")\n",
    "    print(f\"Coefficient: {condition_effect['Coefficient']:.4f}\")\n",
    "    gene_regression_df = regression_df[regression_df['Variable'] != condition]\n",
    "    if p_values is None:\n",
    "        gene_regression_df['Absolute Coefficient'] = gene_regression_df['Coefficient'].abs()\n",
    "        significant_genes = gene_regression_df[gene_regression_df['Coefficient'] != 0]\n",
    "        significant_genes_sorted = significant_genes.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "        print(\n",
    "            f\"Found {len(significant_genes_sorted)} genes with non-zero coefficients associated with the trait '{trait}' \"\n",
    "            f\"conditional on the factor '{condition}'. These genes are identified as significant based on the regression model.\")\n",
    "    else:\n",
    "        # Apply the Benjamini-Hochberg correction, to get the corrected p-values\n",
    "        corrected_p_values = multipletests(gene_regression_df['p_value'], alpha=threshold, method='fdr_bh')[1]\n",
    "        gene_regression_df.loc[:, 'corrected_p_value'] = corrected_p_values\n",
    "        significant_genes = gene_regression_df.loc[gene_regression_df['corrected_p_value'] < threshold]\n",
    "        significant_genes_sorted = significant_genes.sort_values('corrected_p_value')\n",
    "        print(\n",
    "            f\"Found {len(significant_genes_sorted)} significant genes associated with the trait '{trait}' conditional on \"\n",
    "            f\"the factor '{condition}', with corrected p-value < {threshold}:\")\n",
    "\n",
    "    print(significant_genes_sorted.to_string(index=False))\n",
    "\n",
    "    nm_condition = normalize_trait(condition)\n",
    "    # Optionally, save this to a CSV file\n",
    "    if save_output:\n",
    "        significant_genes_sorted.to_csv(\n",
    "            os.path.join(output_dir, f'significant_genes_condition_{nm_condition}_{model_id}.csv'), index=False)\n",
    "\n",
    "\n",
    "def judge_binary_variable_biased(dataframe, col_name, min_proportion=0.1, min_num=5):\n",
    "    \"\"\"\n",
    "    Check if the distribution of a binary variable in the dataset is too biased to be usable for analysis\n",
    "    :param dataframe:\n",
    "    :param col_name:\n",
    "    :param min_proportion:\n",
    "    :param min_num:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    label_counter = dataframe[col_name].value_counts()\n",
    "    total_samples = len(dataframe)\n",
    "    rare_label_num = label_counter.min()\n",
    "    rare_label = label_counter.idxmin()\n",
    "    rare_label_proportion = rare_label_num / total_samples\n",
    "\n",
    "    print(\n",
    "        f\"For the feature \\'{col_name}\\', the least common label is '{rare_label}' with {rare_label_num} occurrences. This represents {rare_label_proportion:.2%} of the dataset.\")\n",
    "\n",
    "    biased = (len(label_counter) < 2) or ((rare_label_proportion < min_proportion) and (rare_label_num < min_num))\n",
    "    return bool(biased)\n",
    "\n",
    "\n",
    "def judge_continuous_variable_biased(dataframe, col_name):\n",
    "    \"\"\"Check if the distribution of a continuous variable in the dataset is too biased to be usable for analysis.\n",
    "    As a starting point, we consider it biased if all values are the same. For the next step, maybe ask GPT to judge\n",
    "    based on quartile statistics combined with its common sense knowledge about this feature.\n",
    "    \"\"\"\n",
    "    quartiles = dataframe[col_name].quantile([0.25, 0.5, 0.75])\n",
    "    min_value = dataframe[col_name].min()\n",
    "    max_value = dataframe[col_name].max()\n",
    "\n",
    "    # Printing quartile information\n",
    "    print(f\"Quartiles for '{col_name}':\")\n",
    "    print(f\"  25%: {quartiles[0.25]}\")\n",
    "    print(f\"  50% (Median): {quartiles[0.5]}\")\n",
    "    print(f\"  75%: {quartiles[0.75]}\")\n",
    "    print(f\"Min: {min_value}\")\n",
    "    print(f\"Max: {max_value}\")\n",
    "\n",
    "    biased = min_value == max_value\n",
    "\n",
    "    return bool(biased)\n",
    "\n",
    "\n",
    "def check_rows_and_columns(dataframe, display=False):\n",
    "    \"\"\"\n",
    "    Get the lists of row names and column names of a dataset, and optionally observe them.\n",
    "    :param dataframe:\n",
    "    :param display:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataframe_rows = dataframe.index.tolist()\n",
    "    if display:\n",
    "        print(f\"The dataset has {len(dataframe_rows)} rows, such as {dataframe_rows[:20]}\")\n",
    "    dataframe_cols = dataframe.columns.tolist()\n",
    "    if display:\n",
    "        print(f\"\\nThe dataset has {len(dataframe_cols)} columns, such as {dataframe_cols[:20]}\")\n",
    "    return dataframe_rows, dataframe_cols\n",
    "\n",
    "\n",
    "def xena_convert_trait(row_index: str):\n",
    "    \"\"\"\n",
    "    Convert the trait information from Sample IDs to labels depending on the last two digits.\n",
    "    Tumor types range from 01 - 09, normal types from 10 - 19.\n",
    "    :param row_index: the index value of a row\n",
    "    :return: the converted value\n",
    "    \"\"\"\n",
    "    last_two_digits = int(row_index[-2:])\n",
    "\n",
    "    if 1 <= last_two_digits <= 9:\n",
    "        return 1\n",
    "    elif 10 <= last_two_digits <= 19:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def xena_convert_gender(cell: str):\n",
    "    \"\"\"Convert the cell content about gender to a binary value\n",
    "    \"\"\"\n",
    "    if isinstance(cell, str):\n",
    "        cell = cell.lower()\n",
    "\n",
    "    if cell == \"female\":\n",
    "        return 0\n",
    "    elif cell == \"male\":\n",
    "        return 1\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def xena_convert_age(cell: str):\n",
    "    \"\"\"Convert the cell content about age to a numerical value using regular expression\n",
    "    \"\"\"\n",
    "    match = re.search(r'\\d+', str(cell))\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def detect_batch_effect(X):\n",
    "    \"\"\"\n",
    "    Detect potential batch effects in a dataset using eigenvalues of XX^T.\n",
    "\n",
    "    Args:\n",
    "    X (numpy.ndarray): A feature matrix with shape (n_samples, n_features).\n",
    "\n",
    "    Returns:\n",
    "    bool: True if a potential batch effect is detected, False otherwise.\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    # Computing XX^T\n",
    "    XXt = np.dot(X, X.T)\n",
    "\n",
    "    # Compute the eigenvalues of XX^T\n",
    "    eigen_values = np.linalg.eigvalsh(XXt)  # Using eigvalsh since XX^T is symmetric\n",
    "    eigen_values = sorted(eigen_values, reverse=True)[:10]\n",
    "    eigen_values = np.array(eigen_values)\n",
    "    normalized_ev = eigen_values / eigen_values[0]\n",
    "\n",
    "    # Check for large gaps in the eigenvalues\n",
    "    for i in range(len(normalized_ev) - 1):\n",
    "        gap = normalized_ev[i] - normalized_ev[i + 1]\n",
    "        if gap > 1 / n_samples:  # You may need to adjust this threshold\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_unique_values_by_row(dataframe, max_len=30):\n",
    "    \"\"\"\n",
    "    Organize the unique values in each row of the given dataframe, to get a dictionary\n",
    "    :param dataframe:\n",
    "    :param max_len:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if '!Sample_geo_accession' in dataframe.columns:\n",
    "        dataframe = dataframe.drop(columns=['!Sample_geo_accession'])\n",
    "    unique_values_dict = {}\n",
    "    for index, row in dataframe.iterrows():\n",
    "        unique_values = list(row.unique())[:max_len]\n",
    "        unique_values_dict[index] = unique_values\n",
    "    return unique_values_dict\n",
    "\n",
    "\n",
    "def xena_select_clinical_features(clinical_df, trait, age_col=None, gender_col=None):\n",
    "    feature_list = []\n",
    "    trait_data = clinical_df.index.to_series().apply(xena_convert_trait).rename(trait)\n",
    "    feature_list.append(trait_data)\n",
    "    if age_col:\n",
    "        age_data = clinical_df[age_col].apply(xena_convert_age).rename(\"Age\")\n",
    "        feature_list.append(age_data)\n",
    "    if gender_col:\n",
    "        gender_data = clinical_df[gender_col].apply(xena_convert_gender).rename(\"Gender\")\n",
    "        feature_list.append(gender_data)\n",
    "    selected_clinical_df = pd.concat(feature_list, axis=1)\n",
    "    return selected_clinical_df\n",
    "\n",
    "\n",
    "def geo_select_clinical_features(clinical_df: pd.DataFrame, trait: str, trait_row: int,\n",
    "                                 convert_trait: Callable,\n",
    "                                 age_row: Optional[int] = None,\n",
    "                                 convert_age: Optional[Callable] = None,\n",
    "                                 gender_row: Optional[int] = None,\n",
    "                                 convert_gender: Optional[Callable] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts and processes specific clinical features from a DataFrame representing\n",
    "    sample characteristics in the GEO database series.\n",
    "\n",
    "    Parameters:\n",
    "    - clinical_df (pd.DataFrame): DataFrame containing clinical data.\n",
    "    - trait (str): The trait of interest.\n",
    "    - trait_row (int): Row identifier for the trait in the DataFrame.\n",
    "    - convert_trait (Callable): Function to convert trait data into a desired format.\n",
    "    - age_row (int, optional): Row identifier for age data. Default is None.\n",
    "    - convert_age (Callable, optional): Function to convert age data. Default is None.\n",
    "    - gender_row (int, optional): Row identifier for gender data. Default is None.\n",
    "    - convert_gender (Callable, optional): Function to convert gender data. Default is None.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the selected and processed clinical features.\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "\n",
    "    trait_data = get_feature_data(clinical_df, trait_row, trait, convert_trait)\n",
    "    feature_list.append(trait_data)\n",
    "    if age_row is not None:\n",
    "        age_data = get_feature_data(clinical_df, age_row, 'Age', convert_age)\n",
    "        feature_list.append(age_data)\n",
    "    if gender_row is not None:\n",
    "        gender_data = get_feature_data(clinical_df, gender_row, 'Gender', convert_gender)\n",
    "        feature_list.append(gender_data)\n",
    "\n",
    "    selected_clinical_df = pd.concat(feature_list, axis=0)\n",
    "    return selected_clinical_df\n",
    "\n",
    "\n",
    "def geo_merge_clinical_genetic_data(clinical_df, genetic_df):\n",
    "    \"\"\"\n",
    "    Merge the clinical features and gene expression features from two dataframes into one dataframe\n",
    "    \"\"\"\n",
    "    if 'ID' in genetic_df.columns:\n",
    "        genetic_df = genetic_df.rename(columns={'ID': 'Gene'})\n",
    "    if 'Gene' in genetic_df.columns:\n",
    "        genetic_df = genetic_df.set_index('Gene')\n",
    "    merged_data = pd.concat([clinical_df, genetic_df], axis=0).T.dropna()\n",
    "    return merged_data\n",
    "\n",
    "\n",
    "def judge_and_remove_biased_features(df, trait, trait_type):\n",
    "    assert trait_type in [\"binary\", \"continuous\"], f\"The trait must be either a binary or a continuous variable!\"\n",
    "    if trait_type == \"binary\":\n",
    "        trait_biased = judge_binary_variable_biased(df, trait)\n",
    "    else:\n",
    "        trait_biased = judge_continuous_variable_biased(df, trait)\n",
    "    if trait_biased:\n",
    "        print(f\"The distribution of the feature \\'{trait}\\' in this dataset is severely biased.\\n\")\n",
    "    else:\n",
    "        print(f\"The distribution of the feature \\'{trait}\\' in this dataset is fine.\\n\")\n",
    "    if \"Age\" in df.columns:\n",
    "        age_biased = judge_continuous_variable_biased(df, 'Age')\n",
    "        if age_biased:\n",
    "            print(f\"The distribution of the feature \\'Age\\' in this dataset is severely biased.\\n\")\n",
    "            df = df.drop(columns='Age')\n",
    "        else:\n",
    "            print(f\"The distribution of the feature \\'Age\\' in this dataset is fine.\\n\")\n",
    "    if \"Gender\" in df.columns:\n",
    "        gender_biased = judge_binary_variable_biased(df, 'Gender')\n",
    "        if gender_biased:\n",
    "            print(f\"The distribution of the feature \\'Gender\\' in this dataset is severely biased.\\n\")\n",
    "            df = df.drop(columns='Gender')\n",
    "        else:\n",
    "            print(f\"The distribution of the feature \\'Gender\\' in this dataset is fine.\\n\")\n",
    "\n",
    "    return trait_biased, df\n",
    "\n",
    "\n",
    "def save_cohort_info(cohort: str, info_path: str, is_available: bool, is_biased: Optional[bool] = None,\n",
    "                     df: Optional[pd.DataFrame] = None, note: str = '') -> None:\n",
    "    \"\"\"\n",
    "    Add or update information about the usability and quality of a dataset for statistical analysis.\n",
    "\n",
    "    Parameters:\n",
    "    cohort (str): A unique identifier for the dataset.\n",
    "    info_path (str): File path to the JSON file where records are stored.\n",
    "    is_available (bool): Indicates whether both the genetic data and trait data are available in the dataset, and can be\n",
    "     preprocessed into a dataframe.\n",
    "    is_biased (bool, optional): Indicates whether the dataset is too biased to be usable.\n",
    "        Required if `is_available` is True.\n",
    "    df (pandas.DataFrame, optional): The preprocessed dataset. Required if `is_available` is True.\n",
    "    note (str, optional): Additional notes about the dataset.\n",
    "\n",
    "    Returns:\n",
    "    None: The function does not return a value but updates or creates a record in the specified JSON file.\n",
    "    \"\"\"\n",
    "    if is_available:\n",
    "        assert (df is not None) and (is_biased is not None), \"'df' and 'is_biased' should be provided if this cohort \" \\\n",
    "                                                             \"is relevant.\"\n",
    "    is_usable = is_available and (not is_biased)\n",
    "    new_record = {\"is_usable\": is_usable,\n",
    "                  \"is_available\": is_available,\n",
    "                  \"is_biased\": is_biased if is_available else None,\n",
    "                  \"has_age\": \"Age\" in df.columns if is_available else None,\n",
    "                  \"has_gender\": \"Gender\" in df.columns if is_available else None,\n",
    "                  \"sample_size\": len(df) if is_available else None,\n",
    "                  \"note\": note}\n",
    "\n",
    "    trait_directory = os.path.dirname(info_path)\n",
    "    os.makedirs(trait_directory, exist_ok=True)\n",
    "    if not os.path.exists(info_path):\n",
    "        with open(info_path, 'w') as file:\n",
    "            json.dump({}, file)\n",
    "        print(f\"A new JSON file was created at: {info_path}\")\n",
    "\n",
    "    with open(info_path, \"r\") as file:\n",
    "        records = json.load(file)\n",
    "    records[cohort] = new_record\n",
    "\n",
    "    temp_path = info_path + \".tmp\"\n",
    "    try:\n",
    "        with open(temp_path, 'w') as file:\n",
    "            json.dump(records, file)\n",
    "        os.replace(temp_path, info_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "        raise\n",
    "\n",
    "\n",
    "def read_json_to_dataframe(json_file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a JSON file and converts it into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "    json_file (str): The path to the JSON file containing the data.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A pandas DataFrame with the JSON data.\n",
    "    \"\"\"\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return pd.DataFrame.from_dict(data, orient='index').reset_index().rename(columns={'index': 'cohort_id'})\n",
    "\n",
    "\n",
    "def filter_and_rank_cohorts(json_file: str, condition: Union[str, None] = None) -> Tuple[\n",
    "    Union[str, None], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Reads a JSON file, filters cohorts based on usability and an optional condition, then ranks them by sample size.\n",
    "\n",
    "    Args:\n",
    "    json_file (str): The path to the JSON file containing the data.\n",
    "    condition (str, optional): An additional condition for filtering. If None, only 'is_usable' is considered.\n",
    "\n",
    "    Returns:\n",
    "    Tuple: A tuple containing the best cohort ID (str or None if no suitable cohort is found) and\n",
    "           the filtered and ranked DataFrame.\n",
    "    \"\"\"\n",
    "    # Read the JSON file into a DataFrame\n",
    "    df = read_json_to_dataframe(json_file)\n",
    "\n",
    "    if condition:\n",
    "        filtered_df = df[(df['is_usable'] == True) & (df[condition] == True)]\n",
    "    else:\n",
    "        filtered_df = df[df['is_usable'] == True]\n",
    "\n",
    "    ranked_df = filtered_df.sort_values(by='sample_size', ascending=False)\n",
    "    best_cohort_id = ranked_df.iloc[0]['cohort_id'] if not ranked_df.empty else None\n",
    "\n",
    "    return best_cohort_id, ranked_df\n",
    "\n",
    "\n",
    "def read_json_to_dataframe(json_file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a JSON file and converts it into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return pd.DataFrame.from_dict(data, orient='index').reset_index().rename(columns={'index': 'cohort_id'})\n",
    "\n",
    "\n",
    "def filter_and_rank_cohorts(json_file: str, condition: Union[str, None] = None) -> Tuple[\n",
    "    Union[str, None], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Reads a JSON file, filters cohorts based on usability and an optional condition, then ranks them by sample size.\n",
    "\n",
    "    Args:\n",
    "    json_file (str): The path to the JSON file containing the data.\n",
    "    condition (str, optional): An additional condition for filtering. If None, only 'is_usable' is considered.\n",
    "\n",
    "    Returns:\n",
    "    Tuple: A tuple containing the best cohort ID (str or None if no suitable cohort is found) and\n",
    "           the filtered and ranked DataFrame.\n",
    "    \"\"\"\n",
    "    df = read_json_to_dataframe(json_file)\n",
    "    if condition:\n",
    "        if condition.lower() in ['age', 'gender']:\n",
    "            condition = 'has_' + condition.lower()\n",
    "        assert condition in ['has_age', 'has_gender']\n",
    "        filtered_df = df[(df['is_usable'] == True) & (df[condition] == True)]\n",
    "    else:\n",
    "        filtered_df = df[df['is_usable'] == True]\n",
    "    ranked_df = filtered_df.sort_values(by='sample_size', ascending=False)\n",
    "    best_cohort_id = ranked_df.iloc[0]['cohort_id'] if not ranked_df.empty else None\n",
    "\n",
    "    return best_cohort_id, ranked_df\n",
    "\n",
    "\n",
    "def preview_df(df, n=5):\n",
    "    return df.head(n).to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:25.928143012Z",
     "start_time": "2024-01-10T21:37:25.918685567Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMTdsU43vVg3",
    "outputId": "38886111-f442-44b4-8398-96bf384d7abd"
   },
   "outputs": [],
   "source": [
    "# This cell is only for use on Google Colab. Skip it if you run your code in other environments\n",
    "\n",
    "\"\"\"import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "proj_dir = '/content/drive/MyDrive/AI4Science_Public'\n",
    "os.chdir(proj_dir)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2. Data preprocessing and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.1. The TCGA Xena dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In TCGA Xena, there is either zero or one cohort related to the trait. We search the names of subdirectories to see if any matches the trait. If a match is found, we directly obtain the file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:26.554597756Z",
     "start_time": "2024-01-10T21:37:26.530982646Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = 'TCGA'\n",
    "dataset_dir = os.path.join(DATA_ROOT, dataset)\n",
    "os.listdir(dataset_dir)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If no match is found, jump directly to GEO in Part 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:26.999521704Z",
     "start_time": "2024-01-10T21:37:26.987471072Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_subdir = \"TCGA_Adrenocortical_Cancer_(ACC)\"\n",
    "cohort = 'Xena'\n",
    "# All the cancer traits in Xena are binary\n",
    "trait_type = 'binary'\n",
    "# Once a relevant cohort is found in Xena, we can generally assume the gene and clinical data are available\n",
    "is_available = True\n",
    "\n",
    "clinical_data_file = os.path.join(dataset_dir, trait_subdir, 'TCGA.ACC.sampleMap_ACC_clinicalMatrix')\n",
    "genetic_data_file = os.path.join(dataset_dir, trait_subdir, 'TCGA.ACC.sampleMap_HiSeqV2_PANCAN.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.180581225Z",
     "start_time": "2024-01-10T21:37:27.217363685Z"
    },
    "id": "MudwB-_iz7sc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clinical_data = pd.read_csv(clinical_data_file, sep='\\t', index_col=0)\n",
    "genetic_data = pd.read_csv(genetic_data_file, compression='gzip', sep='\\t', index_col=0)\n",
    "age_col = gender_col = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rows_and_columns(dataframe, display=False):\n",
    "    \"\"\"\n",
    "    Get the lists of row names and column names of a dataset, and optionally observe them.\n",
    "    :param dataframe:\n",
    "    :param display:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataframe_rows = dataframe.index.tolist()\n",
    "    if display:\n",
    "        print(f\"The dataset has {len(dataframe_rows)} rows, such as {dataframe_rows[:20]}\")\n",
    "    dataframe_cols = dataframe.columns.tolist()\n",
    "    if display:\n",
    "        print(f\"\\nThe dataset has {len(dataframe_cols)} columns, such as {dataframe_cols[:20]}\")\n",
    "    return dataframe_rows, dataframe_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.185775284Z",
     "start_time": "2024-01-10T21:37:30.181745846Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, clinical_data_cols = check_rows_and_columns(clinical_data)\n",
    "clinical_data_cols[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T20:20:11.841042813Z",
     "start_time": "2023-12-28T20:20:11.834458206Z"
    },
    "collapsed": false
   },
   "source": [
    "Read all the column names in the clinical dataset, to find the columns that record information about age or gender.\n",
    "Reference prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.269854441Z",
     "start_time": "2024-01-10T21:37:30.184225525Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f'''\n",
    "Below is a list of column names from a biomedical dataset. Please examine it and identify the columns that are likely to contain information about patients' age. Additionally, please do the same for columns that may hold data on patients' gender. Please provide your answer by strictly following this format, without redundant words:\n",
    "candidate_age_cols = [col_name1, col_name2, ...]\n",
    "candidate_gender_cols = [col_name1, col_name2, ...]\n",
    "If no columns match a criterion, please provide an empty list.\n",
    "\n",
    "Column names:\n",
    "{clinical_data_cols}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.270036796Z",
     "start_time": "2024-01-10T21:37:30.227180075Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidate_age_cols = [ 'age_at_initial_pathologic_diagnosis',\n",
    "                      'days_to_birth', 'year_of_initial_pathologic_diagnosis']\n",
    "candidate_gender_cols = [ 'gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:57:44.207565572Z",
     "start_time": "2023-12-31T03:57:44.202177544Z"
    },
    "collapsed": false
   },
   "source": [
    "Choose a single column from the candidate columns that record age and gender information respectively.\n",
    "If no column meets the requirement, keep 'age_col' or 'gender_col' to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_df(df, n=5):\n",
    "    return df.head(n).to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.270232386Z",
     "start_time": "2024-01-10T21:37:30.227282564Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preview_df(clinical_data[candidate_age_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.270339062Z",
     "start_time": "2024-01-10T21:37:30.227412883Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_col = 'age_at_initial_pathologic_diagnosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.270520195Z",
     "start_time": "2024-01-10T21:37:30.227467704Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preview_df(clinical_data[candidate_gender_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.270626721Z",
     "start_time": "2024-01-10T21:37:30.227530279Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_col = 'gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xena_select_clinical_features(clinical_df, trait, age_col=None, gender_col=None):\n",
    "    feature_list = []\n",
    "    trait_data = clinical_df.index.to_series().apply(xena_convert_trait).rename(trait)\n",
    "    feature_list.append(trait_data)\n",
    "    if age_col:\n",
    "        age_data = clinical_df[age_col].apply(xena_convert_age).rename(\"Age\")\n",
    "        feature_list.append(age_data)\n",
    "    if gender_col:\n",
    "        gender_data = clinical_df[gender_col].apply(xena_convert_gender).rename(\"Gender\")\n",
    "        feature_list.append(gender_data)\n",
    "    selected_clinical_df = pd.concat(feature_list, axis=1)\n",
    "    return selected_clinical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xena_convert_trait(row_index: str):\n",
    "    \"\"\"\n",
    "    Convert the trait information from Sample IDs to labels depending on the last two digits.\n",
    "    Tumor types range from 01 - 09, normal types from 10 - 19.\n",
    "    :param row_index: the index value of a row\n",
    "    :return: the converted value\n",
    "    \"\"\"\n",
    "    last_two_digits = int(row_index[-2:])\n",
    "\n",
    "    if 1 <= last_two_digits <= 9:\n",
    "        return 1\n",
    "    elif 10 <= last_two_digits <= 19:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xena_convert_age(cell: str):\n",
    "    \"\"\"Convert the cell content about age to a numerical value using regular expression\n",
    "    \"\"\"\n",
    "    match = re.search(r'\\d+', str(cell))\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xena_convert_gender(cell: str):\n",
    "    \"\"\"Convert the cell content about gender to a binary value\n",
    "    \"\"\"\n",
    "    if isinstance(cell, str):\n",
    "        cell = cell.lower()\n",
    "\n",
    "    if cell == \"female\":\n",
    "        return 0\n",
    "    elif cell == \"male\":\n",
    "        return 1\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.270719762Z",
     "start_time": "2024-01-10T21:37:30.227585330Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "selected_clinical_data = xena_select_clinical_features(clinical_data, TRAIT, age_col=age_col, gender_col=gender_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_gene_symbols_in_index(gene_df):\n",
    "    \"\"\"Normalize the human gene symbols at the index of a dataframe, and replace the index with its normalized version.\n",
    "    Remove the rows where the index failed to be normalized.\"\"\"\n",
    "    normalized_gene_list = normalize_gene_symbols(gene_df.index.tolist())\n",
    "    assert len(normalized_gene_list) == len(gene_df.index)\n",
    "    gene_df.index = normalized_gene_list\n",
    "    gene_df = gene_df[gene_df.index.notnull()]\n",
    "    return gene_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_gene_symbols(gene_symbols, batch_size=1000):\n",
    "    \"\"\"Normalize human gene symbols in batches using the 'mygenes' library\"\"\"\n",
    "    mg = mygene.MyGeneInfo()\n",
    "    normalized_genes = {}\n",
    "\n",
    "    # Process in batches\n",
    "    for i in range(0, len(gene_symbols), batch_size):\n",
    "        batch = gene_symbols[i:i + batch_size]\n",
    "        results = mg.querymany(batch, scopes='symbol', fields='symbol', species='human')\n",
    "\n",
    "        # Update the normalized_genes dictionary with results from this batch\n",
    "        for gene in results:\n",
    "            normalized_genes[gene['query']] = gene.get('symbol', None)\n",
    "\n",
    "    # Return the normalized symbols in the same order as the input\n",
    "    return [normalized_genes.get(symbol) for symbol in gene_symbols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:38:18.001977877Z",
     "start_time": "2024-01-10T21:37:30.227635342Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mygene\n",
    "\n",
    "if NORMALIZE_GENE:\n",
    "    genetic_data = normalize_gene_symbols_in_index(genetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:38:18.108889749Z",
     "start_time": "2024-01-10T21:38:18.021199718Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data = selected_clinical_data.join(genetic_data.T).dropna()\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_and_remove_biased_features(df, trait, trait_type):\n",
    "    assert trait_type in [\"binary\", \"continuous\"], f\"The trait must be either a binary or a continuous variable!\"\n",
    "    if trait_type == \"binary\":\n",
    "        trait_biased = judge_binary_variable_biased(df, trait)\n",
    "    else:\n",
    "        trait_biased = judge_continuous_variable_biased(df, trait)\n",
    "    if trait_biased:\n",
    "        print(f\"The distribution of the feature \\'{trait}\\' in this dataset is severely biased.\\n\")\n",
    "    else:\n",
    "        print(f\"The distribution of the feature \\'{trait}\\' in this dataset is fine.\\n\")\n",
    "    if \"Age\" in df.columns:\n",
    "        age_biased = judge_continuous_variable_biased(df, 'Age')\n",
    "        if age_biased:\n",
    "            print(f\"The distribution of the feature \\'Age\\' in this dataset is severely biased.\\n\")\n",
    "            df = df.drop(columns='Age')\n",
    "        else:\n",
    "            print(f\"The distribution of the feature \\'Age\\' in this dataset is fine.\\n\")\n",
    "    if \"Gender\" in df.columns:\n",
    "        gender_biased = judge_binary_variable_biased(df, 'Gender')\n",
    "        if gender_biased:\n",
    "            print(f\"The distribution of the feature \\'Gender\\' in this dataset is severely biased.\\n\")\n",
    "            df = df.drop(columns='Gender')\n",
    "        else:\n",
    "            print(f\"The distribution of the feature \\'Gender\\' in this dataset is fine.\\n\")\n",
    "\n",
    "    return trait_biased, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_binary_variable_biased(dataframe, col_name, min_proportion=0.1, min_num=5):\n",
    "    \"\"\"\n",
    "    Check if the distribution of a binary variable in the dataset is too biased to be usable for analysis\n",
    "    :param dataframe:\n",
    "    :param col_name:\n",
    "    :param min_proportion:\n",
    "    :param min_num:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    label_counter = dataframe[col_name].value_counts()\n",
    "    total_samples = len(dataframe)\n",
    "    rare_label_num = label_counter.min()\n",
    "    rare_label = label_counter.idxmin()\n",
    "    rare_label_proportion = rare_label_num / total_samples\n",
    "\n",
    "    print(\n",
    "        f\"For the feature \\'{col_name}\\', the least common label is '{rare_label}' with {rare_label_num} occurrences. This represents {rare_label_proportion:.2%} of the dataset.\")\n",
    "\n",
    "    biased = (len(label_counter) < 2) or ((rare_label_proportion < min_proportion) and (rare_label_num < min_num))\n",
    "    return bool(biased)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_continuous_variable_biased(dataframe, col_name):\n",
    "    \"\"\"Check if the distribution of a continuous variable in the dataset is too biased to be usable for analysis.\n",
    "    As a starting point, we consider it biased if all values are the same. For the next step, maybe ask GPT to judge\n",
    "    based on quartile statistics combined with its common sense knowledge about this feature.\n",
    "    \"\"\"\n",
    "    quartiles = dataframe[col_name].quantile([0.25, 0.5, 0.75])\n",
    "    min_value = dataframe[col_name].min()\n",
    "    max_value = dataframe[col_name].max()\n",
    "\n",
    "    # Printing quartile information\n",
    "    print(f\"Quartiles for '{col_name}':\")\n",
    "    print(f\"  25%: {quartiles[0.25]}\")\n",
    "    print(f\"  50% (Median): {quartiles[0.5]}\")\n",
    "    print(f\"  75%: {quartiles[0.75]}\")\n",
    "    print(f\"Min: {min_value}\")\n",
    "    print(f\"Max: {max_value}\")\n",
    "\n",
    "    biased = min_value == max_value\n",
    "\n",
    "    return bool(biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:38:18.112793384Z",
     "start_time": "2024-01-10T21:38:18.107415526Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"The merged dataset contains {len(merged_data)} samples.\")\n",
    "is_trait_biased, merge_data = judge_and_remove_biased_features(merged_data, TRAIT, trait_type=trait_type)\n",
    "is_trait_biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:38:31.377898533Z",
     "start_time": "2024-01-10T21:38:18.111417452Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data.head()\n",
    "if not is_trait_biased:\n",
    "    merge_data.to_csv(os.path.join(OUTPUT_DIR, cohort + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, List, Tuple, Union, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cohort_info(cohort: str, info_path: str, is_available: bool, is_biased: Optional[bool] = None,\n",
    "                     df: Optional[pd.DataFrame] = None, note: str = '') -> None:\n",
    "    \"\"\"\n",
    "    Add or update information about the usability and quality of a dataset for statistical analysis.\n",
    "\n",
    "    Parameters:\n",
    "    cohort (str): A unique identifier for the dataset.\n",
    "    info_path (str): File path to the JSON file where records are stored.\n",
    "    is_available (bool): Indicates whether both the genetic data and trait data are available in the dataset, and can be\n",
    "     preprocessed into a dataframe.\n",
    "    is_biased (bool, optional): Indicates whether the dataset is too biased to be usable.\n",
    "        Required if `is_available` is True.\n",
    "    df (pandas.DataFrame, optional): The preprocessed dataset. Required if `is_available` is True.\n",
    "    note (str, optional): Additional notes about the dataset.\n",
    "\n",
    "    Returns:\n",
    "    None: The function does not return a value but updates or creates a record in the specified JSON file.\n",
    "    \"\"\"\n",
    "    if is_available:\n",
    "        assert (df is not None) and (is_biased is not None), \"'df' and 'is_biased' should be provided if this cohort \" \\\n",
    "                                                             \"is relevant.\"\n",
    "    is_usable = is_available and (not is_biased)\n",
    "    new_record = {\"is_usable\": is_usable,\n",
    "                  \"is_available\": is_available,\n",
    "                  \"is_biased\": is_biased if is_available else None,\n",
    "                  \"has_age\": \"Age\" in df.columns if is_available else None,\n",
    "                  \"has_gender\": \"Gender\" in df.columns if is_available else None,\n",
    "                  \"sample_size\": len(df) if is_available else None,\n",
    "                  \"note\": note}\n",
    "    \n",
    "    if not os.path.exists(info_path):\n",
    "        with open(info_path, 'w') as file:\n",
    "            json.dump({}, file)\n",
    "        print(f\"A new JSON file was created at: {info_path}\")\n",
    "\n",
    "    with open(info_path, \"r\") as file:\n",
    "        records = json.load(file)\n",
    "    records[cohort] = new_record\n",
    "\n",
    "    temp_path = info_path + \".tmp\"\n",
    "    try:\n",
    "        with open(temp_path, 'w') as file:\n",
    "            json.dump(records, file)\n",
    "        os.replace(temp_path, info_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:38:31.425336629Z",
     "start_time": "2024-01-10T21:38:31.419043732Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "save_cohort_info(cohort, JSON_PATH, is_available, is_trait_biased, merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T21:28:38.028916303Z",
     "start_time": "2023-12-28T21:28:38.016245426Z"
    },
    "collapsed": false
   },
   "source": [
    "## 2.2. The GEO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:25:23.253882615Z",
     "start_time": "2023-12-31T03:25:23.244062710Z"
    },
    "collapsed": false
   },
   "source": [
    "In GEO, there may be one or multiple cohorts for a trait. Each cohort is identified by an accession number. We iterate over all accession numbers in the corresponding subdirectory, preprocess the cohort data, and save them to csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:38:31.425592571Z",
     "start_time": "2024-01-10T21:38:31.419137625Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GSE236924']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'GEO'\n",
    "trait_subdir = \"Inflammatory-Disorders\"\n",
    "\n",
    "trait_path = os.path.join(DATA_ROOT, dataset, trait_subdir)\n",
    "os.listdir(trait_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:39:42.634870142Z",
     "start_time": "2023-12-31T03:39:42.534093295Z"
    },
    "collapsed": false
   },
   "source": [
    "Repeat the below steps for all the accession numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:39:02.935079426Z",
     "start_time": "2024-01-10T21:39:02.923698385Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/jacob/Documents\\\\GEO\\\\Inflammatory-Disorders\\\\GSE236924\\\\GSE236924_family.soft.gz',\n",
       " '/Users/jacob/Documents\\\\GEO\\\\Inflammatory-Disorders\\\\GSE236924\\\\GSE236924_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE236924\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = geo_get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Initial filtering and clinical data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background_and_clinical_data(file_path,\n",
    "                                     prefixes_a=['!Series_title', '!Series_summary', '!Series_overall_design'],\n",
    "                                     prefixes_b=['!Sample_geo_accession', '!Sample_characteristics_ch1']):\n",
    "    \"\"\"Extract from a matrix file the background information about the dataset, and sample characteristics data\"\"\"\n",
    "    background_info, clinical_data = filter_content_by_prefix(file_path, prefixes_a, prefixes_b, unselect=False,\n",
    "                                                              source_type='file',\n",
    "                                                              return_df_a=False, return_df_b=True)\n",
    "    return background_info, clinical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:39:03.718770427Z",
     "start_time": "2024-01-10T21:39:03.677006442Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!Series_title\t\"SIRPa agonist antibody treatment ameliorates experimental arthritis and colitis [array]\"\n",
      "!Series_summary\t\"The innate immune system is finely tuned to enable. rapid response to pathogenic stimuli but keep quiescent during tissue homeostasis.Â Balance of activating and inhibitory signaling sets a threshold for immune activation. Signal regulatory protein (SIRPa) is an immune inhibitory receptor expressed by myeloid cells and interacts with CD47 to inhibit immune cell phagocytosis, migration, and activation. Despite the progress of SIRPa and CD47 antagonist antibodies to promote anti-cancer immunity, it is not yet known whether therapeutic SIRPa receptor agonism could restrain excessive autoimmune inflammation in the context of autoimmunity. Here, we reported that increased neutrophil- and monocyte-associated genes including SIRPA in inflamed tissues biopsies of rheumatoid arthritis and inflammatory bowel diseases, and elevated SIRPA in colonic biopsies is associated with treatment refractory ulcerative colitis patients. We next identified a novel agonistic anti-SIRPa antibody that exhibited potent anti-inflammatory effects in reducing neutrophil and monocytes chemotaxis and tissue infiltration. In preclinical models of arthritis and colitis, anti-SIRPa agonistic antibody ameliorates autoimmune joint inflammation and inflammatory colitis through reducing neutrophils and monocytes in tissues. Our work provides a proof-of-concept for SIRPa receptor agonism for suppressing excessive innate immune activation and autoimmune inflammatory therapeutic treatment\"\n",
      "!Series_overall_design\t\"Comparison of non-disease joint tissue to tissue samples from osteoarthritis and rheumatoid arthritis\"\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "background_prefixes = ['!Series_title', '!Series_summary', '!Series_overall_design']\n",
    "clinical_prefixes = ['!Sample_geo_accession', '!Sample_characteristics_ch1']\n",
    "\n",
    "background_info, clinical_data = get_background_and_clinical_data(matrix_file, background_prefixes, clinical_prefixes)\n",
    "print(background_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:39:04.022548957Z",
     "start_time": "2024-01-10T21:39:04.008519515Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!Sample_geo_accession</th>\n",
       "      <th>GSM7585682</th>\n",
       "      <th>GSM7585683</th>\n",
       "      <th>GSM7585684</th>\n",
       "      <th>GSM7585685</th>\n",
       "      <th>GSM7585686</th>\n",
       "      <th>GSM7585687</th>\n",
       "      <th>GSM7585688</th>\n",
       "      <th>GSM7585689</th>\n",
       "      <th>GSM7585690</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM7585804</th>\n",
       "      <th>GSM7585805</th>\n",
       "      <th>GSM7585806</th>\n",
       "      <th>GSM7585807</th>\n",
       "      <th>GSM7585808</th>\n",
       "      <th>GSM7585809</th>\n",
       "      <th>GSM7585810</th>\n",
       "      <th>GSM7585811</th>\n",
       "      <th>GSM7585812</th>\n",
       "      <th>GSM7585813</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!Sample_characteristics_ch1</td>\n",
       "      <td>disease: OA</td>\n",
       "      <td>disease: OA</td>\n",
       "      <td>disease: OA</td>\n",
       "      <td>disease: Control</td>\n",
       "      <td>disease: RA</td>\n",
       "      <td>disease: OA</td>\n",
       "      <td>disease: OA</td>\n",
       "      <td>disease: OA</td>\n",
       "      <td>disease: Control</td>\n",
       "      <td>...</td>\n",
       "      <td>disease: OA</td>\n",
       "      <td>disease: OA</td>\n",
       "      <td>disease: OA</td>\n",
       "      <td>disease: OA</td>\n",
       "      <td>disease: RA</td>\n",
       "      <td>disease: OA</td>\n",
       "      <td>disease: OA</td>\n",
       "      <td>disease: OA</td>\n",
       "      <td>disease: Control</td>\n",
       "      <td>disease: OA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         !Sample_geo_accession   GSM7585682   GSM7585683   GSM7585684  \\\n",
       "0  !Sample_characteristics_ch1  disease: OA  disease: OA  disease: OA   \n",
       "\n",
       "         GSM7585685   GSM7585686   GSM7585687   GSM7585688   GSM7585689  \\\n",
       "0  disease: Control  disease: RA  disease: OA  disease: OA  disease: OA   \n",
       "\n",
       "         GSM7585690  ...   GSM7585804   GSM7585805   GSM7585806   GSM7585807  \\\n",
       "0  disease: Control  ...  disease: OA  disease: OA  disease: OA  disease: OA   \n",
       "\n",
       "    GSM7585808   GSM7585809   GSM7585810   GSM7585811        GSM7585812  \\\n",
       "0  disease: RA  disease: OA  disease: OA  disease: OA  disease: Control   \n",
       "\n",
       "    GSM7585813  \n",
       "0  disease: OA  \n",
       "\n",
       "[1 rows x 133 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:39:04.307639583Z",
     "start_time": "2024-01-10T21:39:04.289352075Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['disease: OA', 'disease: Control', 'disease: RA']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data_unique = get_unique_values_by_row(clinical_data)\n",
    "clinical_data_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:04.978204446Z",
     "start_time": "2023-12-31T03:58:04.922270095Z"
    },
    "collapsed": false
   },
   "source": [
    "Analyze the metadata to determine data relevance and find ways to extract the clinical data.\n",
    "Reference prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:39:04.854586192Z",
     "start_time": "2024-01-10T21:39:04.836283516Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a biomedical research team, we are selecting datasets to study the association between the human trait \\'Inflammatory Disorders\\' and genetic factors, optionally considering the influence of age and gender. After searching the GEO database and parsing the matrix file of a series, we obtained background information and sample characteristics data. We will provide textual information about the dataset background, and a Python dictionary storing a list of unique values for each field of the sample characteristics data. Please carefully review the provided information and answer the following questions about this dataset:\\n1. Does this dataset contain gene expression data? (Note: Pure miRNA data is not suitable.)\\n2. For each of the traits \\'Inflammatory Disorders\\', \\'age\\', and \\'gender\\', please address these points:\\n   (1) Is there human data available for this trait?\\n   (2) If so, identify the key in the sample characteristics dictionary where unique values of this trait is recorded. The key is an integer. The trait information might be explicitly recorded, or can be inferred from the field with some biomedical knowledge or understanding about the data collection process.\\n   (3) Choose an appropriate data type (either \\'continuous\\' or \\'binary\\') for each trait. Write a Python function to convert any given value of the trait to this data type. The function should handle inference about the trait value and convert unknown values to None.\\n   Name the functions \\'convert_trait\\', \\'convert_age\\', and \\'convert_gender\\', respectively.\\n\\nBackground information about the dataset:\\n!Series_title\\t\"SIRPa agonist antibody treatment ameliorates experimental arthritis and colitis [array]\"\\n!Series_summary\\t\"The innate immune system is finely tuned to enable. rapid response to pathogenic stimuli but keep quiescent during tissue homeostasis.Â\\xa0Balance of activating and inhibitory signaling sets a threshold for immune activation. Signal regulatory protein (SIRPa) is an immune inhibitory receptor expressed by myeloid cells and interacts with CD47 to inhibit immune cell phagocytosis, migration, and activation. Despite the progress of SIRPa and CD47 antagonist antibodies to promote anti-cancer immunity, it is not yet known whether therapeutic SIRPa receptor agonism could restrain excessive autoimmune inflammation in the context of autoimmunity. Here, we reported that increased neutrophil- and monocyte-associated genes including SIRPA in inflamed tissues biopsies of rheumatoid arthritis and inflammatory bowel diseases, and elevated SIRPA in colonic biopsies is associated with treatment refractory ulcerative colitis patients. We next identified a novel agonistic anti-SIRPa antibody that exhibited potent anti-inflammatory effects in reducing neutrophil and monocytes chemotaxis and tissue infiltration. In preclinical models of arthritis and colitis, anti-SIRPa agonistic antibody ameliorates autoimmune joint inflammation and inflammatory colitis through reducing neutrophils and monocytes in tissues. Our work provides a proof-of-concept for SIRPa receptor agonism for suppressing excessive innate immune activation and autoimmune inflammatory therapeutic treatment\"\\n!Series_overall_design\\t\"Comparison of non-disease joint tissue to tissue samples from osteoarthritis and rheumatoid arthritis\"\\n\\nSample characteristics dictionary (from \"!Sample_characteristics_ch1\", converted to a Python dictionary that stores the unique values for each field):\\n{0: [\\'disease: OA\\', \\'disease: Control\\', \\'disease: RA\\']}\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'''As a biomedical research team, we are selecting datasets to study the association between the human trait \\'{TRAIT}\\' and genetic factors, optionally considering the influence of age and gender. After searching the GEO database and parsing the matrix file of a series, we obtained background information and sample characteristics data. We will provide textual information about the dataset background, and a Python dictionary storing a list of unique values for each field of the sample characteristics data. Please carefully review the provided information and answer the following questions about this dataset:\n",
    "1. Does this dataset contain gene expression data? (Note: Pure miRNA data is not suitable.)\n",
    "2. For each of the traits \\'{TRAIT}\\', 'age', and 'gender', please address these points:\n",
    "   (1) Is there human data available for this trait?\n",
    "   (2) If so, identify the key in the sample characteristics dictionary where unique values of this trait is recorded. The key is an integer. The trait information might be explicitly recorded, or can be inferred from the field with some biomedical knowledge or understanding about the data collection process.\n",
    "   (3) Choose an appropriate data type (either 'continuous' or 'binary') for each trait. Write a Python function to convert any given value of the trait to this data type. The function should handle inference about the trait value and convert unknown values to None.\n",
    "   Name the functions 'convert_trait', 'convert_age', and 'convert_gender', respectively.\n",
    "\n",
    "Background information about the dataset:\n",
    "{background_info}\n",
    "\n",
    "Sample characteristics dictionary (from \"!Sample_characteristics_ch1\", converted to a Python dictionary that stores the unique values for each field):\n",
    "{clinical_data_unique}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:04.978240504Z",
     "start_time": "2023-12-31T03:58:04.922365324Z"
    },
    "collapsed": false
   },
   "source": [
    "Understand and verify the answer from GPT, to assign values to the below variables. Assign None to the 'row_id' variables if relevant data row was not found.\n",
    "Later we need to let GPT format its answer to automatically do these. But given the complexity of this step, let's grow some insight from the free-text answers for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:09.324053151Z",
     "start_time": "2024-01-10T21:40:09.251131090Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_gene_availabe = True\n",
    "trait_row = 0\n",
    "age_row = None\n",
    "gender_row = None\n",
    "trait_type = 'binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:09.912115984Z",
     "start_time": "2024-01-10T21:40:09.907913460Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_available = is_gene_availabe and (trait_row is not None)\n",
    "if not is_available:\n",
    "    save_cohort_info(cohort, JSON_PATH, is_available)\n",
    "    print(\"This cohort is not usable. Please skip the following steps and jump to the next accession number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:10.982148317Z",
     "start_time": "2024-01-10T21:40:10.967368918Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify and use the functions generated by GPT\n",
    "\n",
    "def convert_trait(tissue_type):\n",
    "    \"\"\"\n",
    "    Convert tissue type to epilepsy presence (binary).\n",
    "    Assuming epilepsy presence for 'Hippocampus' tissue.\n",
    "    \"\"\"\n",
    "    if tissue_type == 'disease: OA':\n",
    "        return 1  # Epilepsy present\n",
    "    else:\n",
    "        return 0  # Epilepsy not present\n",
    "\n",
    "\n",
    "def convert_age(age_string):\n",
    "    \"\"\"\n",
    "    Convert age string to a continuous numerical value.\n",
    "    Unknown values are converted to None.\n",
    "    \"\"\"\n",
    "    if age_string.lower() == 'n.a.':\n",
    "        return None\n",
    "    try:\n",
    "        # Extract age as an integer from the string\n",
    "        age = int(age_string.split(': ')[1])\n",
    "        return age\n",
    "    except (ValueError, IndexError):\n",
    "        # In case of any format error or unexpected string structure\n",
    "        return None\n",
    "\n",
    "\n",
    "# It sometimes maps 'female' to 0, and sometimes 1. Does it matter?\n",
    "def convert_gender(gender_string):\n",
    "    \"\"\"\n",
    "    Convert gender string to a binary value.\n",
    "    'female' is represented as 1, 'male' as 0.\n",
    "    Unknown values are converted to None.\n",
    "    \"\"\"\n",
    "    if gender_string.lower() == 'male: 0':\n",
    "        return 0\n",
    "    elif gender_string.lower() == 'male: 1':\n",
    "        return 1\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:11.684556802Z",
     "start_time": "2024-01-10T21:40:11.665079581Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\AppData\\Local\\Temp\\ipykernel_25928\\2239879167.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  clinical_df = clinical_df.applymap(convert_fn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSM7585682</th>\n",
       "      <th>GSM7585683</th>\n",
       "      <th>GSM7585684</th>\n",
       "      <th>GSM7585685</th>\n",
       "      <th>GSM7585686</th>\n",
       "      <th>GSM7585687</th>\n",
       "      <th>GSM7585688</th>\n",
       "      <th>GSM7585689</th>\n",
       "      <th>GSM7585690</th>\n",
       "      <th>GSM7585691</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM7585804</th>\n",
       "      <th>GSM7585805</th>\n",
       "      <th>GSM7585806</th>\n",
       "      <th>GSM7585807</th>\n",
       "      <th>GSM7585808</th>\n",
       "      <th>GSM7585809</th>\n",
       "      <th>GSM7585810</th>\n",
       "      <th>GSM7585811</th>\n",
       "      <th>GSM7585812</th>\n",
       "      <th>GSM7585813</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Inflammatory Disorders</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        GSM7585682  GSM7585683  GSM7585684  GSM7585685  \\\n",
       "Inflammatory Disorders           1           1           1           0   \n",
       "\n",
       "                        GSM7585686  GSM7585687  GSM7585688  GSM7585689  \\\n",
       "Inflammatory Disorders           0           1           1           1   \n",
       "\n",
       "                        GSM7585690  GSM7585691  ...  GSM7585804  GSM7585805  \\\n",
       "Inflammatory Disorders           0           0  ...           1           1   \n",
       "\n",
       "                        GSM7585806  GSM7585807  GSM7585808  GSM7585809  \\\n",
       "Inflammatory Disorders           1           1           0           1   \n",
       "\n",
       "                        GSM7585810  GSM7585811  GSM7585812  GSM7585813  \n",
       "Inflammatory Disorders           1           1           0           1  \n",
       "\n",
       "[1 rows x 132 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_clinical_data = geo_select_clinical_features(clinical_data, TRAIT, trait_row, convert_trait, age_row=age_row,\n",
    "                                                      convert_age=convert_age, gender_row=gender_row,\n",
    "                                                      convert_gender=convert_gender)\n",
    "selected_clinical_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:04.978664193Z",
     "start_time": "2023-12-31T03:58:04.966117261Z"
    },
    "collapsed": false
   },
   "source": [
    "### Genetic data preprocessing and final filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:13.509252107Z",
     "start_time": "2024-01-10T21:40:13.468235630Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSM7585682</th>\n",
       "      <th>GSM7585683</th>\n",
       "      <th>GSM7585684</th>\n",
       "      <th>GSM7585685</th>\n",
       "      <th>GSM7585686</th>\n",
       "      <th>GSM7585687</th>\n",
       "      <th>GSM7585688</th>\n",
       "      <th>GSM7585689</th>\n",
       "      <th>GSM7585690</th>\n",
       "      <th>GSM7585691</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM7585804</th>\n",
       "      <th>GSM7585805</th>\n",
       "      <th>GSM7585806</th>\n",
       "      <th>GSM7585807</th>\n",
       "      <th>GSM7585808</th>\n",
       "      <th>GSM7585809</th>\n",
       "      <th>GSM7585810</th>\n",
       "      <th>GSM7585811</th>\n",
       "      <th>GSM7585812</th>\n",
       "      <th>GSM7585813</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1007_s_at</th>\n",
       "      <td>9.915787</td>\n",
       "      <td>9.903900</td>\n",
       "      <td>9.991649</td>\n",
       "      <td>10.767561</td>\n",
       "      <td>9.529866</td>\n",
       "      <td>9.830854</td>\n",
       "      <td>9.892914</td>\n",
       "      <td>9.746448</td>\n",
       "      <td>10.814086</td>\n",
       "      <td>9.732147</td>\n",
       "      <td>...</td>\n",
       "      <td>9.857190</td>\n",
       "      <td>9.791112</td>\n",
       "      <td>9.746602</td>\n",
       "      <td>9.722812</td>\n",
       "      <td>9.997596</td>\n",
       "      <td>9.958022</td>\n",
       "      <td>9.938037</td>\n",
       "      <td>10.069431</td>\n",
       "      <td>9.688291</td>\n",
       "      <td>9.763029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053_at</th>\n",
       "      <td>8.421830</td>\n",
       "      <td>8.347161</td>\n",
       "      <td>8.604659</td>\n",
       "      <td>8.332991</td>\n",
       "      <td>8.622863</td>\n",
       "      <td>8.692989</td>\n",
       "      <td>8.724447</td>\n",
       "      <td>8.587774</td>\n",
       "      <td>8.656676</td>\n",
       "      <td>8.413099</td>\n",
       "      <td>...</td>\n",
       "      <td>8.396229</td>\n",
       "      <td>8.754522</td>\n",
       "      <td>8.505315</td>\n",
       "      <td>8.638358</td>\n",
       "      <td>8.751548</td>\n",
       "      <td>8.438798</td>\n",
       "      <td>8.452104</td>\n",
       "      <td>8.545762</td>\n",
       "      <td>8.873173</td>\n",
       "      <td>8.429541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117_at</th>\n",
       "      <td>8.943705</td>\n",
       "      <td>8.983762</td>\n",
       "      <td>8.625948</td>\n",
       "      <td>7.778453</td>\n",
       "      <td>9.157139</td>\n",
       "      <td>9.316031</td>\n",
       "      <td>9.238900</td>\n",
       "      <td>9.543723</td>\n",
       "      <td>7.984167</td>\n",
       "      <td>9.431390</td>\n",
       "      <td>...</td>\n",
       "      <td>9.738807</td>\n",
       "      <td>8.826449</td>\n",
       "      <td>8.590130</td>\n",
       "      <td>9.612410</td>\n",
       "      <td>9.751620</td>\n",
       "      <td>9.277400</td>\n",
       "      <td>9.069217</td>\n",
       "      <td>9.289044</td>\n",
       "      <td>9.533699</td>\n",
       "      <td>8.881577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121_at</th>\n",
       "      <td>10.272722</td>\n",
       "      <td>10.387588</td>\n",
       "      <td>10.277682</td>\n",
       "      <td>10.018727</td>\n",
       "      <td>10.268421</td>\n",
       "      <td>10.225283</td>\n",
       "      <td>10.182662</td>\n",
       "      <td>10.302074</td>\n",
       "      <td>10.199037</td>\n",
       "      <td>10.414152</td>\n",
       "      <td>...</td>\n",
       "      <td>10.432919</td>\n",
       "      <td>10.126125</td>\n",
       "      <td>10.220427</td>\n",
       "      <td>10.402952</td>\n",
       "      <td>10.440820</td>\n",
       "      <td>10.077504</td>\n",
       "      <td>10.282228</td>\n",
       "      <td>10.376449</td>\n",
       "      <td>10.134850</td>\n",
       "      <td>10.271861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255_g_at</th>\n",
       "      <td>8.850403</td>\n",
       "      <td>6.092576</td>\n",
       "      <td>6.990492</td>\n",
       "      <td>5.633898</td>\n",
       "      <td>6.127919</td>\n",
       "      <td>7.197087</td>\n",
       "      <td>6.259260</td>\n",
       "      <td>5.883277</td>\n",
       "      <td>5.536464</td>\n",
       "      <td>7.032962</td>\n",
       "      <td>...</td>\n",
       "      <td>6.984405</td>\n",
       "      <td>6.011495</td>\n",
       "      <td>6.028396</td>\n",
       "      <td>7.173943</td>\n",
       "      <td>7.235568</td>\n",
       "      <td>7.926299</td>\n",
       "      <td>5.870638</td>\n",
       "      <td>6.185114</td>\n",
       "      <td>5.668072</td>\n",
       "      <td>6.043240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           GSM7585682  GSM7585683  GSM7585684  GSM7585685  GSM7585686  \\\n",
       "ID                                                                      \n",
       "1007_s_at    9.915787    9.903900    9.991649   10.767561    9.529866   \n",
       "1053_at      8.421830    8.347161    8.604659    8.332991    8.622863   \n",
       "117_at       8.943705    8.983762    8.625948    7.778453    9.157139   \n",
       "121_at      10.272722   10.387588   10.277682   10.018727   10.268421   \n",
       "1255_g_at    8.850403    6.092576    6.990492    5.633898    6.127919   \n",
       "\n",
       "           GSM7585687  GSM7585688  GSM7585689  GSM7585690  GSM7585691  ...  \\\n",
       "ID                                                                     ...   \n",
       "1007_s_at    9.830854    9.892914    9.746448   10.814086    9.732147  ...   \n",
       "1053_at      8.692989    8.724447    8.587774    8.656676    8.413099  ...   \n",
       "117_at       9.316031    9.238900    9.543723    7.984167    9.431390  ...   \n",
       "121_at      10.225283   10.182662   10.302074   10.199037   10.414152  ...   \n",
       "1255_g_at    7.197087    6.259260    5.883277    5.536464    7.032962  ...   \n",
       "\n",
       "           GSM7585804  GSM7585805  GSM7585806  GSM7585807  GSM7585808  \\\n",
       "ID                                                                      \n",
       "1007_s_at    9.857190    9.791112    9.746602    9.722812    9.997596   \n",
       "1053_at      8.396229    8.754522    8.505315    8.638358    8.751548   \n",
       "117_at       9.738807    8.826449    8.590130    9.612410    9.751620   \n",
       "121_at      10.432919   10.126125   10.220427   10.402952   10.440820   \n",
       "1255_g_at    6.984405    6.011495    6.028396    7.173943    7.235568   \n",
       "\n",
       "           GSM7585809  GSM7585810  GSM7585811  GSM7585812  GSM7585813  \n",
       "ID                                                                     \n",
       "1007_s_at    9.958022    9.938037   10.069431    9.688291    9.763029  \n",
       "1053_at      8.438798    8.452104    8.545762    8.873173    8.429541  \n",
       "117_at       9.277400    9.069217    9.289044    9.533699    8.881577  \n",
       "121_at      10.077504   10.282228   10.376449   10.134850   10.271861  \n",
       "1255_g_at    7.926299    5.870638    6.185114    5.668072    6.043240  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genetic_data = get_genetic_data(matrix_file)\n",
    "genetic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:14.107050774Z",
     "start_time": "2024-01-10T21:40:14.090977173Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1007_s_at',\n",
       " '1053_at',\n",
       " '117_at',\n",
       " '121_at',\n",
       " '1255_g_at',\n",
       " '1294_at',\n",
       " '1316_at',\n",
       " '1320_at',\n",
       " '1405_i_at',\n",
       " '1431_at',\n",
       " '1438_at',\n",
       " '1487_at',\n",
       " '1494_f_at',\n",
       " '1552256_a_at',\n",
       " '1552257_a_at',\n",
       " '1552258_at',\n",
       " '1552261_at',\n",
       " '1552263_at',\n",
       " '1552264_a_at',\n",
       " '1552266_at']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_row_ids = genetic_data.index[:20].tolist()\n",
    "gene_row_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:30:41.595335164Z",
     "start_time": "2023-12-31T03:30:41.513232329Z"
    },
    "collapsed": false
   },
   "source": [
    "Check if the gene dataset requires mapping to get the gene symbols corresponding to each data row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Reference prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:16.445692615Z",
     "start_time": "2024-01-10T21:40:16.435117932Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBelow are the row headers of a gene expression dataset in GEO. Based on your biomedical knowledge, are they human gene symbols, or are they some other identifiers that need to be mapped to gene symbols? Your answer should be concluded by starting a new line and strictly following this format:\\nrequires_gene_mapping = (True or False)\\n\\nRow headers:\\n['1007_s_at', '1053_at', '117_at', '121_at', '1255_g_at', '1294_at', '1316_at', '1320_at', '1405_i_at', '1431_at', '1438_at', '1487_at', '1494_f_at', '1552256_a_at', '1552257_a_at', '1552258_at', '1552261_at', '1552263_at', '1552264_a_at', '1552266_at']\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'''\n",
    "Below are the row headers of a gene expression dataset in GEO. Based on your biomedical knowledge, are they human gene symbols, or are they some other identifiers that need to be mapped to gene symbols? Your answer should be concluded by starting a new line and strictly following this format:\n",
    "requires_gene_mapping = (True or False)\n",
    "\n",
    "Row headers:\n",
    "{gene_row_ids}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "If not required, jump directly to the gene normalization step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:17.098774002Z",
     "start_time": "2024-01-10T21:40:17.094437169Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "requires_gene_mapping = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:17.399324928Z",
     "start_time": "2024-01-10T21:40:17.381475568Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': ['1007_s_at', '1053_at', '117_at', '121_at', '1255_g_at'], 'GB_ACC': ['U48705', 'M87338', 'X51757', 'X69699', 'L36861'], 'SPOT_ID': [nan, nan, nan, nan, nan], 'Species Scientific Name': ['Homo sapiens', 'Homo sapiens', 'Homo sapiens', 'Homo sapiens', 'Homo sapiens'], 'Annotation Date': ['Oct 6, 2014', 'Oct 6, 2014', 'Oct 6, 2014', 'Oct 6, 2014', 'Oct 6, 2014'], 'Sequence Type': ['Exemplar sequence', 'Exemplar sequence', 'Exemplar sequence', 'Exemplar sequence', 'Exemplar sequence'], 'Sequence Source': ['Affymetrix Proprietary Database', 'GenBank', 'Affymetrix Proprietary Database', 'GenBank', 'Affymetrix Proprietary Database'], 'Target Description': ['U48705 /FEATURE=mRNA /DEFINITION=HSU48705 Human receptor tyrosine kinase DDR gene, complete cds', 'M87338 /FEATURE= /DEFINITION=HUMA1SBU Human replication factor C, 40-kDa subunit (A1) mRNA, complete cds', \"X51757 /FEATURE=cds /DEFINITION=HSP70B Human heat-shock protein HSP70B' gene\", 'X69699 /FEATURE= /DEFINITION=HSPAX8A H.sapiens Pax8 mRNA', 'L36861 /FEATURE=expanded_cds /DEFINITION=HUMGCAPB Homo sapiens guanylate cyclase activating protein (GCAP) gene exons 1-4, complete cds'], 'Representative Public ID': ['U48705', 'M87338', 'X51757', 'X69699', 'L36861'], 'Gene Title': ['discoidin domain receptor tyrosine kinase 1 /// microRNA 4640', 'replication factor C (activator 1) 2, 40kDa', \"heat shock 70kDa protein 6 (HSP70B')\", 'paired box 8', 'guanylate cyclase activator 1A (retina)'], 'Gene Symbol': ['DDR1 /// MIR4640', 'RFC2', 'HSPA6', 'PAX8', 'GUCA1A'], 'ENTREZ_GENE_ID': ['780 /// 100616237', '5982', '3310', '7849', '2978'], 'RefSeq Transcript ID': ['NM_001202521 /// NM_001202522 /// NM_001202523 /// NM_001954 /// NM_013993 /// NM_013994 /// NR_039783 /// XM_005249385 /// XM_005249386 /// XM_005249387 /// XM_005249389 /// XM_005272873 /// XM_005272874 /// XM_005272875 /// XM_005272877 /// XM_005275027 /// XM_005275028 /// XM_005275030 /// XM_005275031 /// XM_005275162 /// XM_005275163 /// XM_005275164 /// XM_005275166 /// XM_005275457 /// XM_005275458 /// XM_005275459 /// XM_005275461 /// XM_006715185 /// XM_006715186 /// XM_006715187 /// XM_006715188 /// XM_006715189 /// XM_006715190 /// XM_006725501 /// XM_006725502 /// XM_006725503 /// XM_006725504 /// XM_006725505 /// XM_006725506 /// XM_006725714 /// XM_006725715 /// XM_006725716 /// XM_006725717 /// XM_006725718 /// XM_006725719 /// XM_006725720 /// XM_006725721 /// XM_006725722 /// XM_006725827 /// XM_006725828 /// XM_006725829 /// XM_006725830 /// XM_006725831 /// XM_006725832 /// XM_006726017 /// XM_006726018 /// XM_006726019 /// XM_006726020 /// XM_006726021 /// XM_006726022 /// XR_427836 /// XR_430858 /// XR_430938 /// XR_430974 /// XR_431015', 'NM_001278791 /// NM_001278792 /// NM_001278793 /// NM_002914 /// NM_181471 /// XM_006716080', 'NM_002155', 'NM_003466 /// NM_013951 /// NM_013952 /// NM_013953 /// NM_013992', 'NM_000409 /// XM_006715073'], 'Gene Ontology Biological Process': ['0001558 // regulation of cell growth // inferred from electronic annotation /// 0001952 // regulation of cell-matrix adhesion // inferred from electronic annotation /// 0006468 // protein phosphorylation // inferred from electronic annotation /// 0007155 // cell adhesion // traceable author statement /// 0007169 // transmembrane receptor protein tyrosine kinase signaling pathway // inferred from electronic annotation /// 0007565 // female pregnancy // inferred from electronic annotation /// 0007566 // embryo implantation // inferred from electronic annotation /// 0007595 // lactation // inferred from electronic annotation /// 0008285 // negative regulation of cell proliferation // inferred from electronic annotation /// 0010715 // regulation of extracellular matrix disassembly // inferred from mutant phenotype /// 0014909 // smooth muscle cell migration // inferred from mutant phenotype /// 0016310 // phosphorylation // inferred from electronic annotation /// 0018108 // peptidyl-tyrosine phosphorylation // inferred from electronic annotation /// 0030198 // extracellular matrix organization // traceable author statement /// 0038063 // collagen-activated tyrosine kinase receptor signaling pathway // inferred from direct assay /// 0038063 // collagen-activated tyrosine kinase receptor signaling pathway // inferred from mutant phenotype /// 0038083 // peptidyl-tyrosine autophosphorylation // inferred from direct assay /// 0043583 // ear development // inferred from electronic annotation /// 0044319 // wound healing, spreading of cells // inferred from mutant phenotype /// 0046777 // protein autophosphorylation // inferred from direct assay /// 0060444 // branching involved in mammary gland duct morphogenesis // inferred from electronic annotation /// 0060749 // mammary gland alveolus development // inferred from electronic annotation /// 0061302 // smooth muscle cell-matrix adhesion // inferred from mutant phenotype', '0000278 // mitotic cell cycle // traceable author statement /// 0000722 // telomere maintenance via recombination // traceable author statement /// 0000723 // telomere maintenance // traceable author statement /// 0006260 // DNA replication // traceable author statement /// 0006271 // DNA strand elongation involved in DNA replication // traceable author statement /// 0006281 // DNA repair // traceable author statement /// 0006283 // transcription-coupled nucleotide-excision repair // traceable author statement /// 0006289 // nucleotide-excision repair // traceable author statement /// 0006297 // nucleotide-excision repair, DNA gap filling // traceable author statement /// 0015979 // photosynthesis // inferred from electronic annotation /// 0015995 // chlorophyll biosynthetic process // inferred from electronic annotation /// 0032201 // telomere maintenance via semi-conservative replication // traceable author statement', '0000902 // cell morphogenesis // inferred from electronic annotation /// 0006200 // ATP catabolic process // inferred from direct assay /// 0006950 // response to stress // inferred from electronic annotation /// 0006986 // response to unfolded protein // traceable author statement /// 0034605 // cellular response to heat // inferred from direct assay /// 0042026 // protein refolding // inferred from direct assay /// 0070370 // cellular heat acclimation // inferred from mutant phenotype', '0001655 // urogenital system development // inferred from sequence or structural similarity /// 0001656 // metanephros development // inferred from electronic annotation /// 0001658 // branching involved in ureteric bud morphogenesis // inferred from expression pattern /// 0001822 // kidney development // inferred from expression pattern /// 0001823 // mesonephros development // inferred from sequence or structural similarity /// 0003337 // mesenchymal to epithelial transition involved in metanephros morphogenesis // inferred from expression pattern /// 0006351 // transcription, DNA-templated // inferred from direct assay /// 0006355 // regulation of transcription, DNA-templated // inferred from electronic annotation /// 0007275 // multicellular organismal development // inferred from electronic annotation /// 0007417 // central nervous system development // inferred from expression pattern /// 0009653 // anatomical structure morphogenesis // traceable author statement /// 0030154 // cell differentiation // inferred from electronic annotation /// 0030878 // thyroid gland development // inferred from expression pattern /// 0030878 // thyroid gland development // inferred from mutant phenotype /// 0038194 // thyroid-stimulating hormone signaling pathway // traceable author statement /// 0039003 // pronephric field specification // inferred from sequence or structural similarity /// 0042472 // inner ear morphogenesis // inferred from sequence or structural similarity /// 0042981 // regulation of apoptotic process // inferred from sequence or structural similarity /// 0045893 // positive regulation of transcription, DNA-templated // inferred from direct assay /// 0045893 // positive regulation of transcription, DNA-templated // inferred from sequence or structural similarity /// 0045944 // positive regulation of transcription from RNA polymerase II promoter // inferred from direct assay /// 0048793 // pronephros development // inferred from sequence or structural similarity /// 0071371 // cellular response to gonadotropin stimulus // inferred from direct assay /// 0071599 // otic vesicle development // inferred from expression pattern /// 0072050 // S-shaped body morphogenesis // inferred from electronic annotation /// 0072073 // kidney epithelium development // inferred from electronic annotation /// 0072108 // positive regulation of mesenchymal to epithelial transition involved in metanephros morphogenesis // inferred from sequence or structural similarity /// 0072164 // mesonephric tubule development // inferred from electronic annotation /// 0072207 // metanephric epithelium development // inferred from expression pattern /// 0072221 // metanephric distal convoluted tubule development // inferred from sequence or structural similarity /// 0072278 // metanephric comma-shaped body morphogenesis // inferred from expression pattern /// 0072284 // metanephric S-shaped body morphogenesis // inferred from expression pattern /// 0072289 // metanephric nephron tubule formation // inferred from sequence or structural similarity /// 0072305 // negative regulation of mesenchymal cell apoptotic process involved in metanephric nephron morphogenesis // inferred from sequence or structural similarity /// 0072307 // regulation of metanephric nephron tubule epithelial cell differentiation // inferred from sequence or structural similarity /// 0090190 // positive regulation of branching involved in ureteric bud morphogenesis // inferred from sequence or structural similarity /// 1900212 // negative regulation of mesenchymal cell apoptotic process involved in metanephros development // inferred from sequence or structural similarity /// 1900215 // negative regulation of apoptotic process involved in metanephric collecting duct development // inferred from sequence or structural similarity /// 1900218 // negative regulation of apoptotic process involved in metanephric nephron tubule development // inferred from sequence or structural similarity /// 2000594 // positive regulation of metanephric DCT cell differentiation // inferred from sequence or structural similarity /// 2000611 // positive regulation of thyroid hormone generation // inferred from mutant phenotype /// 2000612 // regulation of thyroid-stimulating hormone secretion // inferred from mutant phenotype', '0007165 // signal transduction // non-traceable author statement /// 0007601 // visual perception // inferred from electronic annotation /// 0007602 // phototransduction // inferred from electronic annotation /// 0007603 // phototransduction, visible light // traceable author statement /// 0016056 // rhodopsin mediated signaling pathway // traceable author statement /// 0022400 // regulation of rhodopsin mediated signaling pathway // traceable author statement /// 0030828 // positive regulation of cGMP biosynthetic process // inferred from electronic annotation /// 0031282 // regulation of guanylate cyclase activity // inferred from electronic annotation /// 0031284 // positive regulation of guanylate cyclase activity // inferred from electronic annotation /// 0050896 // response to stimulus // inferred from electronic annotation'], 'Gene Ontology Cellular Component': ['0005576 // extracellular region // inferred from electronic annotation /// 0005615 // extracellular space // inferred from direct assay /// 0005886 // plasma membrane // traceable author statement /// 0005887 // integral component of plasma membrane // traceable author statement /// 0016020 // membrane // inferred from electronic annotation /// 0016021 // integral component of membrane // inferred from electronic annotation /// 0043235 // receptor complex // inferred from direct assay /// 0070062 // extracellular vesicular exosome // inferred from direct assay', '0005634 // nucleus // inferred from electronic annotation /// 0005654 // nucleoplasm // traceable author statement /// 0005663 // DNA replication factor C complex // inferred from direct assay', '0005737 // cytoplasm // inferred from direct assay /// 0005814 // centriole // inferred from direct assay /// 0005829 // cytosol // inferred from direct assay /// 0008180 // COP9 signalosome // inferred from direct assay /// 0070062 // extracellular vesicular exosome // inferred from direct assay /// 0072562 // blood microparticle // inferred from direct assay', '0005634 // nucleus // inferred from direct assay /// 0005654 // nucleoplasm // inferred from sequence or structural similarity /// 0005730 // nucleolus // inferred from direct assay', '0001750 // photoreceptor outer segment // inferred from electronic annotation /// 0001917 // photoreceptor inner segment // inferred from electronic annotation /// 0005578 // proteinaceous extracellular matrix // inferred from electronic annotation /// 0005886 // plasma membrane // inferred from direct assay /// 0016020 // membrane // inferred from electronic annotation /// 0097381 // photoreceptor disc membrane // traceable author statement'], 'Gene Ontology Molecular Function': ['0000166 // nucleotide binding // inferred from electronic annotation /// 0004672 // protein kinase activity // inferred from electronic annotation /// 0004713 // protein tyrosine kinase activity // inferred from electronic annotation /// 0004714 // transmembrane receptor protein tyrosine kinase activity // traceable author statement /// 0005515 // protein binding // inferred from physical interaction /// 0005518 // collagen binding // inferred from direct assay /// 0005518 // collagen binding // inferred from mutant phenotype /// 0005524 // ATP binding // inferred from electronic annotation /// 0016301 // kinase activity // inferred from electronic annotation /// 0016740 // transferase activity // inferred from electronic annotation /// 0016772 // transferase activity, transferring phosphorus-containing groups // inferred from electronic annotation /// 0038062 // protein tyrosine kinase collagen receptor activity // inferred from direct assay /// 0046872 // metal ion binding // inferred from electronic annotation', '0000166 // nucleotide binding // inferred from electronic annotation /// 0003677 // DNA binding // inferred from electronic annotation /// 0005515 // protein binding // inferred from physical interaction /// 0005524 // ATP binding // inferred from electronic annotation /// 0016851 // magnesium chelatase activity // inferred from electronic annotation /// 0017111 // nucleoside-triphosphatase activity // inferred from electronic annotation', '0000166 // nucleotide binding // inferred from electronic annotation /// 0005524 // ATP binding // inferred from electronic annotation /// 0019899 // enzyme binding // inferred from physical interaction /// 0031072 // heat shock protein binding // inferred from physical interaction /// 0042623 // ATPase activity, coupled // inferred from direct assay /// 0051082 // unfolded protein binding // inferred from direct assay', '0000979 // RNA polymerase II core promoter sequence-specific DNA binding // inferred from direct assay /// 0003677 // DNA binding // inferred from direct assay /// 0003677 // DNA binding // inferred from mutant phenotype /// 0003700 // sequence-specific DNA binding transcription factor activity // inferred from direct assay /// 0004996 // thyroid-stimulating hormone receptor activity // traceable author statement /// 0005515 // protein binding // inferred from physical interaction /// 0044212 // transcription regulatory region DNA binding // inferred from direct assay', '0005509 // calcium ion binding // inferred from electronic annotation /// 0008048 // calcium sensitive guanylate cyclase activator activity // inferred from electronic annotation /// 0030249 // guanylate cyclase regulator activity // inferred from electronic annotation /// 0046872 // metal ion binding // inferred from electronic annotation']}\n"
     ]
    }
   ],
   "source": [
    "if requires_gene_mapping:\n",
    "    gene_annotation = get_gene_annotation(soft_file)\n",
    "    gene_annotation_summary = preview_df(gene_annotation)\n",
    "    print(gene_annotation_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:04.978931927Z",
     "start_time": "2023-12-31T03:58:04.966328339Z"
    },
    "collapsed": false
   },
   "source": [
    "Observe the first few cells in the ID column of the gene annotation dataframe, to find the names of columns that store the gene probe IDs and gene symbols respectively.\n",
    "Reference prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:17.944343822Z",
     "start_time": "2024-01-10T21:40:17.933815553Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    As a biomedical research team, we are analyzing a gene expression dataset, and find that its row headers are some identifiers related to genes:\n",
      "    ['1007_s_at', '1053_at', '117_at', '121_at', '1255_g_at', '1294_at', '1316_at', '1320_at', '1405_i_at', '1431_at', '1438_at', '1487_at', '1494_f_at', '1552256_a_at', '1552257_a_at', '1552258_at', '1552261_at', '1552263_at', '1552264_a_at', '1552266_at']\n",
      "    To get the mapping from those identifiers to actual gene symbols, we extracted the gene annotation data from a series in the GEO database, and saved it to a Python dictionary. Please read the dictionary, and decide which key stores the identifiers, and which key stores the gene symbols. Please strictly follow this format in your answer:\n",
      "    identifier_key = 'key_name1'\n",
      "    gene_symbol_key = 'key_name2'\n",
      "\n",
      "    Gene annotation dictionary:\n",
      "    {'ID': ['1007_s_at', '1053_at', '117_at', '121_at', '1255_g_at'], 'GB_ACC': ['U48705', 'M87338', 'X51757', 'X69699', 'L36861'], 'SPOT_ID': [nan, nan, nan, nan, nan], 'Species Scientific Name': ['Homo sapiens', 'Homo sapiens', 'Homo sapiens', 'Homo sapiens', 'Homo sapiens'], 'Annotation Date': ['Oct 6, 2014', 'Oct 6, 2014', 'Oct 6, 2014', 'Oct 6, 2014', 'Oct 6, 2014'], 'Sequence Type': ['Exemplar sequence', 'Exemplar sequence', 'Exemplar sequence', 'Exemplar sequence', 'Exemplar sequence'], 'Sequence Source': ['Affymetrix Proprietary Database', 'GenBank', 'Affymetrix Proprietary Database', 'GenBank', 'Affymetrix Proprietary Database'], 'Target Description': ['U48705 /FEATURE=mRNA /DEFINITION=HSU48705 Human receptor tyrosine kinase DDR gene, complete cds', 'M87338 /FEATURE= /DEFINITION=HUMA1SBU Human replication factor C, 40-kDa subunit (A1) mRNA, complete cds', \"X51757 /FEATURE=cds /DEFINITION=HSP70B Human heat-shock protein HSP70B' gene\", 'X69699 /FEATURE= /DEFINITION=HSPAX8A H.sapiens Pax8 mRNA', 'L36861 /FEATURE=expanded_cds /DEFINITION=HUMGCAPB Homo sapiens guanylate cyclase activating protein (GCAP) gene exons 1-4, complete cds'], 'Representative Public ID': ['U48705', 'M87338', 'X51757', 'X69699', 'L36861'], 'Gene Title': ['discoidin domain receptor tyrosine kinase 1 /// microRNA 4640', 'replication factor C (activator 1) 2, 40kDa', \"heat shock 70kDa protein 6 (HSP70B')\", 'paired box 8', 'guanylate cyclase activator 1A (retina)'], 'Gene Symbol': ['DDR1 /// MIR4640', 'RFC2', 'HSPA6', 'PAX8', 'GUCA1A'], 'ENTREZ_GENE_ID': ['780 /// 100616237', '5982', '3310', '7849', '2978'], 'RefSeq Transcript ID': ['NM_001202521 /// NM_001202522 /// NM_001202523 /// NM_001954 /// NM_013993 /// NM_013994 /// NR_039783 /// XM_005249385 /// XM_005249386 /// XM_005249387 /// XM_005249389 /// XM_005272873 /// XM_005272874 /// XM_005272875 /// XM_005272877 /// XM_005275027 /// XM_005275028 /// XM_005275030 /// XM_005275031 /// XM_005275162 /// XM_005275163 /// XM_005275164 /// XM_005275166 /// XM_005275457 /// XM_005275458 /// XM_005275459 /// XM_005275461 /// XM_006715185 /// XM_006715186 /// XM_006715187 /// XM_006715188 /// XM_006715189 /// XM_006715190 /// XM_006725501 /// XM_006725502 /// XM_006725503 /// XM_006725504 /// XM_006725505 /// XM_006725506 /// XM_006725714 /// XM_006725715 /// XM_006725716 /// XM_006725717 /// XM_006725718 /// XM_006725719 /// XM_006725720 /// XM_006725721 /// XM_006725722 /// XM_006725827 /// XM_006725828 /// XM_006725829 /// XM_006725830 /// XM_006725831 /// XM_006725832 /// XM_006726017 /// XM_006726018 /// XM_006726019 /// XM_006726020 /// XM_006726021 /// XM_006726022 /// XR_427836 /// XR_430858 /// XR_430938 /// XR_430974 /// XR_431015', 'NM_001278791 /// NM_001278792 /// NM_001278793 /// NM_002914 /// NM_181471 /// XM_006716080', 'NM_002155', 'NM_003466 /// NM_013951 /// NM_013952 /// NM_013953 /// NM_013992', 'NM_000409 /// XM_006715073'], 'Gene Ontology Biological Process': ['0001558 // regulation of cell growth // inferred from electronic annotation /// 0001952 // regulation of cell-matrix adhesion // inferred from electronic annotation /// 0006468 // protein phosphorylation // inferred from electronic annotation /// 0007155 // cell adhesion // traceable author statement /// 0007169 // transmembrane receptor protein tyrosine kinase signaling pathway // inferred from electronic annotation /// 0007565 // female pregnancy // inferred from electronic annotation /// 0007566 // embryo implantation // inferred from electronic annotation /// 0007595 // lactation // inferred from electronic annotation /// 0008285 // negative regulation of cell proliferation // inferred from electronic annotation /// 0010715 // regulation of extracellular matrix disassembly // inferred from mutant phenotype /// 0014909 // smooth muscle cell migration // inferred from mutant phenotype /// 0016310 // phosphorylation // inferred from electronic annotation /// 0018108 // peptidyl-tyrosine phosphorylation // inferred from electronic annotation /// 0030198 // extracellular matrix organization // traceable author statement /// 0038063 // collagen-activated tyrosine kinase receptor signaling pathway // inferred from direct assay /// 0038063 // collagen-activated tyrosine kinase receptor signaling pathway // inferred from mutant phenotype /// 0038083 // peptidyl-tyrosine autophosphorylation // inferred from direct assay /// 0043583 // ear development // inferred from electronic annotation /// 0044319 // wound healing, spreading of cells // inferred from mutant phenotype /// 0046777 // protein autophosphorylation // inferred from direct assay /// 0060444 // branching involved in mammary gland duct morphogenesis // inferred from electronic annotation /// 0060749 // mammary gland alveolus development // inferred from electronic annotation /// 0061302 // smooth muscle cell-matrix adhesion // inferred from mutant phenotype', '0000278 // mitotic cell cycle // traceable author statement /// 0000722 // telomere maintenance via recombination // traceable author statement /// 0000723 // telomere maintenance // traceable author statement /// 0006260 // DNA replication // traceable author statement /// 0006271 // DNA strand elongation involved in DNA replication // traceable author statement /// 0006281 // DNA repair // traceable author statement /// 0006283 // transcription-coupled nucleotide-excision repair // traceable author statement /// 0006289 // nucleotide-excision repair // traceable author statement /// 0006297 // nucleotide-excision repair, DNA gap filling // traceable author statement /// 0015979 // photosynthesis // inferred from electronic annotation /// 0015995 // chlorophyll biosynthetic process // inferred from electronic annotation /// 0032201 // telomere maintenance via semi-conservative replication // traceable author statement', '0000902 // cell morphogenesis // inferred from electronic annotation /// 0006200 // ATP catabolic process // inferred from direct assay /// 0006950 // response to stress // inferred from electronic annotation /// 0006986 // response to unfolded protein // traceable author statement /// 0034605 // cellular response to heat // inferred from direct assay /// 0042026 // protein refolding // inferred from direct assay /// 0070370 // cellular heat acclimation // inferred from mutant phenotype', '0001655 // urogenital system development // inferred from sequence or structural similarity /// 0001656 // metanephros development // inferred from electronic annotation /// 0001658 // branching involved in ureteric bud morphogenesis // inferred from expression pattern /// 0001822 // kidney development // inferred from expression pattern /// 0001823 // mesonephros development // inferred from sequence or structural similarity /// 0003337 // mesenchymal to epithelial transition involved in metanephros morphogenesis // inferred from expression pattern /// 0006351 // transcription, DNA-templated // inferred from direct assay /// 0006355 // regulation of transcription, DNA-templated // inferred from electronic annotation /// 0007275 // multicellular organismal development // inferred from electronic annotation /// 0007417 // central nervous system development // inferred from expression pattern /// 0009653 // anatomical structure morphogenesis // traceable author statement /// 0030154 // cell differentiation // inferred from electronic annotation /// 0030878 // thyroid gland development // inferred from expression pattern /// 0030878 // thyroid gland development // inferred from mutant phenotype /// 0038194 // thyroid-stimulating hormone signaling pathway // traceable author statement /// 0039003 // pronephric field specification // inferred from sequence or structural similarity /// 0042472 // inner ear morphogenesis // inferred from sequence or structural similarity /// 0042981 // regulation of apoptotic process // inferred from sequence or structural similarity /// 0045893 // positive regulation of transcription, DNA-templated // inferred from direct assay /// 0045893 // positive regulation of transcription, DNA-templated // inferred from sequence or structural similarity /// 0045944 // positive regulation of transcription from RNA polymerase II promoter // inferred from direct assay /// 0048793 // pronephros development // inferred from sequence or structural similarity /// 0071371 // cellular response to gonadotropin stimulus // inferred from direct assay /// 0071599 // otic vesicle development // inferred from expression pattern /// 0072050 // S-shaped body morphogenesis // inferred from electronic annotation /// 0072073 // kidney epithelium development // inferred from electronic annotation /// 0072108 // positive regulation of mesenchymal to epithelial transition involved in metanephros morphogenesis // inferred from sequence or structural similarity /// 0072164 // mesonephric tubule development // inferred from electronic annotation /// 0072207 // metanephric epithelium development // inferred from expression pattern /// 0072221 // metanephric distal convoluted tubule development // inferred from sequence or structural similarity /// 0072278 // metanephric comma-shaped body morphogenesis // inferred from expression pattern /// 0072284 // metanephric S-shaped body morphogenesis // inferred from expression pattern /// 0072289 // metanephric nephron tubule formation // inferred from sequence or structural similarity /// 0072305 // negative regulation of mesenchymal cell apoptotic process involved in metanephric nephron morphogenesis // inferred from sequence or structural similarity /// 0072307 // regulation of metanephric nephron tubule epithelial cell differentiation // inferred from sequence or structural similarity /// 0090190 // positive regulation of branching involved in ureteric bud morphogenesis // inferred from sequence or structural similarity /// 1900212 // negative regulation of mesenchymal cell apoptotic process involved in metanephros development // inferred from sequence or structural similarity /// 1900215 // negative regulation of apoptotic process involved in metanephric collecting duct development // inferred from sequence or structural similarity /// 1900218 // negative regulation of apoptotic process involved in metanephric nephron tubule development // inferred from sequence or structural similarity /// 2000594 // positive regulation of metanephric DCT cell differentiation // inferred from sequence or structural similarity /// 2000611 // positive regulation of thyroid hormone generation // inferred from mutant phenotype /// 2000612 // regulation of thyroid-stimulating hormone secretion // inferred from mutant phenotype', '0007165 // signal transduction // non-traceable author statement /// 0007601 // visual perception // inferred from electronic annotation /// 0007602 // phototransduction // inferred from electronic annotation /// 0007603 // phototransduction, visible light // traceable author statement /// 0016056 // rhodopsin mediated signaling pathway // traceable author statement /// 0022400 // regulation of rhodopsin mediated signaling pathway // traceable author statement /// 0030828 // positive regulation of cGMP biosynthetic process // inferred from electronic annotation /// 0031282 // regulation of guanylate cyclase activity // inferred from electronic annotation /// 0031284 // positive regulation of guanylate cyclase activity // inferred from electronic annotation /// 0050896 // response to stimulus // inferred from electronic annotation'], 'Gene Ontology Cellular Component': ['0005576 // extracellular region // inferred from electronic annotation /// 0005615 // extracellular space // inferred from direct assay /// 0005886 // plasma membrane // traceable author statement /// 0005887 // integral component of plasma membrane // traceable author statement /// 0016020 // membrane // inferred from electronic annotation /// 0016021 // integral component of membrane // inferred from electronic annotation /// 0043235 // receptor complex // inferred from direct assay /// 0070062 // extracellular vesicular exosome // inferred from direct assay', '0005634 // nucleus // inferred from electronic annotation /// 0005654 // nucleoplasm // traceable author statement /// 0005663 // DNA replication factor C complex // inferred from direct assay', '0005737 // cytoplasm // inferred from direct assay /// 0005814 // centriole // inferred from direct assay /// 0005829 // cytosol // inferred from direct assay /// 0008180 // COP9 signalosome // inferred from direct assay /// 0070062 // extracellular vesicular exosome // inferred from direct assay /// 0072562 // blood microparticle // inferred from direct assay', '0005634 // nucleus // inferred from direct assay /// 0005654 // nucleoplasm // inferred from sequence or structural similarity /// 0005730 // nucleolus // inferred from direct assay', '0001750 // photoreceptor outer segment // inferred from electronic annotation /// 0001917 // photoreceptor inner segment // inferred from electronic annotation /// 0005578 // proteinaceous extracellular matrix // inferred from electronic annotation /// 0005886 // plasma membrane // inferred from direct assay /// 0016020 // membrane // inferred from electronic annotation /// 0097381 // photoreceptor disc membrane // traceable author statement'], 'Gene Ontology Molecular Function': ['0000166 // nucleotide binding // inferred from electronic annotation /// 0004672 // protein kinase activity // inferred from electronic annotation /// 0004713 // protein tyrosine kinase activity // inferred from electronic annotation /// 0004714 // transmembrane receptor protein tyrosine kinase activity // traceable author statement /// 0005515 // protein binding // inferred from physical interaction /// 0005518 // collagen binding // inferred from direct assay /// 0005518 // collagen binding // inferred from mutant phenotype /// 0005524 // ATP binding // inferred from electronic annotation /// 0016301 // kinase activity // inferred from electronic annotation /// 0016740 // transferase activity // inferred from electronic annotation /// 0016772 // transferase activity, transferring phosphorus-containing groups // inferred from electronic annotation /// 0038062 // protein tyrosine kinase collagen receptor activity // inferred from direct assay /// 0046872 // metal ion binding // inferred from electronic annotation', '0000166 // nucleotide binding // inferred from electronic annotation /// 0003677 // DNA binding // inferred from electronic annotation /// 0005515 // protein binding // inferred from physical interaction /// 0005524 // ATP binding // inferred from electronic annotation /// 0016851 // magnesium chelatase activity // inferred from electronic annotation /// 0017111 // nucleoside-triphosphatase activity // inferred from electronic annotation', '0000166 // nucleotide binding // inferred from electronic annotation /// 0005524 // ATP binding // inferred from electronic annotation /// 0019899 // enzyme binding // inferred from physical interaction /// 0031072 // heat shock protein binding // inferred from physical interaction /// 0042623 // ATPase activity, coupled // inferred from direct assay /// 0051082 // unfolded protein binding // inferred from direct assay', '0000979 // RNA polymerase II core promoter sequence-specific DNA binding // inferred from direct assay /// 0003677 // DNA binding // inferred from direct assay /// 0003677 // DNA binding // inferred from mutant phenotype /// 0003700 // sequence-specific DNA binding transcription factor activity // inferred from direct assay /// 0004996 // thyroid-stimulating hormone receptor activity // traceable author statement /// 0005515 // protein binding // inferred from physical interaction /// 0044212 // transcription regulatory region DNA binding // inferred from direct assay', '0005509 // calcium ion binding // inferred from electronic annotation /// 0008048 // calcium sensitive guanylate cyclase activator activity // inferred from electronic annotation /// 0030249 // guanylate cyclase regulator activity // inferred from electronic annotation /// 0046872 // metal ion binding // inferred from electronic annotation']}\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "if requires_gene_mapping:\n",
    "    print(f'''\n",
    "    As a biomedical research team, we are analyzing a gene expression dataset, and find that its row headers are some identifiers related to genes:\n",
    "    {gene_row_ids}\n",
    "    To get the mapping from those identifiers to actual gene symbols, we extracted the gene annotation data from a series in the GEO database, and saved it to a Python dictionary. Please read the dictionary, and decide which key stores the identifiers, and which key stores the gene symbols. Please strictly follow this format in your answer:\n",
    "    identifier_key = 'key_name1'\n",
    "    gene_symbol_key = 'key_name2'\n",
    "\n",
    "    Gene annotation dictionary:\n",
    "    {gene_annotation_summary}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:18.245811669Z",
     "start_time": "2024-01-10T21:40:18.234480277Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if requires_gene_mapping:\n",
    "    identifier_key = 'ID'\n",
    "    gene_symbol_key = 'Gene Symbol'\n",
    "    gene_mapping = get_gene_mapping(gene_annotation, identifier_key, gene_symbol_key)\n",
    "    genetic_data = apply_gene_mapping(genetic_data, gene_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.559860684Z",
     "start_time": "2024-01-10T21:40:18.521711414Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if NORMALIZE_GENE:\n",
    "    genetic_data = normalize_gene_symbols_in_index(genetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.572778564Z",
     "start_time": "2024-01-10T21:40:20.565101065Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data = geo_merge_clinical_genetic_data(selected_clinical_data, genetic_data)\n",
    "# The preprocessing runs through, which means is_available should be True\n",
    "is_available = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.595385887Z",
     "start_time": "2024-01-10T21:40:20.574630883Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged dataset contains 132 samples.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The merged dataset contains {len(merged_data)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.595934649Z",
     "start_time": "2024-01-10T21:40:20.580408525Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the feature 'Inflammatory Disorders', the least common label is '0.0' with 43 occurrences. This represents 32.58% of the dataset.\n",
      "The distribution of the feature 'Inflammatory Disorders' in this dataset is fine.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_trait_biased, merged_data = judge_and_remove_biased_features(merged_data, TRAIT, trait_type=trait_type)\n",
    "is_trait_biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.596022151Z",
     "start_time": "2024-01-10T21:40:20.588443384Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new JSON file was created at: /Users/jacob/Documents/output\\Jake\\Inflammatory-Disorders\\cohort_info.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "if is_available:\n",
    "    save_cohort_info(cohort, JSON_PATH, is_available, is_trait_biased, merged_data, note='')\n",
    "else:\n",
    "    save_cohort_info(cohort, JSON_PATH, is_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.681345468Z",
     "start_time": "2024-01-10T21:40:20.591286171Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data.head()\n",
    "if not is_trait_biased:\n",
    "    merged_data.to_csv(os.path.join(OUTPUT_DIR, cohort + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:22.271683755Z",
     "start_time": "2023-12-31T03:58:22.246557674Z"
    },
    "id": "-MTPhRGxJV7I"
   },
   "source": [
    "### 3. Do regression & Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.694597045Z",
     "start_time": "2024-01-10T21:40:20.642161512Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>is_usable</th>\n",
       "      <th>is_available</th>\n",
       "      <th>is_biased</th>\n",
       "      <th>has_age</th>\n",
       "      <th>has_gender</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSE236924</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>132</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohort_id  is_usable  is_available  is_biased  has_age  has_gender  \\\n",
       "0  GSE236924       True          True      False    False       False   \n",
       "\n",
       "   sample_size note  \n",
       "0          132       "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the information of usable cohorts\n",
    "best_cohort, ranked_df = filter_and_rank_cohorts(JSON_PATH)\n",
    "ranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.907514912Z",
     "start_time": "2024-01-10T21:40:20.907178250Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If both age and gender have available cohorts, select 'age' as the condition.\n",
    "condition = 'Age'\n",
    "filter_column = 'has_' + condition.lower()\n",
    "\n",
    "condition_best_cohort, condition_ranked_df = filter_and_rank_cohorts(JSON_PATH, filter_column)\n",
    "condition_best_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:21.120075804Z",
     "start_time": "2024-01-10T21:40:21.109376558Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>is_usable</th>\n",
       "      <th>is_available</th>\n",
       "      <th>is_biased</th>\n",
       "      <th>has_age</th>\n",
       "      <th>has_gender</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [cohort_id, is_usable, is_available, is_biased, has_age, has_gender, sample_size, note]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_ranked_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:27.295070023Z",
     "start_time": "2024-01-10T21:40:21.338515691Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTPUT_DIR, \u001b[43mcondition_best_cohort\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m))\n\u001b[0;32m      2\u001b[0m merged_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "merged_data = pd.read_csv(os.path.join(OUTPUT_DIR, condition_best_cohort + '.csv'))\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:27.358779256Z",
     "start_time": "2024-01-10T21:40:27.271337819Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Inflammatory Disorders' 'Age'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25928\\4059474308.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Remove the other condition to prevent interference.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmerged_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Gender'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTRAIT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTRAIT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcondition\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5564\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m250.0\u001b[0m   \u001b[1;36m150.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5565\u001b[0m         \u001b[0mfalcon\u001b[0m  \u001b[0mspeed\u001b[0m   \u001b[1;36m320.0\u001b[0m   \u001b[1;36m250.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5566\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5567\u001b[0m         \"\"\"\n\u001b[1;32m-> 5568\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   5569\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5570\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5571\u001b[0m             \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4781\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4783\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4784\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4785\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4787\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4788\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4852\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4853\u001b[0m                 \u001b[1;31m# Check if label doesn't exist along axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4854\u001b[0m                 \u001b[0mlabels_missing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4855\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlabels_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4856\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4858\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4859\u001b[0m                 \u001b[1;31m# GH#45860\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Inflammatory Disorders' 'Age'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Remove the other condition to prevent interference.\n",
    "merged_data = merged_data.drop(columns=['Gender'], errors='ignore').astype('float')\n",
    "\n",
    "X = merged_data.drop(columns=[TRAIT, condition]).values\n",
    "Y = merged_data[TRAIT].values\n",
    "Z = merged_data[condition].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Select the appropriate regression model depending on whether the dataset shows batch effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:27.546590575Z",
     "start_time": "2024-01-10T21:40:27.298495045Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m has_batch_effect \u001b[38;5;241m=\u001b[39m detect_batch_effect(\u001b[43mX\u001b[49m)\n\u001b[0;32m      3\u001b[0m has_batch_effect\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "has_batch_effect = detect_batch_effect(X)\n",
    "has_batch_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:27.546733889Z",
     "start_time": "2024-01-10T21:40:27.535249532Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'has_batch_effect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Select appropriate models based on whether the dataset has batch effect.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# We experiment on two models for each branch. We will decide which one to choose later.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_batch_effect\u001b[49m:\n\u001b[0;32m      5\u001b[0m     model_constructor1 \u001b[38;5;241m=\u001b[39m VariableSelection\n\u001b[0;32m      6\u001b[0m     model_params1 \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodified\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlamda\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3e-4\u001b[39m}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'has_batch_effect' is not defined"
     ]
    }
   ],
   "source": [
    "# Select appropriate models based on whether the dataset has batch effect.\n",
    "# We experiment on two models for each branch. We will decide which one to choose later.\n",
    "\n",
    "if has_batch_effect:\n",
    "    model_constructor1 = VariableSelection\n",
    "    model_params1 = {'modified': True, 'lamda': 3e-4}\n",
    "    model_constructor2 = VariableSelection\n",
    "    model_params2 = {'modified': False}\n",
    "else:\n",
    "    model_constructor1 = Lasso\n",
    "    model_params1 = {'alpha': 1.0, 'random_state': 42}\n",
    "    model_constructor2 = VariableSelection\n",
    "    model_params2 = {'modified': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:30.570471636Z",
     "start_time": "2024-01-10T21:40:27.546295159Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_type = 'binary'  # Remember to set this properly, either 'binary' or 'continuous'\n",
    "cv_mean1, cv_std1 = cross_validation(X, Y, Z, model_constructor1, model_params1, target_type=trait_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:47.575878022Z",
     "start_time": "2024-01-10T21:40:30.570907992Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_mean2, cv_std2 = cross_validation(X, Y, Z, model_constructor2, model_params2, target_type=trait_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:51.663737008Z",
     "start_time": "2024-01-10T21:40:47.576021186Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_X, _ = normalize_data(X)\n",
    "normalized_Z, _ = normalize_data(Z)\n",
    "\n",
    "# Train regression model on the whole dataset to identify significant genes\n",
    "model1 = ResidualizationRegressor(model_constructor1, model_params1)\n",
    "model1.fit(normalized_X, Y, normalized_Z)\n",
    "\n",
    "model2 = ResidualizationRegressor(model_constructor2, model_params2)\n",
    "model2.fit(normalized_X, Y, normalized_Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T04:50:59.072075075Z",
     "start_time": "2023-10-14T04:50:38.739499998Z"
    },
    "id": "EjJrxbvb4nlj"
   },
   "source": [
    "### 4. Discussion and report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:51.673565176Z",
     "start_time": "2024-01-10T21:40:51.665291317Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_cols = merged_data.columns.tolist()\n",
    "feature_cols.remove(TRAIT)\n",
    "\n",
    "threshold = 0.05\n",
    "interpret_result(model1, feature_cols, TRAIT, condition, threshold=threshold, save_output=True,\n",
    "                 output_dir=OUTPUT_DIR, model_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:51.730825913Z",
     "start_time": "2024-01-10T21:40:51.675049728Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interpret_result(model2, feature_cols, TRAIT, condition, threshold=threshold, save_output=True,\n",
    "                 output_dir=OUTPUT_DIR, model_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
