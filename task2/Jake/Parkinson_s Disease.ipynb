{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Gold standard curation: Preprocessing and single-step regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this stage of gold standard curation, we will do the data preprocessing, selection, and single-step regression for the 153 traits in our question set. This file shows the reference steps using the trait \"Breast Cancer\" as an example. The workflow consists of the following steps:\n",
    "\n",
    "1. Preprocess all the cohorts related to this trait. Each cohort should be converted to a tabular form and saved to a csv file, with columns being genetic factors, the trait, and age, gender if available;\n",
    "2. If there exists at least one cohort with age or gender information, conduct regression analysis with genetic features together with age or gender as the regressors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:17.389375573Z",
     "start_time": "2024-01-10T22:35:16.727055346Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Set your preferred name\n",
    "USER = \"Jake\"\n",
    "# Set the data and output directories\n",
    "DATA_ROOT = '/Users/jacob/Documents'\n",
    "OUTPUT_ROOT = '/Users/jacob/Documents/output'\n",
    "TRAIT = 'Parkinsons Disease'\n",
    "\n",
    "OUTPUT_DIR = os.path.join(OUTPUT_ROOT, USER, '-'.join(TRAIT.split()))\n",
    "JSON_PATH = os.path.join(OUTPUT_DIR, \"cohort_info.json\")\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Gene symbol normalization may take 1-2 minutes. You may set it to False for debugging.\n",
    "NORMALIZE_GENE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mygene\n",
    "import io\n",
    "import re\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import numpy as np\n",
    "from typing import Optional, List, Tuple, Union, Any\n",
    "import json\n",
    "from sparse_lmm import VariableSelection\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from typing import Callable, Optional, List, Tuple, Union, Any\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "def get_relevant_filepaths(cohort_dir):\n",
    "    \"\"\"Find the file paths of a SOFT file and a matrix file from the given data directory of a cohort.\n",
    "    If there are multiple SOFT files or matrix files, simply choose the first one. May be replaced by better\n",
    "    strategies later.\n",
    "    \"\"\"\n",
    "    files = os.listdir(cohort_dir)\n",
    "    soft_files = [f for f in files if 'soft' in f.lower()]\n",
    "    matrix_files = [f for f in files if 'matrix' in f.lower()]\n",
    "    assert len(soft_files) > 0 and len(matrix_files) > 0\n",
    "    soft_file_path = os.path.join(cohort_dir, soft_files[0])\n",
    "    matrix_file_path = os.path.join(cohort_dir, matrix_files[0])\n",
    "\n",
    "    return soft_file_path, matrix_file_path\n",
    "\n",
    "def line_generator(source, source_type):\n",
    "    \"\"\"Generator that yields lines from a file or a string.\n",
    "\n",
    "    Parameters:\n",
    "    - source: File path or string content.\n",
    "    - source_type: 'file' or 'string'.\n",
    "    \"\"\"\n",
    "    if source_type == 'file':\n",
    "        with gzip.open(source, 'rt') as f:\n",
    "            for line in f:\n",
    "                yield line.strip()\n",
    "    elif source_type == 'string':\n",
    "        for line in source.split('\\n'):\n",
    "            yield line.strip()\n",
    "    else:\n",
    "        raise ValueError(\"source_type must be 'file' or 'string'\")\n",
    "\n",
    "def filter_content_by_prefix(\n",
    "    source: str,\n",
    "    prefixes_a: List[str],\n",
    "    prefixes_b: Optional[List[str]] = None,\n",
    "    unselect: bool = False,\n",
    "    source_type: str = 'file',\n",
    "    return_df_a: bool = True,\n",
    "    return_df_b: bool = True\n",
    ") -> Tuple[Union[str, pd.DataFrame], Optional[Union[str, pd.DataFrame]]]:\n",
    "    \"\"\"\n",
    "    Filters rows from a file or a list of strings based on specified prefixes.\n",
    "\n",
    "    Parameters:\n",
    "    - source (str): File path or string content to filter.\n",
    "    - prefixes_a (List[str]): Primary list of prefixes to filter by.\n",
    "    - prefixes_b (Optional[List[str]]): Optional secondary list of prefixes to filter by.\n",
    "    - unselect (bool): If True, selects rows that do not start with the specified prefixes.\n",
    "    - source_type (str): 'file' if source is a file path, 'string' if source is a string of text.\n",
    "    - return_df_a (bool): If True, returns filtered content for prefixes_a as a pandas DataFrame.\n",
    "    - return_df_b (bool): If True, and if prefixes_b is provided, returns filtered content for prefixes_b as a pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple: A tuple where the first element is the filtered content for prefixes_a, and the second element is the filtered content for prefixes_b.\n",
    "    \"\"\"\n",
    "    filtered_lines_a = []\n",
    "    filtered_lines_b = []\n",
    "    prefix_set_a = set(prefixes_a)\n",
    "    if prefixes_b is not None:\n",
    "        prefix_set_b = set(prefixes_b)\n",
    "\n",
    "    # Use generator to get lines\n",
    "    for line in line_generator(source, source_type):\n",
    "        matched_a = any(line.startswith(prefix) for prefix in prefix_set_a)\n",
    "        if matched_a != unselect:\n",
    "            filtered_lines_a.append(line)\n",
    "        if prefixes_b is not None:\n",
    "            matched_b = any(line.startswith(prefix) for prefix in prefix_set_b)\n",
    "            if matched_b != unselect:\n",
    "                filtered_lines_b.append(line)\n",
    "\n",
    "    filtered_content_a = '\\n'.join(filtered_lines_a)\n",
    "    if return_df_a:\n",
    "        filtered_content_a = pd.read_csv(io.StringIO(filtered_content_a), delimiter='\\t', low_memory=False, on_bad_lines='skip')\n",
    "    filtered_content_b = None\n",
    "    if filtered_lines_b:\n",
    "        filtered_content_b = '\\n'.join(filtered_lines_b)\n",
    "        if return_df_b:\n",
    "            filtered_content_b = pd.read_csv(io.StringIO(filtered_content_b), delimiter='\\t', low_memory=False, on_bad_lines='skip')\n",
    "\n",
    "    return filtered_content_a, filtered_content_b\n",
    "\n",
    "def get_background_and_clinical_data(file_path,\n",
    "                                     prefixes_a=['!Series_title', '!Series_summary', '!Series_overall_design'],\n",
    "                                     prefixes_b=['!Sample_geo_accession', '!Sample_characteristics_ch1']):\n",
    "    \"\"\"Extract from a matrix file the background information about the dataset, and sample characteristics data\"\"\"\n",
    "    background_info, clinical_data = filter_content_by_prefix(file_path, prefixes_a, prefixes_b, unselect=False,\n",
    "                                                              source_type='file',\n",
    "                                                              return_df_a=False, return_df_b=True)\n",
    "    return background_info, clinical_data\n",
    "\n",
    "def get_unique_values_by_row(dataframe, max_len=30):\n",
    "    \"\"\"\n",
    "    Organize the unique values in each row of the given dataframe, to get a dictionary\n",
    "    :param dataframe:\n",
    "    :param max_len:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if '!Sample_geo_accession' in dataframe.columns:\n",
    "        dataframe = dataframe.drop(columns=['!Sample_geo_accession'])\n",
    "    unique_values_dict = {}\n",
    "    for index, row in dataframe.iterrows():\n",
    "        unique_values = list(row.unique())[:max_len]\n",
    "        unique_values_dict[index] = unique_values\n",
    "    return unique_values_dict\n",
    "\n",
    "def check_rows_and_columns(dataframe, display=False):\n",
    "    \"\"\"\n",
    "    Get the lists of row names and column names of a dataset, and optionally observe them.\n",
    "    :param dataframe:\n",
    "    :param display:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataframe_rows = dataframe.index.tolist()\n",
    "    if display:\n",
    "        print(f\"The dataset has {len(dataframe_rows)} rows, such as {dataframe_rows[:20]}\")\n",
    "    dataframe_cols = dataframe.columns.tolist()\n",
    "    if display:\n",
    "        print(f\"\\nThe dataset has {len(dataframe_cols)} columns, such as {dataframe_cols[:20]}\")\n",
    "    return dataframe_rows, dataframe_cols\n",
    "\n",
    "def preview_df(df, n=5):\n",
    "    return df.head(n).to_dict(orient='list')\n",
    "\n",
    "def xena_convert_trait(row_index: str):\n",
    "    \"\"\"\n",
    "    Convert the trait information from Sample IDs to labels depending on the last two digits.\n",
    "    Tumor types range from 01 - 09, normal types from 10 - 19.\n",
    "    :param row_index: the index value of a row\n",
    "    :return: the converted value\n",
    "    \"\"\"\n",
    "    last_two_digits = int(row_index[-2:])\n",
    "\n",
    "    if 1 <= last_two_digits <= 9:\n",
    "        return 1\n",
    "    elif 10 <= last_two_digits <= 19:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def xena_convert_gender(cell: str):\n",
    "    \"\"\"Convert the cell content about gender to a binary value\n",
    "    \"\"\"\n",
    "    if isinstance(cell, str):\n",
    "        cell = cell.lower()\n",
    "\n",
    "    if cell == \"female\":\n",
    "        return 0\n",
    "    elif cell == \"male\":\n",
    "        return 1\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def xena_convert_age(cell: str):\n",
    "    \"\"\"Convert the cell content about age to a numerical value using regular expression\n",
    "    \"\"\"\n",
    "    match = re.search(r'\\d+', str(cell))\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def xena_select_clinical_features(clinical_df, trait, age_col=None, gender_col=None):\n",
    "    feature_list = []\n",
    "    trait_data = clinical_df.index.to_series().apply(xena_convert_trait).rename(trait)\n",
    "    feature_list.append(trait_data)\n",
    "    if age_col:\n",
    "        age_data = clinical_df[age_col].apply(xena_convert_age).rename(\"Age\")\n",
    "        feature_list.append(age_data)\n",
    "    if gender_col:\n",
    "        gender_data = clinical_df[gender_col].apply(xena_convert_gender).rename(\"Gender\")\n",
    "        feature_list.append(gender_data)\n",
    "    selected_clinical_df = pd.concat(feature_list, axis=1)\n",
    "    return selected_clinical_df\n",
    "\n",
    "def normalize_gene_symbols(gene_symbols, batch_size=1000):\n",
    "    \"\"\"Normalize human gene symbols in batches using the 'mygenes' library\"\"\"\n",
    "    mg = mygene.MyGeneInfo()\n",
    "    normalized_genes = {}\n",
    "\n",
    "    # Process in batches\n",
    "    for i in range(0, len(gene_symbols), batch_size):\n",
    "        batch = gene_symbols[i:i + batch_size]\n",
    "        results = mg.querymany(batch, scopes='symbol', fields='symbol', species='human')\n",
    "\n",
    "        # Update the normalized_genes dictionary with results from this batch\n",
    "        for gene in results:\n",
    "            normalized_genes[gene['query']] = gene.get('symbol', None)\n",
    "\n",
    "    # Return the normalized symbols in the same order as the input\n",
    "    return [normalized_genes.get(symbol) for symbol in gene_symbols]\n",
    "\n",
    "def normalize_gene_symbols_in_index(gene_df):\n",
    "    \"\"\"Normalize the human gene symbols at the index of a dataframe, and replace the index with its normalized version.\n",
    "    Remove the rows where the index failed to be normalized.\"\"\"\n",
    "    normalized_gene_list = normalize_gene_symbols(gene_df.index.tolist())\n",
    "    assert len(normalized_gene_list) == len(gene_df.index)\n",
    "    gene_df.index = normalized_gene_list\n",
    "    gene_df = gene_df[gene_df.index.notnull()]\n",
    "    return gene_df\n",
    "\n",
    "def judge_binary_variable_biased(dataframe, col_name, min_proportion=0.1, min_num=5):\n",
    "    \"\"\"\n",
    "    Check if the distribution of a binary variable in the dataset is too biased to be usable for analysis\n",
    "    :param dataframe:\n",
    "    :param col_name:\n",
    "    :param min_proportion:\n",
    "    :param min_num:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    label_counter = dataframe[col_name].value_counts()\n",
    "    total_samples = len(dataframe)\n",
    "    rare_label_num = label_counter.min()\n",
    "    rare_label = label_counter.idxmin()\n",
    "    rare_label_proportion = rare_label_num / total_samples\n",
    "\n",
    "    print(\n",
    "        f\"For the feature \\'{col_name}\\', the least common label is '{rare_label}' with {rare_label_num} occurrences. This represents {rare_label_proportion:.2%} of the dataset.\")\n",
    "\n",
    "    biased = (len(label_counter) < 2) or ((rare_label_proportion < min_proportion) and (rare_label_num < min_num))\n",
    "    return bool(biased)\n",
    "\n",
    "def judge_continuous_variable_biased(dataframe, col_name):\n",
    "    \"\"\"Check if the distribution of a continuous variable in the dataset is too biased to be usable for analysis.\n",
    "    As a starting point, we consider it biased if all values are the same. For the next step, maybe ask GPT to judge\n",
    "    based on quartile statistics combined with its common sense knowledge about this feature.\n",
    "    \"\"\"\n",
    "    quartiles = dataframe[col_name].quantile([0.25, 0.5, 0.75])\n",
    "    min_value = dataframe[col_name].min()\n",
    "    max_value = dataframe[col_name].max()\n",
    "\n",
    "    # Printing quartile information\n",
    "    print(f\"Quartiles for '{col_name}':\")\n",
    "    print(f\"  25%: {quartiles[0.25]}\")\n",
    "    print(f\"  50% (Median): {quartiles[0.5]}\")\n",
    "    print(f\"  75%: {quartiles[0.75]}\")\n",
    "    print(f\"Min: {min_value}\")\n",
    "    print(f\"Max: {max_value}\")\n",
    "\n",
    "    biased = min_value == max_value\n",
    "\n",
    "    return bool(biased)\n",
    "\n",
    "def judge_and_remove_biased_features(df, trait, trait_type):\n",
    "    assert trait_type in [\"binary\", \"continuous\"], f\"The trait must be either a binary or a continuous variable!\"\n",
    "    if trait_type == \"binary\":\n",
    "        trait_biased = judge_binary_variable_biased(df, trait)\n",
    "    else:\n",
    "        trait_biased = judge_continuous_variable_biased(df, trait)\n",
    "    if trait_biased:\n",
    "        print(f\"The distribution of the feature \\'{trait}\\' in this dataset is severely biased.\\n\")\n",
    "    else:\n",
    "        print(f\"The distribution of the feature \\'{trait}\\' in this dataset is fine.\\n\")\n",
    "    if \"Age\" in df.columns:\n",
    "        age_biased = judge_continuous_variable_biased(df, 'Age')\n",
    "        if age_biased:\n",
    "            print(f\"The distribution of the feature \\'Age\\' in this dataset is severely biased.\\n\")\n",
    "            df = df.drop(columns='Age')\n",
    "        else:\n",
    "            print(f\"The distribution of the feature \\'Age\\' in this dataset is fine.\\n\")\n",
    "    if \"Gender\" in df.columns:\n",
    "        gender_biased = judge_binary_variable_biased(df, 'Gender')\n",
    "        if gender_biased:\n",
    "            print(f\"The distribution of the feature \\'Gender\\' in this dataset is severely biased.\\n\")\n",
    "            df = df.drop(columns='Gender')\n",
    "        else:\n",
    "            print(f\"The distribution of the feature \\'Gender\\' in this dataset is fine.\\n\")\n",
    "\n",
    "    return trait_biased, df\n",
    "\n",
    "def save_cohort_info(cohort: str, info_path: str, is_available: bool, is_biased: Optional[bool] = None,\n",
    "                     df: Optional[pd.DataFrame] = None, note: str = '') -> None:\n",
    "    \"\"\"\n",
    "    Add or update information about the usability and quality of a dataset for statistical analysis.\n",
    "\n",
    "    Parameters:\n",
    "    cohort (str): A unique identifier for the dataset.\n",
    "    info_path (str): File path to the JSON file where records are stored.\n",
    "    is_available (bool): Indicates whether both the genetic data and trait data are available in the dataset, and can be\n",
    "     preprocessed into a dataframe.\n",
    "    is_biased (bool, optional): Indicates whether the dataset is too biased to be usable.\n",
    "        Required if `is_available` is True.\n",
    "    df (pandas.DataFrame, optional): The preprocessed dataset. Required if `is_available` is True.\n",
    "    note (str, optional): Additional notes about the dataset.\n",
    "\n",
    "    Returns:\n",
    "    None: The function does not return a value but updates or creates a record in the specified JSON file.\n",
    "    \"\"\"\n",
    "    if is_available:\n",
    "        assert (df is not None) and (is_biased is not None), \"'df' and 'is_biased' should be provided if this cohort \" \\\n",
    "                                                             \"is relevant.\"\n",
    "    is_usable = is_available and (not is_biased)\n",
    "    new_record = {\"is_usable\": is_usable,\n",
    "                  \"is_available\": is_available,\n",
    "                  \"is_biased\": is_biased if is_available else None,\n",
    "                  \"has_age\": \"Age\" in df.columns if is_available else None,\n",
    "                  \"has_gender\": \"Gender\" in df.columns if is_available else None,\n",
    "                  \"sample_size\": len(df) if is_available else None,\n",
    "                  \"note\": note}\n",
    "\n",
    "    if not os.path.exists(info_path):\n",
    "        with open(info_path, 'w') as file:\n",
    "            json.dump({}, file)\n",
    "        print(f\"A new JSON file was created at: {info_path}\")\n",
    "\n",
    "    with open(info_path, \"r\") as file:\n",
    "        records = json.load(file)\n",
    "    records[cohort] = new_record\n",
    "\n",
    "    temp_path = info_path + \".tmp\"\n",
    "    try:\n",
    "        with open(temp_path, 'w') as file:\n",
    "            json.dump(records, file)\n",
    "        os.replace(temp_path, info_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "        raise\n",
    "\n",
    "def get_feature_data(clinical_df, row_id, feature, convert_fn):\n",
    "    \"\"\"select the row corresponding to a feature in the sample characteristics dataframe, and convert the feature into\n",
    "    a binary or continuous variable\"\"\"\n",
    "    clinical_df = clinical_df.iloc[row_id:row_id + 1].drop(columns=['!Sample_geo_accession'], errors='ignore')\n",
    "    clinical_df.index = [feature]\n",
    "    clinical_df = clinical_df.applymap(convert_fn)\n",
    "\n",
    "    return clinical_df\n",
    "\n",
    "def geo_select_clinical_features(clinical_df: pd.DataFrame, trait: str, trait_row: int,\n",
    "                                 convert_trait: Callable,\n",
    "                                 age_row: Optional[int] = None,\n",
    "                                 convert_age: Optional[Callable] = None,\n",
    "                                 gender_row: Optional[int] = None,\n",
    "                                 convert_gender: Optional[Callable] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts and processes specific clinical features from a DataFrame representing\n",
    "    sample characteristics in the GEO database series.\n",
    "\n",
    "    Parameters:\n",
    "    - clinical_df (pd.DataFrame): DataFrame containing clinical data.\n",
    "    - trait (str): The trait of interest.\n",
    "    - trait_row (int): Row identifier for the trait in the DataFrame.\n",
    "    - convert_trait (Callable): Function to convert trait data into a desired format.\n",
    "    - age_row (int, optional): Row identifier for age data. Default is None.\n",
    "    - convert_age (Callable, optional): Function to convert age data. Default is None.\n",
    "    - gender_row (int, optional): Row identifier for gender data. Default is None.\n",
    "    - convert_gender (Callable, optional): Function to convert gender data. Default is None.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the selected and processed clinical features.\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "\n",
    "    trait_data = get_feature_data(clinical_df, trait_row, trait, convert_trait)\n",
    "    feature_list.append(trait_data)\n",
    "    if age_row is not None:\n",
    "        age_data = get_feature_data(clinical_df, age_row, 'Age', convert_age)\n",
    "        feature_list.append(age_data)\n",
    "    if gender_row is not None:\n",
    "        gender_data = get_feature_data(clinical_df, gender_row, 'Gender', convert_gender)\n",
    "        feature_list.append(gender_data)\n",
    "\n",
    "    selected_clinical_df = pd.concat(feature_list, axis=0)\n",
    "    return selected_clinical_df\n",
    "\n",
    "def get_genetic_data(file_path):\n",
    "    \"\"\"Read the gene expression data into a dataframe, and adjust its format\"\"\"\n",
    "    genetic_data = pd.read_csv(file_path, compression='gzip', skiprows=52, comment='!', delimiter='\\t')\n",
    "    genetic_data = genetic_data.dropna()\n",
    "    genetic_data = genetic_data.rename(columns={'ID_REF': 'ID'}).astype({'ID': 'str'})\n",
    "    genetic_data.set_index('ID', inplace=True)\n",
    "\n",
    "    return genetic_data\n",
    "\n",
    "def get_gene_annotation(file_path, prefixes=['^', '!', '#']):\n",
    "    \"\"\"Extract from a SOFT file the gene annotation data\"\"\"\n",
    "    gene_metadata = filter_content_by_prefix(file_path, prefixes_a=prefixes, unselect=True, source_type='file',\n",
    "                                             return_df_a=True)\n",
    "    return gene_metadata[0]\n",
    "\n",
    "def get_gene_mapping(annotation, prob_col, gene_col):\n",
    "    \"\"\"Process the gene annotation to get the mapping between gene names and gene probes.\n",
    "    \"\"\"\n",
    "    mapping_data = annotation.loc[:, [prob_col, gene_col]]\n",
    "    mapping_data = mapping_data.dropna()\n",
    "    mapping_data = mapping_data.rename(columns={gene_col: 'Gene'}).astype({'ID': 'str'})\n",
    "\n",
    "    return mapping_data\n",
    "\n",
    "def apply_gene_mapping(expression_df, mapping_df):\n",
    "    \"\"\"\n",
    "    Converts measured data about gene probes into gene expression data.\n",
    "    Handles the potential many-to-many relationship between probes and genes.\n",
    "\n",
    "    Parameters:\n",
    "    expression_df (DataFrame): A DataFrame with gene expression data, indexed by 'ID'.\n",
    "    mapping_df (DataFrame): A DataFrame mapping 'ID' to 'Gene', with 'ID' as a column.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame with mean gene expression values, indexed by 'Gene'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a regex pattern for splitting gene names\n",
    "    split_pattern = r';|\\|+|/{2,}|,|\\[|\\]|\\(|\\)'\n",
    "\n",
    "    # Split the 'Gene' column in 'mapping_df' using the regex pattern\n",
    "    mapping_df['Gene'] = mapping_df['Gene'].str.split(split_pattern)\n",
    "    mapping_df = mapping_df.explode('Gene')\n",
    "\n",
    "    # Set 'ID' as the index of 'mapping_df' for merging\n",
    "    mapping_df.set_index('ID', inplace=True)\n",
    "\n",
    "    # Merge 'mapping_df' with 'expression_df' by their indices\n",
    "    merged_df = mapping_df.join(expression_df)\n",
    "\n",
    "    # Group by 'Gene' and calculate the mean expression values\n",
    "    gene_expression_df = merged_df.groupby('Gene').mean().dropna()\n",
    "\n",
    "    return gene_expression_df\n",
    "\n",
    "def geo_merge_clinical_genetic_data(clinical_df, genetic_df):\n",
    "    \"\"\"\n",
    "    Merge the clinical features and gene expression features from two dataframes into one dataframe\n",
    "    \"\"\"\n",
    "    if 'ID' in genetic_df.columns:\n",
    "        genetic_df = genetic_df.rename(columns={'ID': 'Gene'})\n",
    "    if 'Gene' in genetic_df.columns:\n",
    "        genetic_df = genetic_df.set_index('Gene')\n",
    "    merged_data = pd.concat([clinical_df, genetic_df], axis=0).T.dropna()\n",
    "    return merged_data\n",
    "\n",
    "def read_json_to_dataframe(json_file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a JSON file and converts it into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "    json_file (str): The path to the JSON file containing the data.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A pandas DataFrame with the JSON data.\n",
    "    \"\"\"\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return pd.DataFrame.from_dict(data, orient='index').reset_index().rename(columns={'index': 'cohort_id'})\n",
    "\n",
    "def filter_and_rank_cohorts(json_file: str, condition: Union[str, None] = None) -> Tuple[\n",
    "    Union[str, None], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Reads a JSON file, filters cohorts based on usability and an optional condition, then ranks them by sample size.\n",
    "\n",
    "    Args:\n",
    "    json_file (str): The path to the JSON file containing the data.\n",
    "    condition (str, optional): An additional condition for filtering. If None, only 'is_usable' is considered.\n",
    "\n",
    "    Returns:\n",
    "    Tuple: A tuple containing the best cohort ID (str or None if no suitable cohort is found) and\n",
    "           the filtered and ranked DataFrame.\n",
    "    \"\"\"\n",
    "    # Read the JSON file into a DataFrame\n",
    "    df = read_json_to_dataframe(json_file)\n",
    "\n",
    "    if condition:\n",
    "        filtered_df = df[(df['is_usable'] == True) & (df[condition] == True)]\n",
    "    else:\n",
    "        filtered_df = df[df['is_usable'] == True]\n",
    "\n",
    "    ranked_df = filtered_df.sort_values(by='sample_size', ascending=False)\n",
    "    best_cohort_id = ranked_df.iloc[0]['cohort_id'] if not ranked_df.empty else None\n",
    "\n",
    "    return best_cohort_id, ranked_df\n",
    "\n",
    "def detect_batch_effect(X):\n",
    "    \"\"\"\n",
    "    Detect potential batch effects in a dataset using eigenvalues of XX^T.\n",
    "\n",
    "    Args:\n",
    "    X (numpy.ndarray): A feature matrix with shape (n_samples, n_features).\n",
    "\n",
    "    Returns:\n",
    "    bool: True if a potential batch effect is detected, False otherwise.\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    # Computing XX^T\n",
    "    XXt = np.dot(X, X.T)\n",
    "\n",
    "    # Compute the eigenvalues of XX^T\n",
    "    eigen_values = np.linalg.eigvalsh(XXt)  # Using eigvalsh since XX^T is symmetric\n",
    "    eigen_values = sorted(eigen_values, reverse=True)\n",
    "\n",
    "    # Check for large gaps in the eigenvalues\n",
    "    for i in range(len(eigen_values) - 1):\n",
    "        gap = eigen_values[i] - eigen_values[i + 1]\n",
    "        if gap > 1 / n_samples:  # You may need to adjust this threshold\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def normalize_data(X_train, X_test=None):\n",
    "    \"\"\"Compute the mean and standard deviation statistics of the training data, use them to normalize the training data,\n",
    "    and optionally the test data\"\"\"\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    std = np.std(X_train, axis=0)\n",
    "\n",
    "    # Handling columns with std = 0\n",
    "    std_no_zero = np.where(std == 0, 1, std)\n",
    "\n",
    "    # Normalize X_train\n",
    "    X_train_normalized = (X_train - mean) / std_no_zero\n",
    "    # Set normalized values to 0 where std was 0\n",
    "    X_train_normalized[:, std == 0] = 0\n",
    "\n",
    "    if X_test is not None:\n",
    "        X_test_normalized = (X_test - mean) / std_no_zero\n",
    "        X_test_normalized[:, std == 0] = 0\n",
    "    else:\n",
    "        X_test_normalized = None\n",
    "\n",
    "    return X_train_normalized, X_test_normalized\n",
    "\n",
    "\n",
    "class ResidualizationRegressor:\n",
    "    def __init__(self, regression_model_constructor, params=None):\n",
    "        if params is None:\n",
    "            params = {}\n",
    "        self.regression_model = regression_model_constructor(**params)\n",
    "        self.beta_Z = None  # Coefficients for regression of Y on Z\n",
    "        self.beta_X = None  # Coefficients for regression of residual on X\n",
    "        self.neg_log_p_values = None  # Negative logarithm of p-values\n",
    "        self.p_values = None  # Actual p-values\n",
    "\n",
    "    def _reshape_data(self, data):\n",
    "        \"\"\"\n",
    "        Reshape the data to ensure it's in the correct format (2D array).\n",
    "\n",
    "        :param data: The input data (can be 1D or 2D array).\n",
    "        :return: Reshaped 2D array.\n",
    "        \"\"\"\n",
    "        if data.ndim == 1:\n",
    "            return data.reshape(-1, 1)\n",
    "        return data\n",
    "\n",
    "    def _reshape_output(self, data):\n",
    "        \"\"\"\n",
    "        Reshape the output data to ensure it's in the correct format (1D array).\n",
    "\n",
    "        :param data: The output data (can be 1D or 2D array).\n",
    "        :return: Reshaped 1D array.\n",
    "        \"\"\"\n",
    "        if data.ndim == 2 and data.shape[1] == 1:\n",
    "            return data.ravel()\n",
    "        return data\n",
    "\n",
    "    def fit(self, X, Y, Z):\n",
    "        X = self._reshape_data(X)\n",
    "        Y = self._reshape_data(Y)\n",
    "        Z = self._reshape_data(Z)\n",
    "\n",
    "        # Step 1: Linear regression of Y on Z\n",
    "        Z_ones = np.column_stack((np.ones(Z.shape[0]), Z))\n",
    "        self.beta_Z = np.linalg.pinv(Z_ones.T @ Z_ones) @ Z_ones.T @ Y\n",
    "        Y_hat = Z_ones @ self.beta_Z\n",
    "        e_Y = Y - Y_hat  # Residual of Y\n",
    "\n",
    "        # Step 2: Regress the residual on X using the included regression model\n",
    "        self.regression_model.fit(X, e_Y)\n",
    "\n",
    "        # Obtain coefficients from the regression model\n",
    "        if hasattr(self.regression_model, 'coef_'):\n",
    "            self.beta_X = self.regression_model.coef_\n",
    "        elif hasattr(self.regression_model, 'getBeta'):\n",
    "            beta_output = self.regression_model.getBeta()\n",
    "            self.beta_X = self._reshape_output(beta_output)\n",
    "\n",
    "        # Obtain negative logarithm of p-values, if available\n",
    "        if hasattr(self.regression_model, 'getNegLogP'):\n",
    "            neg_log_p_output = self.regression_model.getNegLogP()\n",
    "            if neg_log_p_output is not None:\n",
    "                self.neg_log_p_values = self._reshape_output(neg_log_p_output)\n",
    "                self.p_values = np.exp(-self.neg_log_p_values)\n",
    "                # Concatenate the p-values of Z and X. The p-values of Z were not computed, mark with NaN.\n",
    "                p_values_Z = np.full(Z.shape[1], np.nan)\n",
    "                self.p_values = np.concatenate((p_values_Z, self.p_values))\n",
    "\n",
    "    def predict(self, X, Z):\n",
    "        X = self._reshape_data(X)\n",
    "        Z = self._reshape_data(Z)\n",
    "\n",
    "        Z_ones = np.column_stack((np.ones(Z.shape[0]), Z))\n",
    "        ZX = np.column_stack((Z, X))\n",
    "        combined_beta = np.concatenate((self.beta_Z[1:].ravel(), self.beta_X.ravel()))\n",
    "        return ZX @ combined_beta + self.beta_Z[0]\n",
    "\n",
    "    def get_coefficients(self):\n",
    "        return np.concatenate((self.beta_Z[1:].ravel(), self.beta_X.ravel()))\n",
    "\n",
    "    def get_p_values(self):\n",
    "        return self.p_values\n",
    "\n",
    "    def predict(self, X, Z):\n",
    "        X = self._reshape_data(X)\n",
    "        Z = self._reshape_data(Z)\n",
    "\n",
    "        Z_ones = np.column_stack((np.ones(Z.shape[0]), Z))\n",
    "        ZX = np.column_stack((Z, X))\n",
    "        combined_beta = np.concatenate((self.beta_Z[1:].ravel(), self.beta_X.ravel()))\n",
    "        return ZX @ combined_beta + self.beta_Z[0]\n",
    "\n",
    "    def get_coefficients(self):\n",
    "        return np.concatenate((self.beta_Z[1:].ravel(), self.beta_X.ravel()))\n",
    "\n",
    "    def get_p_values(self):\n",
    "        return self.p_values\n",
    "\n",
    "\n",
    "def cross_validation(X, Y, Z, model_constructor, model_params, k=5, target_type='binary'):\n",
    "    assert target_type in ['binary', 'continuous'], \"The target type must be chosen from 'binary' or 'continuous'\"\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    fold_size = len(X) // k\n",
    "    performances = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Split data into train and test based on the current fold\n",
    "        test_indices = indices[i * fold_size: (i + 1) * fold_size]\n",
    "        train_indices = np.setdiff1d(indices, test_indices)\n",
    "\n",
    "        X_train, X_test = X[train_indices], X[test_indices]\n",
    "        Y_train, Y_test = Y[train_indices], Y[test_indices]\n",
    "        Z_train, Z_test = Z[train_indices], Z[test_indices]\n",
    "\n",
    "        normalized_X_train, normalized_X_test = normalize_data(X_train, X_test)\n",
    "        normalized_Z_train, normalized_Z_test = normalize_data(Z_train, Z_test)\n",
    "\n",
    "        # model = model_constructor(**model_params)\n",
    "        model = ResidualizationRegressor(model_constructor, model_params)\n",
    "        model.fit(normalized_X_train, Y_train, normalized_Z_train)\n",
    "        predictions = model.predict(normalized_X_test, normalized_Z_test)\n",
    "\n",
    "        if target_type == 'binary':\n",
    "            predictions = (predictions > 0.5).astype(int)\n",
    "            Y_test = (Y_test > 0.5).astype(int)\n",
    "            performance = accuracy_score(Y_test, predictions)\n",
    "        elif target_type == 'continuous':\n",
    "            performance = mean_squared_error(Y_test, predictions)\n",
    "\n",
    "        performances.append(performance)\n",
    "\n",
    "    cv_mean = np.mean(performances)\n",
    "    cv_std = np.std(performances)\n",
    "\n",
    "    if target_type == 'binary':\n",
    "        print(f'The cross-validation accuracy is {(cv_mean * 100):.2f}% ± {(cv_std * 100):.2f}%')\n",
    "    else:\n",
    "        print(f'The cross-validation MSE is {(cv_mean * 100):.2f}% ± {(cv_std * 100):.2f}%')\n",
    "\n",
    "    return cv_mean, cv_std\n",
    "\n",
    "def interpret_result(model: Any, feature_names: List[str], trait: str, condition: str,\n",
    "                     threshold: float = 0.05, save_output: bool = True,\n",
    "                     output_dir: str = './output', model_id: int = 1) -> None:\n",
    "    \"\"\"This function interprets and reports the result of a trained linear regression model, where the regressor\n",
    "    consists of one variable about condition and multiple variables about genetic factors.\n",
    "    The function extracts coefficients and p-values from the model, and identifies the significant genes based on\n",
    "    p-values or non-zero coefficients, depending on the availability of p-values.\n",
    "\n",
    "    Parameters:\n",
    "    model (Any): The trained regression Model.\n",
    "    feature_names (List[str]): A list of feature names corresponding to the model's coefficients.\n",
    "    trait (str): The target trait of interest.\n",
    "    condition (str): The specific condition to examine within the model.\n",
    "    threshold (float): Significance level for p-value correction. Defaults to 0.05.\n",
    "    save_output (bool): Flag to determine whether to save the output to a file. Defaults to True.\n",
    "    output_dir (str): Directory path where output files are saved. Defaults to './output'.\n",
    "    model_id (int): The index of the model, 1 or 2.\n",
    "\n",
    "    Returns:\n",
    "    None: This function does not return anything but prints and optionally saves the output.\n",
    "    \"\"\"\n",
    "    coefficients = model.get_coefficients().reshape(-1).tolist()\n",
    "    p_values = model.get_p_values()\n",
    "    if p_values is None:\n",
    "        regression_df = pd.DataFrame({\n",
    "            'Variable': feature_names,\n",
    "            'Coefficient': coefficients\n",
    "        })\n",
    "    else:\n",
    "        regression_df = pd.DataFrame({\n",
    "            'Variable': feature_names,\n",
    "            'Coefficient': coefficients,\n",
    "            'p_value': p_values.reshape(-1).tolist()\n",
    "        })\n",
    "\n",
    "    condition_effect = regression_df[regression_df['Variable'] == condition].iloc[0]\n",
    "\n",
    "    print(f\"Effect of the condition on the target variable:\")\n",
    "    print(f\"Variable: {condition}\")\n",
    "    print(f\"Coefficient: {condition_effect['Coefficient']:.4f}\")\n",
    "    gene_regression_df = regression_df[regression_df['Variable'] != condition]\n",
    "    if p_values is None:\n",
    "        gene_regression_df['Absolute Coefficient'] = gene_regression_df['Coefficient'].abs()\n",
    "        significant_genes = gene_regression_df[gene_regression_df['Coefficient'] != 0]\n",
    "        significant_genes_sorted = significant_genes.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "        print(\n",
    "            f\"Found {len(significant_genes_sorted)} genes with non-zero coefficients associated with the trait '{trait}' \"\n",
    "            f\"conditional on the factor '{condition}'. These genes are identified as significant based on the regression model.\")\n",
    "    else:\n",
    "        # Apply the Benjamini-Hochberg correction, to get the corrected p-values\n",
    "        corrected_p_values = multipletests(gene_regression_df['p_value'], alpha=threshold, method='fdr_bh')[1]\n",
    "        gene_regression_df.loc[:, 'corrected_p_value'] = corrected_p_values\n",
    "        significant_genes = gene_regression_df.loc[gene_regression_df['corrected_p_value'] < threshold]\n",
    "        significant_genes_sorted = significant_genes.sort_values('corrected_p_value')\n",
    "        print(\n",
    "            f\"Found {len(significant_genes_sorted)} significant genes associated with the trait '{trait}' conditional on \"\n",
    "            f\"the factor '{condition}', with corrected p-value < {threshold}:\")\n",
    "\n",
    "    print(significant_genes_sorted.to_string(index=False))\n",
    "\n",
    "    # Optionally, save this to a CSV file\n",
    "    if save_output:\n",
    "        significant_genes_sorted.to_csv(\n",
    "            os.path.join(output_dir, f'significant_genes_condition_{condition}_{model_id}.csv'), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2. Data preprocessing and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T21:28:38.028916303Z",
     "start_time": "2023-12-28T21:28:38.016245426Z"
    },
    "collapsed": false
   },
   "source": [
    "## 2.2. The GEO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:25:23.253882615Z",
     "start_time": "2023-12-31T03:25:23.244062710Z"
    },
    "collapsed": false
   },
   "source": [
    "In GEO, there may be one or multiple cohorts for a trait. Each cohort is identified by an accession number. We iterate over all accession numbers in the corresponding subdirectory, preprocess the cohort data, and save them to csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:24.501752524Z",
     "start_time": "2024-01-10T22:35:24.482837955Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GSE202665', 'GSE202666', 'GSE202667', 'GSE227990']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'GEO'\n",
    "trait_subdir = \"Parkinson_s-Disease\"\n",
    "\n",
    "trait_path = os.path.join(DATA_ROOT, dataset, trait_subdir)\n",
    "os.listdir(trait_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:39:42.634870142Z",
     "start_time": "2023-12-31T03:39:42.534093295Z"
    },
    "collapsed": false
   },
   "source": [
    "Repeat the below steps for all the accession numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:24.987046441Z",
     "start_time": "2024-01-10T22:35:24.959501373Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/jacob/Documents\\\\GEO\\\\Parkinson_s-Disease\\\\GSE202667\\\\GSE202667_family.soft.gz',\n",
       " '/Users/jacob/Documents\\\\GEO\\\\Parkinson_s-Disease\\\\GSE202667\\\\GSE202667-GPL20844_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE202667\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Initial filtering and clinical data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:25.542978467Z",
     "start_time": "2024-01-10T22:35:25.389340503Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!Series_title\t\"Time-resolved RNA signatures of CD4+ T cells in Parkinson's disease\"\n",
      "!Series_summary\t\"This SuperSeries is composed of the SubSeries listed below.\"\n",
      "!Series_overall_design\t\"Refer to individual Series\"\n"
     ]
    }
   ],
   "source": [
    "background_prefixes = ['!Series_title', '!Series_summary', '!Series_overall_design']\n",
    "clinical_prefixes = ['!Sample_geo_accession', '!Sample_characteristics_ch1']\n",
    "\n",
    "background_info, clinical_data = get_background_and_clinical_data(matrix_file, background_prefixes, clinical_prefixes)\n",
    "print(background_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:25.667635089Z",
     "start_time": "2024-01-10T22:35:25.621258628Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!Sample_geo_accession</th>\n",
       "      <th>GSM6128044</th>\n",
       "      <th>GSM6128045</th>\n",
       "      <th>GSM6128046</th>\n",
       "      <th>GSM6128047</th>\n",
       "      <th>GSM6128048</th>\n",
       "      <th>GSM6128049</th>\n",
       "      <th>GSM6128050</th>\n",
       "      <th>GSM6128051</th>\n",
       "      <th>GSM6128052</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM6128093</th>\n",
       "      <th>GSM6128094</th>\n",
       "      <th>GSM6128095</th>\n",
       "      <th>GSM6128096</th>\n",
       "      <th>GSM6128097</th>\n",
       "      <th>GSM6128098</th>\n",
       "      <th>GSM6128099</th>\n",
       "      <th>GSM6128100</th>\n",
       "      <th>GSM6128101</th>\n",
       "      <th>GSM6128102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!Sample_characteristics_ch1</td>\n",
       "      <td>disease state: Parkinson's disease</td>\n",
       "      <td>disease state: Parkinson's disease</td>\n",
       "      <td>disease state: Parkinson's disease</td>\n",
       "      <td>disease state: Parkinson's disease</td>\n",
       "      <td>disease state: Parkinson's disease</td>\n",
       "      <td>disease state: Parkinson's disease</td>\n",
       "      <td>disease state: Parkinson's disease</td>\n",
       "      <td>disease state: Parkinson's disease</td>\n",
       "      <td>disease state: Parkinson's disease</td>\n",
       "      <td>...</td>\n",
       "      <td>disease state: Healthy Control</td>\n",
       "      <td>disease state: Healthy Control</td>\n",
       "      <td>disease state: Healthy Control</td>\n",
       "      <td>disease state: Healthy Control</td>\n",
       "      <td>disease state: Healthy Control</td>\n",
       "      <td>disease state: Healthy Control</td>\n",
       "      <td>disease state: Healthy Control</td>\n",
       "      <td>disease state: Healthy Control</td>\n",
       "      <td>disease state: Healthy Control</td>\n",
       "      <td>disease state: Healthy Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!Sample_characteristics_ch1</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>...</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "      <td>cell type: CD4+ T cells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!Sample_characteristics_ch1</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>...</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "      <td>gender: male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!Sample_characteristics_ch1</td>\n",
       "      <td>age: 53</td>\n",
       "      <td>age: 53</td>\n",
       "      <td>age: 53</td>\n",
       "      <td>age: 53</td>\n",
       "      <td>age: 53</td>\n",
       "      <td>age: 53</td>\n",
       "      <td>age: 57</td>\n",
       "      <td>age: 57</td>\n",
       "      <td>age: 57</td>\n",
       "      <td>...</td>\n",
       "      <td>age: 66</td>\n",
       "      <td>age: 66</td>\n",
       "      <td>age: 66</td>\n",
       "      <td>age: 66</td>\n",
       "      <td>age: 53</td>\n",
       "      <td>age: 53</td>\n",
       "      <td>age: 53</td>\n",
       "      <td>age: 53</td>\n",
       "      <td>age: 53</td>\n",
       "      <td>age: 53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!Sample_characteristics_ch1</td>\n",
       "      <td>Stage: 1</td>\n",
       "      <td>Stage: 1</td>\n",
       "      <td>Stage: 1</td>\n",
       "      <td>Stage: 1</td>\n",
       "      <td>Stage: 1</td>\n",
       "      <td>Stage: 1</td>\n",
       "      <td>Stage: 1</td>\n",
       "      <td>Stage: 1</td>\n",
       "      <td>Stage: 1</td>\n",
       "      <td>...</td>\n",
       "      <td>Stage: 0 (Healthy Control)</td>\n",
       "      <td>Stage: 0 (Healthy Control)</td>\n",
       "      <td>Stage: 0 (Healthy Control)</td>\n",
       "      <td>Stage: 0 (Healthy Control)</td>\n",
       "      <td>Stage: 0 (Healthy Control)</td>\n",
       "      <td>Stage: 0 (Healthy Control)</td>\n",
       "      <td>Stage: 0 (Healthy Control)</td>\n",
       "      <td>Stage: 0 (Healthy Control)</td>\n",
       "      <td>Stage: 0 (Healthy Control)</td>\n",
       "      <td>Stage: 0 (Healthy Control)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         !Sample_geo_accession                          GSM6128044  \\\n",
       "0  !Sample_characteristics_ch1  disease state: Parkinson's disease   \n",
       "1  !Sample_characteristics_ch1             cell type: CD4+ T cells   \n",
       "2  !Sample_characteristics_ch1                        gender: male   \n",
       "3  !Sample_characteristics_ch1                             age: 53   \n",
       "4  !Sample_characteristics_ch1                            Stage: 1   \n",
       "\n",
       "                           GSM6128045                          GSM6128046  \\\n",
       "0  disease state: Parkinson's disease  disease state: Parkinson's disease   \n",
       "1             cell type: CD4+ T cells             cell type: CD4+ T cells   \n",
       "2                        gender: male                        gender: male   \n",
       "3                             age: 53                             age: 53   \n",
       "4                            Stage: 1                            Stage: 1   \n",
       "\n",
       "                           GSM6128047                          GSM6128048  \\\n",
       "0  disease state: Parkinson's disease  disease state: Parkinson's disease   \n",
       "1             cell type: CD4+ T cells             cell type: CD4+ T cells   \n",
       "2                        gender: male                        gender: male   \n",
       "3                             age: 53                             age: 53   \n",
       "4                            Stage: 1                            Stage: 1   \n",
       "\n",
       "                           GSM6128049                          GSM6128050  \\\n",
       "0  disease state: Parkinson's disease  disease state: Parkinson's disease   \n",
       "1             cell type: CD4+ T cells             cell type: CD4+ T cells   \n",
       "2                        gender: male                        gender: male   \n",
       "3                             age: 53                             age: 57   \n",
       "4                            Stage: 1                            Stage: 1   \n",
       "\n",
       "                           GSM6128051                          GSM6128052  \\\n",
       "0  disease state: Parkinson's disease  disease state: Parkinson's disease   \n",
       "1             cell type: CD4+ T cells             cell type: CD4+ T cells   \n",
       "2                        gender: male                        gender: male   \n",
       "3                             age: 57                             age: 57   \n",
       "4                            Stage: 1                            Stage: 1   \n",
       "\n",
       "   ...                      GSM6128093                      GSM6128094  \\\n",
       "0  ...  disease state: Healthy Control  disease state: Healthy Control   \n",
       "1  ...         cell type: CD4+ T cells         cell type: CD4+ T cells   \n",
       "2  ...                    gender: male                    gender: male   \n",
       "3  ...                         age: 66                         age: 66   \n",
       "4  ...      Stage: 0 (Healthy Control)      Stage: 0 (Healthy Control)   \n",
       "\n",
       "                       GSM6128095                      GSM6128096  \\\n",
       "0  disease state: Healthy Control  disease state: Healthy Control   \n",
       "1         cell type: CD4+ T cells         cell type: CD4+ T cells   \n",
       "2                    gender: male                    gender: male   \n",
       "3                         age: 66                         age: 66   \n",
       "4      Stage: 0 (Healthy Control)      Stage: 0 (Healthy Control)   \n",
       "\n",
       "                       GSM6128097                      GSM6128098  \\\n",
       "0  disease state: Healthy Control  disease state: Healthy Control   \n",
       "1         cell type: CD4+ T cells         cell type: CD4+ T cells   \n",
       "2                    gender: male                    gender: male   \n",
       "3                         age: 53                         age: 53   \n",
       "4      Stage: 0 (Healthy Control)      Stage: 0 (Healthy Control)   \n",
       "\n",
       "                       GSM6128099                      GSM6128100  \\\n",
       "0  disease state: Healthy Control  disease state: Healthy Control   \n",
       "1         cell type: CD4+ T cells         cell type: CD4+ T cells   \n",
       "2                    gender: male                    gender: male   \n",
       "3                         age: 53                         age: 53   \n",
       "4      Stage: 0 (Healthy Control)      Stage: 0 (Healthy Control)   \n",
       "\n",
       "                       GSM6128101                      GSM6128102  \n",
       "0  disease state: Healthy Control  disease state: Healthy Control  \n",
       "1         cell type: CD4+ T cells         cell type: CD4+ T cells  \n",
       "2                    gender: male                    gender: male  \n",
       "3                         age: 53                         age: 53  \n",
       "4      Stage: 0 (Healthy Control)      Stage: 0 (Healthy Control)  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:25.865622581Z",
     "start_time": "2024-01-10T22:35:25.859057718Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [\"disease state: Parkinson's disease\", 'disease state: Healthy Control'],\n",
       " 1: ['cell type: CD4+ T cells'],\n",
       " 2: ['gender: male'],\n",
       " 3: ['age: 53',\n",
       "  'age: 57',\n",
       "  'age: 63',\n",
       "  'age: 75',\n",
       "  'age: 85',\n",
       "  'age: 76',\n",
       "  'age: 69',\n",
       "  'age: 66'],\n",
       " 4: ['Stage: 1', 'Stage: 0 (Healthy Control)', 'Stage: 4', 'Stage: 2.5'],\n",
       " 5: ['time-point post activation: 0 h',\n",
       "  'time-point post activation: 2 h',\n",
       "  'time-point post activation: 4 h',\n",
       "  'time-point post activation: 8 h',\n",
       "  'time-point post activation: 12 h',\n",
       "  'time-point post activation: 24 h']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data_unique = get_unique_values_by_row(clinical_data)\n",
    "clinical_data_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:04.978204446Z",
     "start_time": "2023-12-31T03:58:04.922270095Z"
    },
    "collapsed": false
   },
   "source": [
    "Analyze the metadata to determine data relevance and find ways to extract the clinical data.\n",
    "Reference prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:26.257455749Z",
     "start_time": "2024-01-10T22:35:26.245215578Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a biomedical research team, we are selecting datasets to study the association between the human trait \\'Parkinsons Disease\\' and genetic factors, optionally considering the influence of age and gender. After searching the GEO database and parsing the matrix file of a series, we obtained background information and sample characteristics data. We will provide textual information about the dataset background, and a Python dictionary storing a list of unique values for each field of the sample characteristics data. Please carefully review the provided information and answer the following questions about this dataset:\\n1. Does this dataset contain gene expression data? (Note: Pure miRNA data is not suitable.)\\n2. For each of the traits \\'Parkinsons Disease\\', \\'age\\', and \\'gender\\', please address these points:\\n   (1) Is there human data available for this trait?\\n   (2) If so, identify the key in the sample characteristics dictionary where unique values of this trait is recorded. The key is an integer. The trait information might be explicitly recorded, or can be inferred from the field with some biomedical knowledge or understanding about the data collection process.\\n   (3) Choose an appropriate data type (either \\'continuous\\' or \\'binary\\') for each trait. Write a Python function to convert any given value of the trait to this data type. The function should handle inference about the trait value and convert unknown values to None.\\n   Name the functions \\'convert_trait\\', \\'convert_age\\', and \\'convert_gender\\', respectively.\\n\\nBackground information about the dataset:\\n!Series_title\\t\"Time-resolved RNA signatures of CD4+ T cells in Parkinson\\'s disease\"\\n!Series_summary\\t\"This SuperSeries is composed of the SubSeries listed below.\"\\n!Series_overall_design\\t\"Refer to individual Series\"\\n\\nSample characteristics dictionary (from \"!Sample_characteristics_ch1\", converted to a Python dictionary that stores the unique values for each field):\\n{0: [\"disease state: Parkinson\\'s disease\", \\'disease state: Healthy Control\\'], 1: [\\'cell type: CD4+ T cells\\'], 2: [\\'gender: male\\'], 3: [\\'age: 53\\', \\'age: 57\\', \\'age: 63\\', \\'age: 75\\', \\'age: 85\\', \\'age: 76\\', \\'age: 69\\', \\'age: 66\\'], 4: [\\'Stage: 1\\', \\'Stage: 0 (Healthy Control)\\', \\'Stage: 4\\', \\'Stage: 2.5\\'], 5: [\\'time-point post activation: 0 h\\', \\'time-point post activation: 2 h\\', \\'time-point post activation: 4 h\\', \\'time-point post activation: 8 h\\', \\'time-point post activation: 12 h\\', \\'time-point post activation: 24 h\\']}\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'''As a biomedical research team, we are selecting datasets to study the association between the human trait \\'{TRAIT}\\' and genetic factors, optionally considering the influence of age and gender. After searching the GEO database and parsing the matrix file of a series, we obtained background information and sample characteristics data. We will provide textual information about the dataset background, and a Python dictionary storing a list of unique values for each field of the sample characteristics data. Please carefully review the provided information and answer the following questions about this dataset:\n",
    "1. Does this dataset contain gene expression data? (Note: Pure miRNA data is not suitable.)\n",
    "2. For each of the traits \\'{TRAIT}\\', 'age', and 'gender', please address these points:\n",
    "   (1) Is there human data available for this trait?\n",
    "   (2) If so, identify the key in the sample characteristics dictionary where unique values of this trait is recorded. The key is an integer. The trait information might be explicitly recorded, or can be inferred from the field with some biomedical knowledge or understanding about the data collection process.\n",
    "   (3) Choose an appropriate data type (either 'continuous' or 'binary') for each trait. Write a Python function to convert any given value of the trait to this data type. The function should handle inference about the trait value and convert unknown values to None.\n",
    "   Name the functions 'convert_trait', 'convert_age', and 'convert_gender', respectively.\n",
    "\n",
    "Background information about the dataset:\n",
    "{background_info}\n",
    "\n",
    "Sample characteristics dictionary (from \"!Sample_characteristics_ch1\", converted to a Python dictionary that stores the unique values for each field):\n",
    "{clinical_data_unique}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:04.978240504Z",
     "start_time": "2023-12-31T03:58:04.922365324Z"
    },
    "collapsed": false
   },
   "source": [
    "Understand and verify the answer from GPT, to assign values to the below variables. Assign None to the 'row_id' variables if relevant data row was not found.\n",
    "Later we need to let GPT format its answer to automatically do these. But given the complexity of this step, let's grow some insight from the free-text answers for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:26.880553410Z",
     "start_time": "2024-01-10T22:35:26.874815564Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_gene_availabe = True\n",
    "trait_row = 0\n",
    "age_row = 3\n",
    "gender_row = 2\n",
    "\n",
    "trait_type = 'binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:27.115159871Z",
     "start_time": "2024-01-10T22:35:27.104408551Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_available = is_gene_availabe and (trait_row is not None)\n",
    "if not is_available:\n",
    "    save_cohort_info(cohort, JSON_PATH, is_available)\n",
    "    print(\"This cohort is not usable. Please skip the following steps and jump to the next accession number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:27.501693674Z",
     "start_time": "2024-01-10T22:35:27.497272055Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_trait(disease_string):\n",
    "    \"\"\"\n",
    "    Convert disease string to a binary value representing low grade glioma and glioblastoma.\n",
    "    Presence of low grade glioma and glioblastoma is represented as 1, absence as 0.\n",
    "    Unknown or non-breast cancer histologies are converted to None.\n",
    "    \"\"\"\n",
    "    if \"Parkinson's disease\" in disease_string:\n",
    "        return 1\n",
    "    elif 'Healthy Control' in disease_string:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def convert_age(age_string):\n",
    "    \"\"\"\n",
    "    Convert age string to a continuous numerical value.\n",
    "    Unknown values are converted to None.\n",
    "    \"\"\"\n",
    "    if age_string.lower() == 'n.a.':\n",
    "        return None\n",
    "    try:\n",
    "        # Extract age as an integer from the string\n",
    "        age = int(age_string.split(': ')[1])\n",
    "        return age\n",
    "    except (ValueError, IndexError):\n",
    "        # In case of any format error or unexpected string structure\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def convert_gender(value):\n",
    "    \"\"\"\n",
    "    Convert the value to binary data type for gender.\n",
    "    'Sex: male' -> True\n",
    "    'Sex: female' -> False\n",
    "    Unknown or other values -> None\n",
    "    \"\"\"\n",
    "    if value == 'gender: male':\n",
    "        return True\n",
    "    elif value == 'gender: female':\n",
    "        return False\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:27.766905953Z",
     "start_time": "2024-01-10T22:35:27.724446061Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\AppData\\Local\\Temp\\ipykernel_3040\\2288027067.py:344: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  clinical_df = clinical_df.applymap(convert_fn)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp\\ipykernel_3040\\2288027067.py:344: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  clinical_df = clinical_df.applymap(convert_fn)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp\\ipykernel_3040\\2288027067.py:344: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  clinical_df = clinical_df.applymap(convert_fn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSM6128044</th>\n",
       "      <th>GSM6128045</th>\n",
       "      <th>GSM6128046</th>\n",
       "      <th>GSM6128047</th>\n",
       "      <th>GSM6128048</th>\n",
       "      <th>GSM6128049</th>\n",
       "      <th>GSM6128050</th>\n",
       "      <th>GSM6128051</th>\n",
       "      <th>GSM6128052</th>\n",
       "      <th>GSM6128053</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM6128093</th>\n",
       "      <th>GSM6128094</th>\n",
       "      <th>GSM6128095</th>\n",
       "      <th>GSM6128096</th>\n",
       "      <th>GSM6128097</th>\n",
       "      <th>GSM6128098</th>\n",
       "      <th>GSM6128099</th>\n",
       "      <th>GSM6128100</th>\n",
       "      <th>GSM6128101</th>\n",
       "      <th>GSM6128102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parkinsons Disease</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    GSM6128044  GSM6128045  GSM6128046  GSM6128047  \\\n",
       "Parkinsons Disease           1           1           1           1   \n",
       "Age                         53          53          53          53   \n",
       "Gender                       1           1           1           1   \n",
       "\n",
       "                    GSM6128048  GSM6128049  GSM6128050  GSM6128051  \\\n",
       "Parkinsons Disease           1           1           1           1   \n",
       "Age                         53          53          57          57   \n",
       "Gender                       1           1           1           1   \n",
       "\n",
       "                    GSM6128052  GSM6128053  ...  GSM6128093  GSM6128094  \\\n",
       "Parkinsons Disease           1           1  ...           0           0   \n",
       "Age                         57          57  ...          66          66   \n",
       "Gender                       1           1  ...           1           1   \n",
       "\n",
       "                    GSM6128095  GSM6128096  GSM6128097  GSM6128098  \\\n",
       "Parkinsons Disease           0           0           0           0   \n",
       "Age                         66          66          53          53   \n",
       "Gender                       1           1           1           1   \n",
       "\n",
       "                    GSM6128099  GSM6128100  GSM6128101  GSM6128102  \n",
       "Parkinsons Disease           0           0           0           0  \n",
       "Age                         53          53          53          53  \n",
       "Gender                       1           1           1           1  \n",
       "\n",
       "[3 rows x 59 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_clinical_data = geo_select_clinical_features(clinical_data, TRAIT, trait_row, convert_trait, age_row=age_row,\n",
    "                                                      convert_age=convert_age, gender_row=gender_row,\n",
    "                                                      convert_gender=convert_gender)\n",
    "selected_clinical_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:04.978664193Z",
     "start_time": "2023-12-31T03:58:04.966117261Z"
    },
    "collapsed": false
   },
   "source": [
    "### Genetic data preprocessing and final filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:28.390236406Z",
     "start_time": "2024-01-10T22:35:28.100474737Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSM6128044</th>\n",
       "      <th>GSM6128045</th>\n",
       "      <th>GSM6128046</th>\n",
       "      <th>GSM6128047</th>\n",
       "      <th>GSM6128048</th>\n",
       "      <th>GSM6128049</th>\n",
       "      <th>GSM6128050</th>\n",
       "      <th>GSM6128051</th>\n",
       "      <th>GSM6128052</th>\n",
       "      <th>GSM6128053</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM6128093</th>\n",
       "      <th>GSM6128094</th>\n",
       "      <th>GSM6128095</th>\n",
       "      <th>GSM6128096</th>\n",
       "      <th>GSM6128097</th>\n",
       "      <th>GSM6128098</th>\n",
       "      <th>GSM6128099</th>\n",
       "      <th>GSM6128100</th>\n",
       "      <th>GSM6128101</th>\n",
       "      <th>GSM6128102</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.041915</td>\n",
       "      <td>14.948874</td>\n",
       "      <td>15.122211</td>\n",
       "      <td>14.909551</td>\n",
       "      <td>15.025710</td>\n",
       "      <td>14.936510</td>\n",
       "      <td>15.233353</td>\n",
       "      <td>15.164319</td>\n",
       "      <td>14.989328</td>\n",
       "      <td>14.960833</td>\n",
       "      <td>...</td>\n",
       "      <td>15.096799</td>\n",
       "      <td>15.056032</td>\n",
       "      <td>14.850176</td>\n",
       "      <td>14.859671</td>\n",
       "      <td>15.304689</td>\n",
       "      <td>15.200333</td>\n",
       "      <td>14.829884</td>\n",
       "      <td>14.707132</td>\n",
       "      <td>14.703971</td>\n",
       "      <td>14.747495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.286518</td>\n",
       "      <td>4.136799</td>\n",
       "      <td>4.038174</td>\n",
       "      <td>4.426550</td>\n",
       "      <td>4.344365</td>\n",
       "      <td>4.082068</td>\n",
       "      <td>4.623377</td>\n",
       "      <td>4.249123</td>\n",
       "      <td>4.483723</td>\n",
       "      <td>4.252725</td>\n",
       "      <td>...</td>\n",
       "      <td>4.287737</td>\n",
       "      <td>4.209073</td>\n",
       "      <td>4.430695</td>\n",
       "      <td>4.450587</td>\n",
       "      <td>4.223967</td>\n",
       "      <td>4.432748</td>\n",
       "      <td>4.549448</td>\n",
       "      <td>4.402691</td>\n",
       "      <td>4.481657</td>\n",
       "      <td>4.574302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.189070</td>\n",
       "      <td>4.607924</td>\n",
       "      <td>3.972293</td>\n",
       "      <td>4.269585</td>\n",
       "      <td>4.352344</td>\n",
       "      <td>4.185243</td>\n",
       "      <td>4.299983</td>\n",
       "      <td>4.143780</td>\n",
       "      <td>4.234318</td>\n",
       "      <td>4.112836</td>\n",
       "      <td>...</td>\n",
       "      <td>4.175581</td>\n",
       "      <td>4.137040</td>\n",
       "      <td>4.486673</td>\n",
       "      <td>4.510211</td>\n",
       "      <td>4.225022</td>\n",
       "      <td>4.511184</td>\n",
       "      <td>4.497018</td>\n",
       "      <td>4.381050</td>\n",
       "      <td>4.391122</td>\n",
       "      <td>4.431749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.413795</td>\n",
       "      <td>4.606961</td>\n",
       "      <td>4.344494</td>\n",
       "      <td>4.528238</td>\n",
       "      <td>4.724342</td>\n",
       "      <td>4.470592</td>\n",
       "      <td>4.433586</td>\n",
       "      <td>4.756976</td>\n",
       "      <td>4.343704</td>\n",
       "      <td>4.529971</td>\n",
       "      <td>...</td>\n",
       "      <td>5.082732</td>\n",
       "      <td>4.992251</td>\n",
       "      <td>5.248119</td>\n",
       "      <td>5.047150</td>\n",
       "      <td>4.679911</td>\n",
       "      <td>4.845397</td>\n",
       "      <td>4.838148</td>\n",
       "      <td>4.849301</td>\n",
       "      <td>5.122951</td>\n",
       "      <td>4.963008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.547071</td>\n",
       "      <td>4.643106</td>\n",
       "      <td>4.492584</td>\n",
       "      <td>4.372428</td>\n",
       "      <td>4.676640</td>\n",
       "      <td>4.297519</td>\n",
       "      <td>4.825471</td>\n",
       "      <td>4.628260</td>\n",
       "      <td>4.555112</td>\n",
       "      <td>4.614366</td>\n",
       "      <td>...</td>\n",
       "      <td>4.312833</td>\n",
       "      <td>4.444259</td>\n",
       "      <td>4.605639</td>\n",
       "      <td>4.430050</td>\n",
       "      <td>4.714706</td>\n",
       "      <td>4.680952</td>\n",
       "      <td>4.450228</td>\n",
       "      <td>4.632615</td>\n",
       "      <td>4.660033</td>\n",
       "      <td>4.828656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    GSM6128044  GSM6128045  GSM6128046  GSM6128047  GSM6128048  GSM6128049  \\\n",
       "ID                                                                           \n",
       "1    15.041915   14.948874   15.122211   14.909551   15.025710   14.936510   \n",
       "2     4.286518    4.136799    4.038174    4.426550    4.344365    4.082068   \n",
       "3     4.189070    4.607924    3.972293    4.269585    4.352344    4.185243   \n",
       "4     4.413795    4.606961    4.344494    4.528238    4.724342    4.470592   \n",
       "5     4.547071    4.643106    4.492584    4.372428    4.676640    4.297519   \n",
       "\n",
       "    GSM6128050  GSM6128051  GSM6128052  GSM6128053  ...  GSM6128093  \\\n",
       "ID                                                  ...               \n",
       "1    15.233353   15.164319   14.989328   14.960833  ...   15.096799   \n",
       "2     4.623377    4.249123    4.483723    4.252725  ...    4.287737   \n",
       "3     4.299983    4.143780    4.234318    4.112836  ...    4.175581   \n",
       "4     4.433586    4.756976    4.343704    4.529971  ...    5.082732   \n",
       "5     4.825471    4.628260    4.555112    4.614366  ...    4.312833   \n",
       "\n",
       "    GSM6128094  GSM6128095  GSM6128096  GSM6128097  GSM6128098  GSM6128099  \\\n",
       "ID                                                                           \n",
       "1    15.056032   14.850176   14.859671   15.304689   15.200333   14.829884   \n",
       "2     4.209073    4.430695    4.450587    4.223967    4.432748    4.549448   \n",
       "3     4.137040    4.486673    4.510211    4.225022    4.511184    4.497018   \n",
       "4     4.992251    5.248119    5.047150    4.679911    4.845397    4.838148   \n",
       "5     4.444259    4.605639    4.430050    4.714706    4.680952    4.450228   \n",
       "\n",
       "    GSM6128100  GSM6128101  GSM6128102  \n",
       "ID                                      \n",
       "1    14.707132   14.703971   14.747495  \n",
       "2     4.402691    4.481657    4.574302  \n",
       "3     4.381050    4.391122    4.431749  \n",
       "4     4.849301    5.122951    4.963008  \n",
       "5     4.632615    4.660033    4.828656  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genetic_data = get_genetic_data(matrix_file)\n",
    "genetic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:28.504970777Z",
     "start_time": "2024-01-10T22:35:28.387016747Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_row_ids = genetic_data.index[:20].tolist()\n",
    "gene_row_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:30:41.595335164Z",
     "start_time": "2023-12-31T03:30:41.513232329Z"
    },
    "collapsed": false
   },
   "source": [
    "Check if the gene dataset requires mapping to get the gene symbols corresponding to each data row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Reference prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:28.864348262Z",
     "start_time": "2024-01-10T22:35:28.855656327Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBelow are the row headers of a gene expression dataset in GEO. Based on your biomedical knowledge, are they human gene symbols, or are they some other identifiers that need to be mapped to gene symbols? Your answer should be concluded by starting a new line and strictly following this format:\\nrequires_gene_mapping = (True or False)\\n\\nRow headers:\\n['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'''\n",
    "Below are the row headers of a gene expression dataset in GEO. Based on your biomedical knowledge, are they human gene symbols, or are they some other identifiers that need to be mapped to gene symbols? Your answer should be concluded by starting a new line and strictly following this format:\n",
    "requires_gene_mapping = (True or False)\n",
    "\n",
    "Row headers:\n",
    "{gene_row_ids}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If not required, jump directly to the gene normalization step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:29.247854265Z",
     "start_time": "2024-01-10T22:35:29.243816086Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "requires_gene_mapping = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:32.963372660Z",
     "start_time": "2024-01-10T22:35:29.430087750Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': ['1', '2', '3', '4', '5'], 'COL': ['192', '192', '192', '192', '192'], 'ROW': ['328', '326', '324', '322', '320'], 'NAME': ['GE_BrightCorner', 'DarkCorner', 'DarkCorner', 'A_21_P0014386', 'A_33_P3396872'], 'SPOT_ID': ['GE_BrightCorner', 'DarkCorner', 'DarkCorner', 'A_21_P0014386', 'A_33_P3396872'], 'CONTROL_TYPE': ['pos', 'pos', 'pos', 'FALSE', 'FALSE'], 'REFSEQ': [nan, nan, nan, nan, 'NM_001105533'], 'GB_ACC': [nan, nan, nan, nan, 'NM_001105533'], 'LOCUSLINK_ID': [nan, nan, nan, nan, '79974'], 'GENE_SYMBOL': [nan, nan, nan, nan, 'CPED1'], 'GENE_NAME': [nan, nan, nan, nan, 'cadherin-like and PC-esterase domain containing 1'], 'UNIGENE_ID': [nan, nan, nan, nan, 'Hs.189652'], 'ENSEMBL_ID': [nan, nan, nan, nan, nan], 'TIGR_ID': [nan, nan, nan, nan, nan], 'ACCESSION_STRING': [nan, nan, nan, nan, 'ref|NM_001105533|gb|AK025639|gb|BC030538|tc|THC2601673'], 'CHROMOSOMAL_LOCATION': [nan, nan, nan, 'unmapped', 'chr7:120901888-120901947'], 'CYTOBAND': [nan, nan, nan, nan, 'hs|7q31.31'], 'DESCRIPTION': [nan, nan, nan, nan, 'Homo sapiens cadherin-like and PC-esterase domain containing 1 (CPED1), transcript variant 2, mRNA [NM_001105533]'], 'GO_ID': [nan, nan, nan, nan, 'GO:0005783(endoplasmic reticulum)'], 'SEQUENCE': [nan, nan, nan, 'AATACATGTTTTGGTAAACACTCGGTCAGAGCACCCTCTTTCTGTGGAATCAGACTGGCA', 'GCTTATCTCACCTAATACAGGGACTATGCAACCAAGAAACTGGAAATAAAAACAAAGATA'], 'SPOT_ID.1': [nan, nan, nan, nan, nan]}\n"
     ]
    }
   ],
   "source": [
    "if requires_gene_mapping:\n",
    "    gene_annotation = get_gene_annotation(soft_file)\n",
    "    gene_annotation_summary = preview_df(gene_annotation)\n",
    "    print(gene_annotation_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:04.978931927Z",
     "start_time": "2023-12-31T03:58:04.966328339Z"
    },
    "collapsed": false
   },
   "source": [
    "Observe the first few cells in the ID column of the gene annotation dataframe, to find the names of columns that store the gene probe IDs and gene symbols respectively.\n",
    "Reference prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:33.011996136Z",
     "start_time": "2024-01-10T22:35:32.962171369Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    As a biomedical research team, we are analyzing a gene expression dataset, and find that its row headers are some identifiers related to genes:\n",
      "    ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']\n",
      "    To get the mapping from those identifiers to actual gene symbols, we extracted the gene annotation data from a series in the GEO database, and saved it to a Python dictionary. Please read the dictionary, and decide which key stores the identifiers, and which key stores the gene symbols. Please strictly follow this format in your answer:\n",
      "    identifier_key = 'key_name1'\n",
      "    gene_symbol_key = 'key_name2'\n",
      "\n",
      "    Gene annotation dictionary:\n",
      "    {'ID': ['1', '2', '3', '4', '5'], 'COL': ['192', '192', '192', '192', '192'], 'ROW': ['328', '326', '324', '322', '320'], 'NAME': ['GE_BrightCorner', 'DarkCorner', 'DarkCorner', 'A_21_P0014386', 'A_33_P3396872'], 'SPOT_ID': ['GE_BrightCorner', 'DarkCorner', 'DarkCorner', 'A_21_P0014386', 'A_33_P3396872'], 'CONTROL_TYPE': ['pos', 'pos', 'pos', 'FALSE', 'FALSE'], 'REFSEQ': [nan, nan, nan, nan, 'NM_001105533'], 'GB_ACC': [nan, nan, nan, nan, 'NM_001105533'], 'LOCUSLINK_ID': [nan, nan, nan, nan, '79974'], 'GENE_SYMBOL': [nan, nan, nan, nan, 'CPED1'], 'GENE_NAME': [nan, nan, nan, nan, 'cadherin-like and PC-esterase domain containing 1'], 'UNIGENE_ID': [nan, nan, nan, nan, 'Hs.189652'], 'ENSEMBL_ID': [nan, nan, nan, nan, nan], 'TIGR_ID': [nan, nan, nan, nan, nan], 'ACCESSION_STRING': [nan, nan, nan, nan, 'ref|NM_001105533|gb|AK025639|gb|BC030538|tc|THC2601673'], 'CHROMOSOMAL_LOCATION': [nan, nan, nan, 'unmapped', 'chr7:120901888-120901947'], 'CYTOBAND': [nan, nan, nan, nan, 'hs|7q31.31'], 'DESCRIPTION': [nan, nan, nan, nan, 'Homo sapiens cadherin-like and PC-esterase domain containing 1 (CPED1), transcript variant 2, mRNA [NM_001105533]'], 'GO_ID': [nan, nan, nan, nan, 'GO:0005783(endoplasmic reticulum)'], 'SEQUENCE': [nan, nan, nan, 'AATACATGTTTTGGTAAACACTCGGTCAGAGCACCCTCTTTCTGTGGAATCAGACTGGCA', 'GCTTATCTCACCTAATACAGGGACTATGCAACCAAGAAACTGGAAATAAAAACAAAGATA'], 'SPOT_ID.1': [nan, nan, nan, nan, nan]}\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "if requires_gene_mapping:\n",
    "    print(f'''\n",
    "    As a biomedical research team, we are analyzing a gene expression dataset, and find that its row headers are some identifiers related to genes:\n",
    "    {gene_row_ids}\n",
    "    To get the mapping from those identifiers to actual gene symbols, we extracted the gene annotation data from a series in the GEO database, and saved it to a Python dictionary. Please read the dictionary, and decide which key stores the identifiers, and which key stores the gene symbols. Please strictly follow this format in your answer:\n",
    "    identifier_key = 'key_name1'\n",
    "    gene_symbol_key = 'key_name2'\n",
    "\n",
    "    Gene annotation dictionary:\n",
    "    {gene_annotation_summary}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:33.251224154Z",
     "start_time": "2024-01-10T22:35:33.003183996Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if requires_gene_mapping:\n",
    "    identifier_key = 'ID'\n",
    "    gene_symbol_key = 'GENE_SYMBOL'\n",
    "    gene_mapping = get_gene_mapping(gene_annotation, identifier_key, gene_symbol_key)\n",
    "    genetic_data = apply_gene_mapping(genetic_data, gene_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:44.671811264Z",
     "start_time": "2024-01-10T22:35:33.295037921Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51 input query terms found dup hits:\t[('A2MP1', 2), ('AACSP1', 2), ('AADACL2-AS1', 3), ('AADACP1', 2), ('ABCA11P', 2), ('ABCA17P', 2), ('\n",
      "40 input query terms found no hit:\t['AAED1', 'AARS', 'AATK-AS1', 'ACN9', 'ACPP', 'ACPT', 'ACRC', 'ACTN1-AS1', 'ADCK3', 'ADCK4', 'ADPRHL\n",
      "34 input query terms found dup hits:\t[('ARHGAP5-AS1', 2), ('ARHGEF34P', 2), ('ARHGEF7-AS1', 2), ('ARIH2OS', 2), ('ARMC2-AS1', 2), ('ASB9P\n",
      "137 input query terms found no hit:\t['ARMC4', 'ARNTL', 'ARNTL2', 'ARNTL2-AS1', 'ARSE', 'ASNA1', 'ASUN', 'ATHL1', 'ATP5A1', 'ATP5B', 'ATP\n",
      "17 input query terms found dup hits:\t[('C1QTNF1-AS1', 2), ('C20orf181', 2), ('C21orf62-AS1', 2), ('C3P1', 2), ('CA5BP1', 2), ('CACNA1C-IT\n",
      "254 input query terms found no hit:\t['C17orf102', 'C17orf104', 'C17orf105', 'C17orf112', 'C17orf47', 'C17orf51', 'C17orf53', 'C17orf59',\n",
      "27 input query terms found dup hits:\t[('CD99P1', 3), ('CDR1', 2), ('CDRT15P1', 2), ('CDRT15P2', 2), ('CDRT8', 2), ('CEACAM22P', 2), ('CEC\n",
      "27 input query terms found no hit:\t['CD97', 'CDIPT-AS1', 'CDRT1', 'CEBPA-AS1', 'CECR1', 'CECR5', 'CECR5-AS1', 'CECR6', 'CELSR3-AS1', 'C\n",
      "42 input query terms found dup hits:\t[('CROCCP2', 2), ('CRYBB2P1', 2), ('CSAG4', 3), ('CSN1S2AP', 3), ('CSNK1A1P1', 2), ('CST13P', 2), ('\n",
      "70 input query terms found no hit:\t['CRHR1-IT1', 'CRIPAK', 'CSE1L-AS1', 'CSRP2BP', 'CSTF3-AS1', 'CTAGE5', 'CTB-113P19.1', 'CTB-178M22.2\n",
      "28 input query terms found dup hits:\t[('DPH3P1', 2), ('DPPA2P3', 2), ('DPRXP4', 2), ('DPY19L1P1', 2), ('DPY19L2P1', 2), ('DPY19L2P2', 3),\n",
      "116 input query terms found no hit:\t['DPCR1', 'DPH6-AS1', 'DSCR3', 'DUPD1', 'DUSP13', 'DUSP27', 'DYX1C1', 'EBLN3', 'ECRP', 'EFCAB1', 'EF\n",
      "38 input query terms found dup hits:\t[('FAM224A', 2), ('FAM27B', 2), ('FAM41AY1', 2), ('FAM53B-AS1', 2), ('FAM66A', 2), ('FAM66D', 3), ('\n",
      "154 input query terms found no hit:\t['FAM231A', 'FAM26D', 'FAM26E', 'FAM26F', 'FAM27L', 'FAM35A', 'FAM45A', 'FAM46A', 'FAM46B', 'FAM46C'\n",
      "43 input query terms found dup hits:\t[('GGNBP1', 2), ('GGT8P', 2), ('GLRA4', 2), ('GLUD1P3', 2), ('GLYCAM1', 2), ('GLYCTK-AS1', 2), ('GNR\n",
      "149 input query terms found no hit:\t['GGTA1P', 'GIF', 'GK3P', 'GLTSCR1', 'GLTSCR1L', 'GLTSCR2', 'GLUD1P7', 'GM140', 'GMCL1P1', 'GMDS-AS1\n",
      "31 input query terms found dup hits:\t[('HLA-DRB6', 2), ('HLA-J', 9), ('HLA-L', 7), ('HMGA1P7', 2), ('HMGB3P1', 2), ('HMMR-AS1', 2), ('HOT\n",
      "36 input query terms found no hit:\t['HMHA1', 'HMP19', 'HN1', 'HN1L', 'HNRNPU-AS1', 'HP09025', 'HPVC1', 'HPX-2', 'HRASLS', 'HRASLS2', 'H\n",
      "60 input query terms found dup hits:\t[('KCNMA1-AS3', 2), ('KCNMB2-AS1', 2), ('KDM4A-AS1', 2), ('KIF9-AS1', 2), ('KIR3DX1', 5), ('KLF3-AS1\n",
      "100 input query terms found no hit:\t['KDELC1', 'KDELC2', 'KGFLP1', 'KGFLP2', 'KIAA0020', 'KIAA0100', 'KIAA0101', 'KIAA0125', 'KIAA0141',\n",
      "127 input query terms found dup hits:\t[('LINC00502', 2), ('LINC00508', 2), ('LINC00518', 2), ('LINC00526', 2), ('LINC00534', 2), ('LINC005\n",
      "292 input query terms found no hit:\t['LINC00483', 'LINC00493', 'LINC00514', 'LINC00521', 'LINC00527', 'LINC00535', 'LINC00551', 'LINC005\n",
      "708 input query terms found no hit:\t['LOC100131101', 'LOC100131129', 'LOC100131131', 'LOC100131132', 'LOC100131150', 'LOC100131170', 'LO\n",
      "695 input query terms found no hit:\t['LOC101928103', 'LOC101928106', 'LOC101928108', 'LOC101928114', 'LOC101928115', 'LOC101928117', 'LO\n",
      "8 input query terms found dup hits:\t[('LPAL2', 2), ('LRP5L', 2), ('LRRC37A11P', 2), ('LRRC37A4P', 3), ('LRRC37A5P', 2), ('LRRC37BP1', 2)\n",
      "532 input query terms found no hit:\t['LOC102724791', 'LOC102724792', 'LOC102724794', 'LOC102724795', 'LOC102724809', 'LOC102724810', 'LO\n",
      "31 input query terms found dup hits:\t[('MAGEA8-AS1', 2), ('MAMDC2-AS1', 2), ('MAP3K14-AS1', 2), ('MAPT-AS1', 4), ('MBL1P', 2), ('MCF2L-AS\n",
      "59 input query terms found no hit:\t['MAATS1', 'MAGEA10-MAGEA5', 'MAGI2-IT1', 'MAN1B1-AS1', 'MANEA-AS1', 'MARS', 'MB21D1', 'MCTS2P', 'ME\n",
      "29 input query terms found dup hits:\t[('MTMR9LP', 2), ('MTUS2-AS1', 2), ('MYADML', 2), ('MYHAS', 2), ('NAALADL2-AS1', 2), ('NAPA-AS1', 2)\n",
      "30 input query terms found no hit:\t['MTL5', 'MTSS1L', 'MUC3', 'MUM1', 'MUM1L1', 'MURC', 'MUT', 'MYEOV2', 'MYLPF', 'N6AMT2', 'NACAP1', '\n",
      "33 input query terms found dup hits:\t[('NXF4', 2), ('NXF5', 2), ('OACYLP', 2), ('OFCC1', 2), ('OGFR-AS1', 2), ('OGFRP1', 2), ('OR10J3', 3\n",
      "34 input query terms found no hit:\t['NUPL1', 'NUPL2', 'NUPR1L', 'OBFC1', 'OCLM', 'OCR1', 'ODF3', 'ODF3B', 'ODF3L1', 'ODF3L2', 'OK/SW-CL\n",
      "32 input query terms found dup hits:\t[('PDZRN3-AS1', 2), ('PFN1P2', 2), ('PGM5P2', 2), ('PHKA2-AS1', 2), ('PIN1P1', 2), ('PIP5K1P1', 2), \n",
      "44 input query terms found no hit:\t['PDX1-AS1', 'PDZD3', 'PER4', 'PGCP1', 'PHB', 'PIFO', 'PIH1D3', 'PIK3IP1-AS1', 'PKI55', 'PLA2G16', '\n",
      "25 input query terms found dup hits:\t[('PRORSD1P', 2), ('PRORY', 2), ('PRR34', 2), ('PRR34-AS1', 2), ('PRR7-AS1', 2), ('PRSS30P', 3), ('P\n",
      "39 input query terms found no hit:\t['PROSC', 'PRPF4B', 'PRR26', 'PRR31', 'PRSS42', 'PRSS45', 'PRSS46', 'PRUNE', 'PSMD5-AS1', 'PTCHD2', \n",
      "52 input query terms found dup hits:\t[('RNF138P1', 2), ('ROPN1L-AS1', 2), ('RORB-AS1', 2), ('RP9P', 2), ('RPL13AP17', 2), ('RPL13AP3', 2)\n",
      "36 input query terms found no hit:\t['RNF139-AS1', 'RNF144A-AS1', 'RNF165', 'RNF219', 'RNF219-AS1', 'RNMTL1', 'RPARP-AS1', 'RPL34-AS1', \n",
      "36 input query terms found dup hits:\t[('SIGLEC17P', 2), ('SIGLEC5', 2), ('SLC14A2-AS1', 3), ('SLC25A25-AS1', 2), ('SLC25A3P1', 2), ('SLC2\n",
      "25 input query terms found no hit:\t['SKINTL', 'SKIV2L', 'SKIV2L2', 'SLC22A20', 'SLC26A10', 'SLC2A1-AS1', 'SLC35E2', 'SLC9A3R1', 'SLC9A3\n",
      "23 input query terms found dup hits:\t[('SNRPD2P2', 2), ('SP2-AS1', 2), ('SP3P', 2), ('SPAG5-AS1', 2), ('SPATA41', 2), ('SPRR2C', 2), ('SR\n",
      "45 input query terms found no hit:\t['SOGA1', 'SOGA3', 'SPACA6P', 'SPACA6P-AS', 'SPATA5', 'SPATA5L1', 'SPDYE8P', 'SPERT', 'SPG20', 'SPG2\n",
      "40 input query terms found dup hits:\t[('TCP10L2', 2), ('TEC', 2), ('TEKT4P2', 2), ('TERC', 2), ('TESC-AS1', 2), ('TET2-AS1', 2), ('TEX21P\n",
      "56 input query terms found no hit:\t['TCP10', 'TCTE3', 'TCTEX1D1', 'TCTEX1D2', 'TCTEX1D4', 'TDGF1', 'TEPP', 'TEX33', 'TEX37', 'TEX40', '\n",
      "36 input query terms found dup hits:\t[('TRPC2', 2), ('TRPM2-AS', 2), ('TSPEAR-AS2', 2), ('TSSC2', 2), ('TTC21B-AS1', 2), ('TTC3P1', 2), (\n",
      "58 input query terms found no hit:\t['TRIM78P', 'TROVE2', 'TRY2P', 'TSRM', 'TSSC1', 'TSTA3', 'TTC25', 'TTC26', 'TTC30A', 'TTC30B', 'TTC3\n",
      "2 input query terms found dup hits:\t[('WTAPP1', 2), ('XIRP2-AS1', 2)]\n",
      "923 input query terms found no hit:\t['WISP1', 'WISP2', 'WISP3', 'WRB', 'WTH3DI', 'XKRY2', 'XLOC_014422', 'XLOC_014484', 'XLOC_l2_000001'\n",
      "29 input query terms found dup hits:\t[('XXYLT1-AS2', 2), ('YWHAEP1', 2), ('YWHAEP7', 3), ('YY1P2', 2), ('ZFPM2-AS1', 2), ('ZNF137P', 2), \n",
      "93 input query terms found no hit:\t['XLOC_l2_015659', 'XLOC_l2_015661', 'XLOC_l2_015700', 'XLOC_l2_015703', 'XLOC_l2_015716', 'XLOC_l2_\n",
      "1000 input query terms found no hit:\t['chr10:53059356-53059370', 'chr10:6194216-6194230', 'chr10:6194217-6194230', 'chr10:65132753-651327\n",
      "1000 input query terms found no hit:\t['chr20:33578232-33578216', 'chr20:33578232-33578217', 'chr20:33578253-33578269', 'chr20:33578254-33\n",
      "1000 input query terms found no hit:\t['lnc-ABCD3-4', 'lnc-ABCD4-1', 'lnc-ABCF2-1', 'lnc-ABHD12-1', 'lnc-ABHD12B-1', 'lnc-ABHD12B-2', 'lnc\n",
      "1000 input query terms found no hit:\t['lnc-C10orf68-4', 'lnc-C10orf71-1', 'lnc-C10orf71-2', 'lnc-C10orf85-1', 'lnc-C10orf90-2', 'lnc-C10o\n",
      "1000 input query terms found no hit:\t['lnc-CMTM5-1', 'lnc-CMYA5-1', 'lnc-CNBD1-2', 'lnc-CNBD1-3', 'lnc-CNBD1-4', 'lnc-CNIH-1', 'lnc-CNIH3\n",
      "1000 input query terms found no hit:\t['lnc-FANCF-3', 'lnc-FANCI-1', 'lnc-FANCI-3', 'lnc-FANCL-1', 'lnc-FANCL-2', 'lnc-FANCM-5', 'lnc-FANK\n",
      "1000 input query terms found no hit:\t['lnc-ITSN1-2', 'lnc-ITSN2-1', 'lnc-ITSN2-2', 'lnc-IVNS1ABP-2', 'lnc-IWS1-1', 'lnc-IYD-1', 'lnc-IYD-\n",
      "1000 input query terms found no hit:\t['lnc-NDN-4', 'lnc-NDNL2-1', 'lnc-NDRG4-1', 'lnc-NDST1-1', 'lnc-NDST2-3', 'lnc-NDUFA4-1', 'lnc-NDUFA\n",
      "1000 input query terms found no hit:\t['lnc-PTPN1-2', 'lnc-PTPN14-1', 'lnc-PTPN14-3', 'lnc-PTPN20B-2', 'lnc-PTPN23-1', 'lnc-PTPN23-2', 'ln\n",
      "1000 input query terms found no hit:\t['lnc-SLC2A12-3', 'lnc-SLC2A12-4', 'lnc-SLC2A13-2', 'lnc-SLC2A13-3', 'lnc-SLC2A4RG-1', 'lnc-SLC2A6-1\n",
      "743 input query terms found no hit:\t['lnc-TRPM2-1', 'lnc-TRPM6-4', 'lnc-TRPM7-1', 'lnc-TRPT1-1', 'lnc-TRPT1-2', 'lnc-TRPV1-1', 'lnc-TRPV\n"
     ]
    }
   ],
   "source": [
    "if NORMALIZE_GENE:\n",
    "    genetic_data = normalize_gene_symbols_in_index(genetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:44.723357427Z",
     "start_time": "2024-01-10T22:35:44.679550325Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data = geo_merge_clinical_genetic_data(selected_clinical_data, genetic_data)\n",
    "# The preprocessing runs through, which means is_available should be True\n",
    "is_available = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:44.723686867Z",
     "start_time": "2024-01-10T22:35:44.723207836Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged dataset contains 59 samples.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The merged dataset contains {len(merged_data)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:44.724037948Z",
     "start_time": "2024-01-10T22:35:44.723502019Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the feature 'Parkinsons Disease', the least common label is '1.0' with 29 occurrences. This represents 49.15% of the dataset.\n",
      "The distribution of the feature 'Parkinsons Disease' in this dataset is fine.\n",
      "\n",
      "Quartiles for 'Age':\n",
      "  25%: 57.0\n",
      "  50% (Median): 66.0\n",
      "  75%: 75.0\n",
      "Min: 53.0\n",
      "Max: 85.0\n",
      "The distribution of the feature 'Age' in this dataset is fine.\n",
      "\n",
      "For the feature 'Gender', the least common label is '1.0' with 59 occurrences. This represents 100.00% of the dataset.\n",
      "The distribution of the feature 'Gender' in this dataset is severely biased.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_trait_biased, merged_data = judge_and_remove_biased_features(merged_data, TRAIT, trait_type=trait_type)\n",
    "is_trait_biased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicated that this data set only contains male individuals, which is severly biased and should be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:44.724165548Z",
     "start_time": "2024-01-10T22:35:44.723629008Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new JSON file was created at: /Users/jacob/Documents/output\\Jake\\Parkinsons-Disease\\cohort_info.json\n"
     ]
    }
   ],
   "source": [
    "if is_available:\n",
    "    save_cohort_info(cohort, JSON_PATH, is_available, is_trait_biased, merged_data, note='')\n",
    "else:\n",
    "    save_cohort_info(cohort, JSON_PATH, is_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:44.851270613Z",
     "start_time": "2024-01-10T22:35:44.723865072Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data.head()\n",
    "if not is_trait_biased:\n",
    "    merged_data.to_csv(os.path.join(OUTPUT_DIR, cohort + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:22.271683755Z",
     "start_time": "2023-12-31T03:58:22.246557674Z"
    },
    "id": "-MTPhRGxJV7I"
   },
   "source": [
    "### 3. Do regression & Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:44.851707696Z",
     "start_time": "2024-01-10T22:35:44.851421217Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>is_usable</th>\n",
       "      <th>is_available</th>\n",
       "      <th>is_biased</th>\n",
       "      <th>has_age</th>\n",
       "      <th>has_gender</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSE202667</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohort_id  is_usable  is_available  is_biased  has_age  has_gender  \\\n",
       "0  GSE202667       True          True      False     True       False   \n",
       "\n",
       "   sample_size note  \n",
       "0           59       "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the information of usable cohorts\n",
    "best_cohort, ranked_df = filter_and_rank_cohorts(JSON_PATH)\n",
    "ranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:44.852763201Z",
     "start_time": "2024-01-10T22:35:44.851646029Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GSE202667'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If both age and gender have available cohorts, select 'age' as the condition.\n",
    "condition = 'Age'\n",
    "filter_column = 'has_' + condition.lower()\n",
    "\n",
    "condition_best_cohort, condition_ranked_df = filter_and_rank_cohorts(JSON_PATH, filter_column)\n",
    "condition_best_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T22:35:44.926936066Z",
     "start_time": "2024-01-10T22:35:44.856500393Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>is_usable</th>\n",
       "      <th>is_available</th>\n",
       "      <th>is_biased</th>\n",
       "      <th>has_age</th>\n",
       "      <th>has_gender</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSE202667</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohort_id  is_usable  is_available  is_biased  has_age  has_gender  \\\n",
       "0  GSE202667       True          True      False     True       False   \n",
       "\n",
       "   sample_size note  \n",
       "0           59       "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_ranked_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parkinsons Disease</th>\n",
       "      <th>Age</th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1BG-AS1</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2M-AS1</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A2MP1</th>\n",
       "      <th>A3GALT2</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>9.654958</td>\n",
       "      <td>6.840383</td>\n",
       "      <td>4.606614</td>\n",
       "      <td>7.791717</td>\n",
       "      <td>9.338443</td>\n",
       "      <td>4.131266</td>\n",
       "      <td>4.630472</td>\n",
       "      <td>4.116816</td>\n",
       "      <td>...</td>\n",
       "      <td>6.923014</td>\n",
       "      <td>5.928867</td>\n",
       "      <td>5.336804</td>\n",
       "      <td>9.945157</td>\n",
       "      <td>8.728173</td>\n",
       "      <td>4.083643</td>\n",
       "      <td>7.152738</td>\n",
       "      <td>8.764589</td>\n",
       "      <td>10.991895</td>\n",
       "      <td>8.935958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>8.814921</td>\n",
       "      <td>6.116481</td>\n",
       "      <td>4.750553</td>\n",
       "      <td>7.069863</td>\n",
       "      <td>8.309786</td>\n",
       "      <td>4.180329</td>\n",
       "      <td>4.441678</td>\n",
       "      <td>3.934067</td>\n",
       "      <td>...</td>\n",
       "      <td>6.983116</td>\n",
       "      <td>5.711287</td>\n",
       "      <td>5.271011</td>\n",
       "      <td>9.982510</td>\n",
       "      <td>8.338410</td>\n",
       "      <td>4.171956</td>\n",
       "      <td>6.225974</td>\n",
       "      <td>9.815245</td>\n",
       "      <td>10.403894</td>\n",
       "      <td>9.145225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>8.801728</td>\n",
       "      <td>6.418458</td>\n",
       "      <td>4.445648</td>\n",
       "      <td>6.530332</td>\n",
       "      <td>8.201789</td>\n",
       "      <td>4.249116</td>\n",
       "      <td>4.348418</td>\n",
       "      <td>4.014694</td>\n",
       "      <td>...</td>\n",
       "      <td>7.089069</td>\n",
       "      <td>5.812418</td>\n",
       "      <td>5.381214</td>\n",
       "      <td>9.808489</td>\n",
       "      <td>8.227430</td>\n",
       "      <td>4.176350</td>\n",
       "      <td>6.427028</td>\n",
       "      <td>8.220737</td>\n",
       "      <td>10.320584</td>\n",
       "      <td>9.407862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>8.819856</td>\n",
       "      <td>6.463039</td>\n",
       "      <td>4.848204</td>\n",
       "      <td>5.120851</td>\n",
       "      <td>7.341023</td>\n",
       "      <td>4.216061</td>\n",
       "      <td>4.298238</td>\n",
       "      <td>4.129527</td>\n",
       "      <td>...</td>\n",
       "      <td>7.567015</td>\n",
       "      <td>5.737634</td>\n",
       "      <td>4.901521</td>\n",
       "      <td>9.714882</td>\n",
       "      <td>8.099116</td>\n",
       "      <td>4.271942</td>\n",
       "      <td>6.437460</td>\n",
       "      <td>7.828501</td>\n",
       "      <td>9.750806</td>\n",
       "      <td>9.957810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>8.983630</td>\n",
       "      <td>6.757611</td>\n",
       "      <td>4.680821</td>\n",
       "      <td>6.321323</td>\n",
       "      <td>7.208938</td>\n",
       "      <td>4.237601</td>\n",
       "      <td>4.483631</td>\n",
       "      <td>4.103769</td>\n",
       "      <td>...</td>\n",
       "      <td>7.994359</td>\n",
       "      <td>7.831097</td>\n",
       "      <td>5.145042</td>\n",
       "      <td>9.492221</td>\n",
       "      <td>8.189065</td>\n",
       "      <td>4.124397</td>\n",
       "      <td>6.858179</td>\n",
       "      <td>8.675738</td>\n",
       "      <td>10.305819</td>\n",
       "      <td>9.322602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parkinsons Disease   Age      A1BG  A1BG-AS1      A1CF       A2M   A2M-AS1  \\\n",
       "0                 1.0  53.0  9.654958  6.840383  4.606614  7.791717  9.338443   \n",
       "1                 1.0  53.0  8.814921  6.116481  4.750553  7.069863  8.309786   \n",
       "2                 1.0  53.0  8.801728  6.418458  4.445648  6.530332  8.201789   \n",
       "3                 1.0  53.0  8.819856  6.463039  4.848204  5.120851  7.341023   \n",
       "4                 1.0  53.0  8.983630  6.757611  4.680821  6.321323  7.208938   \n",
       "\n",
       "      A2ML1     A2MP1   A3GALT2  ...    ZWILCH     ZWINT      ZXDA      ZXDB  \\\n",
       "0  4.131266  4.630472  4.116816  ...  6.923014  5.928867  5.336804  9.945157   \n",
       "1  4.180329  4.441678  3.934067  ...  6.983116  5.711287  5.271011  9.982510   \n",
       "2  4.249116  4.348418  4.014694  ...  7.089069  5.812418  5.381214  9.808489   \n",
       "3  4.216061  4.298238  4.129527  ...  7.567015  5.737634  4.901521  9.714882   \n",
       "4  4.237601  4.483631  4.103769  ...  7.994359  7.831097  5.145042  9.492221   \n",
       "\n",
       "       ZXDC    ZYG11A    ZYG11B       ZYX      ZZEF1      ZZZ3  \n",
       "0  8.728173  4.083643  7.152738  8.764589  10.991895  8.935958  \n",
       "1  8.338410  4.171956  6.225974  9.815245  10.403894  9.145225  \n",
       "2  8.227430  4.176350  6.427028  8.220737  10.320584  9.407862  \n",
       "3  8.099116  4.271942  6.437460  7.828501   9.750806  9.957810  \n",
       "4  8.189065  4.124397  6.858179  8.675738  10.305819  9.322602  \n",
       "\n",
       "[5 rows x 21250 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = pd.read_csv(os.path.join(OUTPUT_DIR, condition_best_cohort + '.csv'))\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merged_data.drop(columns=['Gender'], errors='ignore').astype('float')\n",
    "\n",
    "X = merged_data.drop(columns=[TRAIT, condition]).values\n",
    "Y = merged_data[TRAIT].values\n",
    "Z = merged_data[condition].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_batch_effect = detect_batch_effect(X)\n",
    "has_batch_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select appropriate models based on whether the dataset has batch effect.\n",
    "# We experiment on two models for each branch. We will decide which one to choose later.\n",
    "\n",
    "if has_batch_effect:\n",
    "    model_constructor1 = VariableSelection\n",
    "    model_params1 = {'modified': True, 'lamda': 3e-4}\n",
    "    model_constructor2 = VariableSelection\n",
    "    model_params2 = {'modified': False}\n",
    "else:\n",
    "    model_constructor1 = Lasso\n",
    "    model_params1 = {'alpha': 1.0, 'random_state': 42}\n",
    "    model_constructor2 = VariableSelection\n",
    "    model_params2 = {'modified': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Module 'scipy' has no attribute 'exp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\__init__.py:150\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'exp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m trait_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Remember to set this properly, either 'binary' or 'continuous'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cv_mean1, cv_std1 \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_constructor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrait_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 657\u001b[0m, in \u001b[0;36mcross_validation\u001b[1;34m(X, Y, Z, model_constructor, model_params, k, target_type)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;66;03m# model = model_constructor(**model_params)\u001b[39;00m\n\u001b[0;32m    656\u001b[0m model \u001b[38;5;241m=\u001b[39m ResidualizationRegressor(model_constructor, model_params)\n\u001b[1;32m--> 657\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_Z_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(normalized_X_test, normalized_Z_test)\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[1;32mIn[7], line 585\u001b[0m, in \u001b[0;36mResidualizationRegressor.fit\u001b[1;34m(self, X, Y, Z)\u001b[0m\n\u001b[0;32m    582\u001b[0m e_Y \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m-\u001b[39m Y_hat  \u001b[38;5;66;03m# Residual of Y\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;66;03m# Step 2: Regress the residual on X using the included regression model\u001b[39;00m\n\u001b[1;32m--> 585\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregression_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;66;03m# Obtain coefficients from the regression model\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregression_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoef_\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sparse_lmm\\VariableSelection.py:45\u001b[0m, in \u001b[0;36mVariableSelection.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macceleration:\n\u001b[1;32m---> 45\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_detail(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sparse_lmm\\VariableSelection.py:58\u001b[0m, in \u001b[0;36mVariableSelection.fit_fast\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     55\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(y, (n_s, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU, ldelta0\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_nullmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldelta0 \u001b[38;5;241m=\u001b[39m ldelta0\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodified:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sparse_lmm\\VariableSelection.py:210\u001b[0m, in \u001b[0;36mVariableSelection.train_nullmodel\u001b[1;34m(self, y, K, S, U, numintervals)\u001b[0m\n\u001b[0;32m    208\u001b[0m ldeltagrid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(numintervals \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (numintervals \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldeltamax \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldeltamin) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldeltamin\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(numintervals \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 210\u001b[0m     nllgrid[i] \u001b[38;5;241m=\u001b[39m \u001b[43mnLLeval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mldeltagrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# the method is in helpingMethods\u001b[39;00m\n\u001b[0;32m    212\u001b[0m nllmin \u001b[38;5;241m=\u001b[39m nllgrid\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m    213\u001b[0m ldeltaopt_glob \u001b[38;5;241m=\u001b[39m ldeltagrid[nllgrid\u001b[38;5;241m.\u001b[39margmin()]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sparse_lmm\\helpingMethods.py:72\u001b[0m, in \u001b[0;36mnLLeval\u001b[1;34m(ldelta, Uy, S, REML)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03mevaluate the negative log likelihood of a random effects model:\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03mnLL = 1/2(n_s*log(2pi) + logdet(K) + 1/ss * y^T(K + deltaI)^{-1}y,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03mldelta: log-transformed ratio sigma_gg/sigma_ee\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     71\u001b[0m n_s \u001b[38;5;241m=\u001b[39m Uy\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 72\u001b[0m delta \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m(ldelta)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# evaluate log determinant\u001b[39;00m\n\u001b[0;32m     75\u001b[0m Sd \u001b[38;5;241m=\u001b[39m S \u001b[38;5;241m+\u001b[39m delta\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\__init__.py:152\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[name]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscipy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: Module 'scipy' has no attribute 'exp'"
     ]
    }
   ],
   "source": [
    "trait_type = 'binary'  # Remember to set this properly, either 'binary' or 'continuous'\n",
    "cv_mean1, cv_std1 = cross_validation(X, Y, Z, model_constructor1, model_params1, target_type=trait_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Module 'scipy' has no attribute 'exp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\__init__.py:150\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'exp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cv_mean2, cv_std2 \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_constructor2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrait_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 657\u001b[0m, in \u001b[0;36mcross_validation\u001b[1;34m(X, Y, Z, model_constructor, model_params, k, target_type)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;66;03m# model = model_constructor(**model_params)\u001b[39;00m\n\u001b[0;32m    656\u001b[0m model \u001b[38;5;241m=\u001b[39m ResidualizationRegressor(model_constructor, model_params)\n\u001b[1;32m--> 657\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_Z_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(normalized_X_test, normalized_Z_test)\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[1;32mIn[7], line 585\u001b[0m, in \u001b[0;36mResidualizationRegressor.fit\u001b[1;34m(self, X, Y, Z)\u001b[0m\n\u001b[0;32m    582\u001b[0m e_Y \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m-\u001b[39m Y_hat  \u001b[38;5;66;03m# Residual of Y\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;66;03m# Step 2: Regress the residual on X using the included regression model\u001b[39;00m\n\u001b[1;32m--> 585\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregression_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;66;03m# Obtain coefficients from the regression model\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregression_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoef_\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sparse_lmm\\VariableSelection.py:45\u001b[0m, in \u001b[0;36mVariableSelection.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macceleration:\n\u001b[1;32m---> 45\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_detail(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sparse_lmm\\VariableSelection.py:58\u001b[0m, in \u001b[0;36mVariableSelection.fit_fast\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     55\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(y, (n_s, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU, ldelta0\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_nullmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldelta0 \u001b[38;5;241m=\u001b[39m ldelta0\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodified:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sparse_lmm\\VariableSelection.py:210\u001b[0m, in \u001b[0;36mVariableSelection.train_nullmodel\u001b[1;34m(self, y, K, S, U, numintervals)\u001b[0m\n\u001b[0;32m    208\u001b[0m ldeltagrid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(numintervals \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (numintervals \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldeltamax \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldeltamin) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldeltamin\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(numintervals \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 210\u001b[0m     nllgrid[i] \u001b[38;5;241m=\u001b[39m \u001b[43mnLLeval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mldeltagrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# the method is in helpingMethods\u001b[39;00m\n\u001b[0;32m    212\u001b[0m nllmin \u001b[38;5;241m=\u001b[39m nllgrid\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m    213\u001b[0m ldeltaopt_glob \u001b[38;5;241m=\u001b[39m ldeltagrid[nllgrid\u001b[38;5;241m.\u001b[39margmin()]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sparse_lmm\\helpingMethods.py:72\u001b[0m, in \u001b[0;36mnLLeval\u001b[1;34m(ldelta, Uy, S, REML)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03mevaluate the negative log likelihood of a random effects model:\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03mnLL = 1/2(n_s*log(2pi) + logdet(K) + 1/ss * y^T(K + deltaI)^{-1}y,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03mldelta: log-transformed ratio sigma_gg/sigma_ee\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     71\u001b[0m n_s \u001b[38;5;241m=\u001b[39m Uy\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 72\u001b[0m delta \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m(ldelta)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# evaluate log determinant\u001b[39;00m\n\u001b[0;32m     75\u001b[0m Sd \u001b[38;5;241m=\u001b[39m S \u001b[38;5;241m+\u001b[39m delta\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\__init__.py:152\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[name]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscipy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: Module 'scipy' has no attribute 'exp'"
     ]
    }
   ],
   "source": [
    "cv_mean2, cv_std2 = cross_validation(X, Y, Z, model_constructor2, model_params2, target_type=trait_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Module 'scipy' has no attribute 'exp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\__init__.py:150\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'exp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train regression model on the whole dataset to identify significant genes\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model1 \u001b[38;5;241m=\u001b[39m ResidualizationRegressor(model_constructor1, model_params1)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_Z\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m model2 \u001b[38;5;241m=\u001b[39m ResidualizationRegressor(model_constructor2, model_params2)\n\u001b[0;32m      9\u001b[0m model2\u001b[38;5;241m.\u001b[39mfit(normalized_X, Y, normalized_Z)\n",
      "Cell \u001b[1;32mIn[7], line 585\u001b[0m, in \u001b[0;36mResidualizationRegressor.fit\u001b[1;34m(self, X, Y, Z)\u001b[0m\n\u001b[0;32m    582\u001b[0m e_Y \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m-\u001b[39m Y_hat  \u001b[38;5;66;03m# Residual of Y\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;66;03m# Step 2: Regress the residual on X using the included regression model\u001b[39;00m\n\u001b[1;32m--> 585\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregression_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;66;03m# Obtain coefficients from the regression model\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregression_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoef_\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sparse_lmm\\VariableSelection.py:45\u001b[0m, in \u001b[0;36mVariableSelection.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macceleration:\n\u001b[1;32m---> 45\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_detail(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sparse_lmm\\VariableSelection.py:58\u001b[0m, in \u001b[0;36mVariableSelection.fit_fast\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     55\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(y, (n_s, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU, ldelta0\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_nullmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldelta0 \u001b[38;5;241m=\u001b[39m ldelta0\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodified:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sparse_lmm\\VariableSelection.py:210\u001b[0m, in \u001b[0;36mVariableSelection.train_nullmodel\u001b[1;34m(self, y, K, S, U, numintervals)\u001b[0m\n\u001b[0;32m    208\u001b[0m ldeltagrid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(numintervals \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (numintervals \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldeltamax \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldeltamin) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldeltamin\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(numintervals \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 210\u001b[0m     nllgrid[i] \u001b[38;5;241m=\u001b[39m \u001b[43mnLLeval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mldeltagrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# the method is in helpingMethods\u001b[39;00m\n\u001b[0;32m    212\u001b[0m nllmin \u001b[38;5;241m=\u001b[39m nllgrid\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m    213\u001b[0m ldeltaopt_glob \u001b[38;5;241m=\u001b[39m ldeltagrid[nllgrid\u001b[38;5;241m.\u001b[39margmin()]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sparse_lmm\\helpingMethods.py:72\u001b[0m, in \u001b[0;36mnLLeval\u001b[1;34m(ldelta, Uy, S, REML)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03mevaluate the negative log likelihood of a random effects model:\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03mnLL = 1/2(n_s*log(2pi) + logdet(K) + 1/ss * y^T(K + deltaI)^{-1}y,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03mldelta: log-transformed ratio sigma_gg/sigma_ee\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     71\u001b[0m n_s \u001b[38;5;241m=\u001b[39m Uy\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 72\u001b[0m delta \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m(ldelta)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# evaluate log determinant\u001b[39;00m\n\u001b[0;32m     75\u001b[0m Sd \u001b[38;5;241m=\u001b[39m S \u001b[38;5;241m+\u001b[39m delta\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\__init__.py:152\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[name]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscipy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: Module 'scipy' has no attribute 'exp'"
     ]
    }
   ],
   "source": [
    "normalized_X, _ = normalize_data(X)\n",
    "normalized_Z, _ = normalize_data(Z)\n",
    "\n",
    "# Train regression model on the whole dataset to identify significant genes\n",
    "model1 = ResidualizationRegressor(model_constructor1, model_params1)\n",
    "model1.fit(normalized_X, Y, normalized_Z)\n",
    "\n",
    "model2 = ResidualizationRegressor(model_constructor2, model_params2)\n",
    "model2.fit(normalized_X, Y, normalized_Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Discussion and report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'ravel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m feature_cols\u001b[38;5;241m.\u001b[39mremove(TRAIT)\n\u001b[0;32m      4\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43minterpret_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRAIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                 \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 700\u001b[0m, in \u001b[0;36minterpret_result\u001b[1;34m(model, feature_names, trait, condition, threshold, save_output, output_dir, model_id)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpret_result\u001b[39m(model: Any, feature_names: List[\u001b[38;5;28mstr\u001b[39m], trait: \u001b[38;5;28mstr\u001b[39m, condition: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    680\u001b[0m                      threshold: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m, save_output: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    681\u001b[0m                      output_dir: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output\u001b[39m\u001b[38;5;124m'\u001b[39m, model_id: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    682\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function interprets and reports the result of a trained linear regression model, where the regressor\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;124;03m    consists of one variable about condition and multiple variables about genetic factors.\u001b[39;00m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;124;03m    The function extracts coefficients and p-values from the model, and identifies the significant genes based on\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;124;03m    None: This function does not return anything but prints and optionally saves the output.\u001b[39;00m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 700\u001b[0m     coefficients \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coefficients\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    701\u001b[0m     p_values \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_p_values()\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[7], line 629\u001b[0m, in \u001b[0;36mResidualizationRegressor.get_coefficients\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_coefficients\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_Z[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mravel(), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta_X\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m()))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'ravel'"
     ]
    }
   ],
   "source": [
    "feature_cols = merged_data.columns.tolist()\n",
    "feature_cols.remove(TRAIT)\n",
    "\n",
    "threshold = 0.05\n",
    "interpret_result(model1, feature_cols, TRAIT, condition, threshold=threshold, save_output=True,\n",
    "                 output_dir=OUTPUT_DIR, model_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m interpret_result(\u001b[43mmodel2\u001b[49m, feature_cols, TRAIT, condition, threshold\u001b[38;5;241m=\u001b[39mthreshold, save_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      2\u001b[0m                  output_dir\u001b[38;5;241m=\u001b[39mOUTPUT_DIR, model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "interpret_result(model2, feature_cols, TRAIT, condition, threshold=threshold, save_output=True,\n",
    "                 output_dir=OUTPUT_DIR, model_id=2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
