{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Gold standard curation: Preprocessing and single-step regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this stage of gold standard curation, we will do the data preprocessing, selection, and single-step regression for the 153 traits in our question set. This file shows the reference steps using the trait \"Breast Cancer\" as an example. The workflow consists of the following steps:\n",
    "\n",
    "1. Preprocess all the cohorts related to this trait. Each cohort should be converted to a tabular form and saved to a csv file, with columns being genetic factors, the trait, and age, gender if available;\n",
    "2. If there exists at least one cohort with age or gender information, conduct regression analysis with genetic features together with age or gender as the regressors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:25.927828954Z",
     "start_time": "2024-01-10T21:37:25.311064788Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils import *\n",
    "\n",
    "# Set your preferred name\n",
    "USER = \"Mianchen\"\n",
    "# Set the data and output directories\n",
    "DATA_ROOT = '/Users/zhangmianchen/Downloads/DATA'\n",
    "OUTPUT_ROOT = '/Users/zhangmianchen/Downloads/'\n",
    "TRAIT = 'Adrenocortical Cancer'\n",
    "\n",
    "OUTPUT_DIR = os.path.join(OUTPUT_ROOT, USER, '-'.join(TRAIT.split()))\n",
    "JSON_PATH = os.path.join(OUTPUT_DIR, \"cohort_info.json\")\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Gene symbol normalization may take 1-2 minutes. You may set it to False for debugging.\n",
    "NORMALIZE_GENE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:25.928143012Z",
     "start_time": "2024-01-10T21:37:25.918685567Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMTdsU43vVg3",
    "outputId": "38886111-f442-44b4-8398-96bf384d7abd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import os\\nfrom google.colab import drive\\n\\ndrive.mount('/content/drive', force_remount=True)\\nproj_dir = '/content/drive/MyDrive/AI4Science_Public'\\nos.chdir(proj_dir)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell is only for use on Google Colab. Skip it if you run your code in other environments\n",
    "\n",
    "\"\"\"import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "proj_dir = '/content/drive/MyDrive/AI4Science_Public'\n",
    "os.chdir(proj_dir)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2. Data preprocessing and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.1. The TCGA Xena dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In TCGA Xena, there is either zero or one cohort related to the trait. We search the names of subdirectories to see if any matches the trait. If a match is found, we directly obtain the file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:26.554597756Z",
     "start_time": "2024-01-10T21:37:26.530982646Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'TCGA_Kidney_Papillary_Cell_Carcinoma_(KIRP)',\n",
       " 'TCGA_Melanoma_(SKCM)',\n",
       " 'TCGA_Kidney_Chromophobe_(KICH)',\n",
       " 'TCGA_Sarcoma_(SARC)',\n",
       " 'TCGA_Esophageal_Cancer_(ESCA)',\n",
       " 'TCGA_Adrenocortical_Cancer_(ACC)']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'TCGA'\n",
    "dataset_dir = os.path.join(DATA_ROOT, dataset)\n",
    "os.listdir(dataset_dir)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If no match is found, jump directly to GEO in Part 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:26.999521704Z",
     "start_time": "2024-01-10T21:37:26.987471072Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_subdir = \"TCGA_Adrenocortical_Cancer_(ACC)\"\n",
    "cohort = 'Xena'\n",
    "# All the cancer traits in Xena are binary\n",
    "trait_type = 'binary'\n",
    "# Once a relevant cohort is found in Xena, we can generally assume the gene and clinical data are available\n",
    "is_available = True\n",
    "\n",
    "clinical_data_file = os.path.join(dataset_dir, trait_subdir, 'TCGA.ACC.sampleMap_ACC_clinicalMatrix')\n",
    "genetic_data_file = os.path.join(dataset_dir, trait_subdir, 'TCGA.ACC.sampleMap_HiSeqV2_PANCAN.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.180581225Z",
     "start_time": "2024-01-10T21:37:27.217363685Z"
    },
    "id": "MudwB-_iz7sc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clinical_data = pd.read_csv(clinical_data_file, sep='\\t', index_col=0)\n",
    "genetic_data = pd.read_csv(genetic_data_file, compression='gzip', sep='\\t', index_col=0)\n",
    "age_col = gender_col = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rows_and_columns(dataframe, display=False):\n",
    "    \"\"\"\n",
    "    Get the lists of row names and column names of a dataset, and optionally observe them.\n",
    "    :param dataframe:\n",
    "    :param display:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataframe_rows = dataframe.index.tolist()\n",
    "    if display:\n",
    "        print(f\"The dataset has {len(dataframe_rows)} rows, such as {dataframe_rows[:20]}\")\n",
    "    dataframe_cols = dataframe.columns.tolist()\n",
    "    if display:\n",
    "        print(f\"\\nThe dataset has {len(dataframe_cols)} columns, such as {dataframe_cols[:20]}\")\n",
    "    return dataframe_rows, dataframe_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.185775284Z",
     "start_time": "2024-01-10T21:37:30.181745846Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_INTEGRATION',\n",
       " '_PATIENT',\n",
       " '_cohort',\n",
       " '_primary_disease',\n",
       " '_primary_site',\n",
       " 'additional_pharmaceutical_therapy',\n",
       " 'additional_radiation_therapy',\n",
       " 'age_at_initial_pathologic_diagnosis',\n",
       " 'atypical_mitotic_figures',\n",
       " 'bcr_followup_barcode']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, clinical_data_cols = check_rows_and_columns(clinical_data)\n",
    "clinical_data_cols[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T20:20:11.841042813Z",
     "start_time": "2023-12-28T20:20:11.834458206Z"
    },
    "collapsed": false
   },
   "source": [
    "Read all the column names in the clinical dataset, to find the columns that record information about age or gender.\n",
    "Reference prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.269854441Z",
     "start_time": "2024-01-10T21:37:30.184225525Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBelow is a list of column names from a biomedical dataset. Please examine it and identify the columns that are likely to contain information about patients' age. Additionally, please do the same for columns that may hold data on patients' gender. Please provide your answer by strictly following this format, without redundant words:\\ncandidate_age_cols = [col_name1, col_name2, ...]\\ncandidate_gender_cols = [col_name1, col_name2, ...]\\nIf no columns match a criterion, please provide an empty list.\\n\\nColumn names:\\n['_INTEGRATION', '_PATIENT', '_cohort', '_primary_disease', '_primary_site', 'additional_pharmaceutical_therapy', 'additional_radiation_therapy', 'age_at_initial_pathologic_diagnosis', 'atypical_mitotic_figures', 'bcr_followup_barcode', 'bcr_patient_barcode', 'bcr_sample_barcode', 'clinical_M', 'ct_scan_findings', 'cytoplasm_presence_less_than_equal_25_percent', 'days_to_birth', 'days_to_collection', 'days_to_death', 'days_to_initial_pathologic_diagnosis', 'days_to_last_followup', 'days_to_new_tumor_event_additional_surgery_procedure', 'days_to_new_tumor_event_after_initial_treatment', 'diffuse_architecture', 'distant_metastasis_anatomic_site', 'excess_adrenal_hormone_diagnosis_method_type', 'excess_adrenal_hormone_history_type', 'form_completion_date', 'gender', 'germline_testing_performed', 'histologic_disease_progression_present_indicator', 'histological_type', 'history_of_neoadjuvant_treatment', 'icd_10', 'icd_o_3_histology', 'icd_o_3_site', 'informed_consent_verified', 'initial_weight', 'invasion_of_tumor_capsule', 'is_ffpe', 'laterality', 'lost_follow_up', 'lymph_node_examined_count', 'metastatic_neoplasm_confirmed_diagnosis_method_name', 'metastatic_neoplasm_confirmed_diagnosis_method_text', 'mitoses_count', 'mitotane_therapy', 'mitotane_therapy_adjuvant_setting', 'mitotane_therapy_for_macroscopic_residual_disease', 'mitotic_rate', 'necrosis', 'new_neoplasm_confirmed_diagnosis_method_name', 'new_neoplasm_event_occurrence_anatomic_site', 'new_neoplasm_event_type', 'new_neoplasm_occurrence_anatomic_site_text', 'new_tumor_event_additional_surgery_procedure', 'new_tumor_event_after_initial_treatment', 'nuclear_grade_III_IV', 'number_of_lymphnodes_positive_by_he', 'oct_embedded', 'other_dx', 'pathologic_N', 'pathologic_T', 'pathologic_stage', 'pathology_report_file_name', 'patient_id', 'person_neoplasm_cancer_status', 'post_surgical_procedure_assessment_thyroid_gland_carcinoma_stats', 'postoperative_rx_tx', 'primary_lymph_node_presentation_assessment', 'primary_therapy_outcome_success', 'radiation_therapy', 'residual_tumor', 'ret', 'sample_type', 'sample_type_id', 'sinusoid_invasion', 'therapeutic_mitotane_levels_achieved', 'therapeutic_mitotane_lvl_macroscopic_residual', 'therapeutic_mitotane_lvl_progression', 'therapeutic_mitotane_lvl_recurrence', 'tissue_prospective_collection_indicator', 'tissue_retrospective_collection_indicator', 'tissue_source_site', 'tumor_tissue_site', 'vial_number', 'vital_status', 'weiss_score', 'weiss_venous_invasion', 'year_of_initial_pathologic_diagnosis', '_GENOMIC_ID_TCGA_ACC_mutation_curated_bcm_gene', '_GENOMIC_ID_TCGA_ACC_exp_HiSeqV2_percentile', '_GENOMIC_ID_data/public/TCGA/ACC/miRNA_HiSeq_gene', '_GENOMIC_ID_TCGA_ACC_miRNA_HiSeq', '_GENOMIC_ID_TCGA_ACC_RPPA', '_GENOMIC_ID_TCGA_ACC_hMethyl450', '_GENOMIC_ID_TCGA_ACC_exp_HiSeqV2_exon', '_GENOMIC_ID_TCGA_ACC_exp_HiSeqV2', '_GENOMIC_ID_TCGA_ACC_gistic2thd', '_GENOMIC_ID_TCGA_ACC_PDMRNAseq', '_GENOMIC_ID_TCGA_ACC_PDMRNAseqCNV', '_GENOMIC_ID_TCGA_ACC_exp_HiSeqV2_PANCAN', '_GENOMIC_ID_TCGA_ACC_gistic2', '_GENOMIC_ID_TCGA_ACC_mutation_bcm_gene', '_GENOMIC_ID_TCGA_ACC_mutation_curated_broad_gene']\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'''\n",
    "Below is a list of column names from a biomedical dataset. Please examine it and identify the columns that are likely to contain information about patients' age. Additionally, please do the same for columns that may hold data on patients' gender. Please provide your answer by strictly following this format, without redundant words:\n",
    "candidate_age_cols = [col_name1, col_name2, ...]\n",
    "candidate_gender_cols = [col_name1, col_name2, ...]\n",
    "If no columns match a criterion, please provide an empty list.\n",
    "\n",
    "Column names:\n",
    "{clinical_data_cols}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.270036796Z",
     "start_time": "2024-01-10T21:37:30.227180075Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidate_age_cols = [ 'age_at_initial_pathologic_diagnosis',\n",
    "                      'days_to_birth', 'year_of_initial_pathologic_diagnosis']\n",
    "candidate_gender_cols = [ 'gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:57:44.207565572Z",
     "start_time": "2023-12-31T03:57:44.202177544Z"
    },
    "collapsed": false
   },
   "source": [
    "Choose a single column from the candidate columns that record age and gender information respectively.\n",
    "If no column meets the requirement, keep 'age_col' or 'gender_col' to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_df(df, n=5):\n",
    "    return df.head(n).to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.270232386Z",
     "start_time": "2024-01-10T21:37:30.227282564Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age_at_initial_pathologic_diagnosis': [58, 44, 23, 23, 30],\n",
       " 'days_to_birth': [-21496, -16090, -8624, -8451, -11171],\n",
       " 'year_of_initial_pathologic_diagnosis': [2000, 2004, 2008, 2000, 2000]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preview_df(clinical_data[candidate_age_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.270339062Z",
     "start_time": "2024-01-10T21:37:30.227412883Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_col = 'age_at_initial_pathologic_diagnosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.270520195Z",
     "start_time": "2024-01-10T21:37:30.227467704Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': ['MALE', 'FEMALE', 'FEMALE', 'FEMALE', 'MALE']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preview_df(clinical_data[candidate_gender_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.270626721Z",
     "start_time": "2024-01-10T21:37:30.227530279Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_col = 'gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xena_select_clinical_features(clinical_df, trait, age_col=None, gender_col=None):\n",
    "    feature_list = []\n",
    "    trait_data = clinical_df.index.to_series().apply(xena_convert_trait).rename(trait)\n",
    "    feature_list.append(trait_data)\n",
    "    if age_col:\n",
    "        age_data = clinical_df[age_col].apply(xena_convert_age).rename(\"Age\")\n",
    "        feature_list.append(age_data)\n",
    "    if gender_col:\n",
    "        gender_data = clinical_df[gender_col].apply(xena_convert_gender).rename(\"Gender\")\n",
    "        feature_list.append(gender_data)\n",
    "    selected_clinical_df = pd.concat(feature_list, axis=1)\n",
    "    return selected_clinical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xena_convert_trait(row_index: str):\n",
    "    \"\"\"\n",
    "    Convert the trait information from Sample IDs to labels depending on the last two digits.\n",
    "    Tumor types range from 01 - 09, normal types from 10 - 19.\n",
    "    :param row_index: the index value of a row\n",
    "    :return: the converted value\n",
    "    \"\"\"\n",
    "    last_two_digits = int(row_index[-2:])\n",
    "\n",
    "    if 1 <= last_two_digits <= 9:\n",
    "        return 1\n",
    "    elif 10 <= last_two_digits <= 19:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xena_convert_age(cell: str):\n",
    "    \"\"\"Convert the cell content about age to a numerical value using regular expression\n",
    "    \"\"\"\n",
    "    match = re.search(r'\\d+', str(cell))\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xena_convert_gender(cell: str):\n",
    "    \"\"\"Convert the cell content about gender to a binary value\n",
    "    \"\"\"\n",
    "    if isinstance(cell, str):\n",
    "        cell = cell.lower()\n",
    "\n",
    "    if cell == \"female\":\n",
    "        return 0\n",
    "    elif cell == \"male\":\n",
    "        return 1\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.270719762Z",
     "start_time": "2024-01-10T21:37:30.227585330Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "selected_clinical_data = xena_select_clinical_features(clinical_data, TRAIT, age_col=age_col, gender_col=gender_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_gene_symbols_in_index(gene_df):\n",
    "    \"\"\"Normalize the human gene symbols at the index of a dataframe, and replace the index with its normalized version.\n",
    "    Remove the rows where the index failed to be normalized.\"\"\"\n",
    "    normalized_gene_list = normalize_gene_symbols(gene_df.index.tolist())\n",
    "    assert len(normalized_gene_list) == len(gene_df.index)\n",
    "    gene_df.index = normalized_gene_list\n",
    "    gene_df = gene_df[gene_df.index.notnull()]\n",
    "    return gene_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_gene_symbols(gene_symbols, batch_size=1000):\n",
    "    \"\"\"Normalize human gene symbols in batches using the 'mygenes' library\"\"\"\n",
    "    mg = mygene.MyGeneInfo()\n",
    "    normalized_genes = {}\n",
    "\n",
    "    # Process in batches\n",
    "    for i in range(0, len(gene_symbols), batch_size):\n",
    "        batch = gene_symbols[i:i + batch_size]\n",
    "        results = mg.querymany(batch, scopes='symbol', fields='symbol', species='human')\n",
    "\n",
    "        # Update the normalized_genes dictionary with results from this batch\n",
    "        for gene in results:\n",
    "            normalized_genes[gene['query']] = gene.get('symbol', None)\n",
    "\n",
    "    # Return the normalized symbols in the same order as the input\n",
    "    return [normalized_genes.get(symbol) for symbol in gene_symbols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:38:18.001977877Z",
     "start_time": "2024-01-10T21:37:30.227635342Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15 input query terms found dup hits:\t[('GTF2IP1', 2), ('RBMY1A3P', 3), ('HERC2P2', 3), ('WASH3P', 3), ('NUDT9P1', 2), ('SNORD104', 2), ('\n",
      "154 input query terms found no hit:\t['C16orf13', 'C16orf11', 'LOC100272146', 'LOC339240', 'NACAP1', 'LOC441204', 'KLRA1', 'FAM183A', 'FA\n",
      "9 input query terms found dup hits:\t[('SUGT1P1', 2), ('SNORD127', 2), ('SNORA62', 4), ('IFITM4P', 8), ('HLA-DRB6', 2), ('FUNDC2P2', 2), \n",
      "190 input query terms found no hit:\t['NARFL', 'NFKBIL2', 'LOC150197', 'TMEM84', 'LOC162632', 'PPPDE1', 'PPPDE2', 'C1orf38', 'C1orf31', '\n",
      "20 input query terms found dup hits:\t[('PIP5K1P1', 2), ('SNORA40', 2), ('SNORD116-24', 2), ('SNORD116-25', 2), ('SNORD116-23', 2), ('SNOR\n",
      "149 input query terms found no hit:\t['FAM153C', 'C9orf167', 'CLK2P', 'CCDC76', 'CCDC75', 'CCDC72', 'HIST3H2BB', 'PRAC', 'LOC285780', 'LO\n",
      "18 input query terms found dup hits:\t[('SNORD58C', 2), ('UOX', 2), ('UBE2Q2P1', 3), ('PPP4R1L', 2), ('SNORD63', 3), ('SNORD116-22', 2), (\n",
      "158 input query terms found no hit:\t['C16orf91', 'LOC100130581', 'SFRS2', 'C16orf5', 'C16orf7', 'C16orf3', 'C21orf7', 'C21orf2', 'LOC389\n",
      "19 input query terms found dup hits:\t[('FAM66D', 2), ('FAM66A', 2), ('THSD1P1', 2), ('MSLNL', 2), ('EEF1DP3', 2), ('PGM5P2', 2), ('UBE2MP\n",
      "169 input query terms found no hit:\t['LOC284551', 'LOC285548', 'LOC728410', 'LOC541473', 'DULLARD', 'KIAA0368', 'EFTUD1', 'TWISTNB', 'SF\n",
      "17 input query terms found dup hits:\t[('S100A7L2', 2), ('POM121L8P', 2), ('SNORD16', 2), ('MEG8', 2), ('RPL23P8', 2), ('KIR3DX1', 5), ('R\n",
      "165 input query terms found no hit:\t['TMEM188', 'PDZD3', 'FAM102B', 'FAM102A', 'SMCR7L', 'G6PC', 'OSTCL', 'LOC653544', 'LOC653545', 'USP\n",
      "20 input query terms found dup hits:\t[('SNORD50B', 2), ('PCNAP1', 2), ('SNORA63', 7), ('C5orf60', 2), ('CEACAM22P', 2), ('SNORA16A', 2), \n",
      "147 input query terms found no hit:\t['LRRC37A4', 'LOC100131726', 'CPSF3L', 'COL4A3BP', 'PAR1', 'LOC92973', 'MICALCL', 'SMCR7', 'HIST4H4'\n",
      "15 input query terms found dup hits:\t[('SDHAP3', 2), ('PSORS1C3', 8), ('POM121L10P', 2), ('HLA-J', 9), ('HLA-H', 9), ('HLA-L', 7), ('NME2\n",
      "153 input query terms found no hit:\t['LOC100131193', 'KIAA1109', 'DUS2L', 'MYST1', 'IGLL3', 'C12orf69', 'NEURL', 'FAM188B', 'FLJ32063', \n",
      "8 input query terms found dup hits:\t[('PLGLA', 2), ('PA2G4P4', 2), ('RPL23AP7', 2), ('ST20', 2), ('RPL23AP64', 3), ('DPY19L2P2', 3), ('F\n",
      "177 input query terms found no hit:\t['LOC283314', 'RBM9', 'C20orf118', 'LOC150786', 'C20orf112', 'C20orf111', 'C20orf117', 'C20orf114', \n",
      "19 input query terms found dup hits:\t[('TPTE2P1', 2), ('FOLH1B', 2), ('ID2B', 2), ('MSX2P1', 2), ('RAET1K', 2), ('BMS1P4', 2), ('RPL23AP8\n",
      "175 input query terms found no hit:\t['MYEOV2', 'FAM35B2', 'C20orf85', 'FAM175A', 'C17orf73', 'C17orf72', 'C17orf71', 'C17orf70', 'C17orf\n",
      "26 input query terms found dup hits:\t[('CATSPER2P1', 2), ('AQP7P3', 2), ('AQP7P1', 2), ('ATP8B5P', 2), ('OR7E91P', 2), ('ZNF204P', 2), ('\n",
      "144 input query terms found no hit:\t['BASE', 'C14orf21', 'C14orf23', 'FAM5B', 'TROVE2', 'C18orf62', 'LOC401052', 'GNB2L1', 'FAM19A4', 'F\n",
      "17 input query terms found dup hits:\t[('P2RX6P', 2), ('RP9P', 2), ('SNORD1A', 2), ('SNORD10', 2), ('SNORD19', 2), ('NRADDP', 2), ('AOX2P'\n",
      "169 input query terms found no hit:\t['TTC15', 'C4orf29', 'FAM48A', 'C4orf21', 'C3orf65', 'C4orf23', 'C3orf67', 'LOC144742', 'C3orf63', '\n",
      "17 input query terms found dup hits:\t[('SNORA58', 2), ('PMCHL1', 2), ('FAM95B1', 2), ('TMEM191A', 2), ('RPL13P5', 2), ('SBDSP1', 2), ('CY\n",
      "143 input query terms found no hit:\t['LOC254312', 'ZNF542', 'CSDAP1', 'FAM73A', 'FAM73B', 'TCTE3', 'ZNF37B', 'LOC728875', 'KIAA1826', 'P\n",
      "16 input query terms found dup hits:\t[('ZFP91-CNTF', 2), ('SNORD116-27', 2), ('GSTM2P1', 2), ('C3P1', 2), ('NCF1B', 2), ('SNORD114-4', 2)\n",
      "138 input query terms found no hit:\t['LOC100129716', 'C14orf184', 'C14orf181', 'C14orf183', 'C14orf182', 'C7orf26', 'C7orf27', 'C7orf23'\n",
      "14 input query terms found dup hits:\t[('ANXA2P1', 2), ('ANXA2P3', 2), ('ANXA2P2', 2), ('SNORD116-12', 2), ('ZNF286B', 2), ('SAA3P', 2), (\n",
      "132 input query terms found no hit:\t['AKR1CL1', 'CCDC21', 'CCDC23', 'TMEM111', 'APOB48R', 'LOC595101', 'KIAA1430', 'KIAA1432', 'ORC4L', \n",
      "15 input query terms found dup hits:\t[('TCP10L2', 2), ('CXADRP3', 2), ('SNORD116-13', 2), ('TPTE2P3', 2), ('SNORD116-15', 2), ('SNORD116-\n",
      "175 input query terms found no hit:\t['DFNB59', 'LOC100170939', 'FAM36A', 'C2orf70', 'C2orf71', 'C2orf77', 'C2orf79', 'LOC100128191', 'HR\n",
      "16 input query terms found dup hits:\t[('PMS2CL', 2), ('BRD7P3', 2), ('SCARNA17', 2), ('GABARAPL3', 2), ('MT1IP', 2), ('ADAM6', 3), ('SNOR\n",
      "142 input query terms found no hit:\t['C9orf30', 'PEG3AS', 'C9orf37', 'TXNDC3', 'LOC442308', 'FAM46D', 'FAM46A', 'FAM46B', 'FAM46C', 'WDR\n",
      "13 input query terms found dup hits:\t[('FAM197Y2', 3), ('SNORD1C', 2), ('SNORA71B', 2), ('NAT8B', 3), ('SNORA21', 2), ('VENTXP7', 2), ('G\n",
      "148 input query terms found no hit:\t['FCGR1B', 'RG9MTD2', 'RARS', 'LOC727677', 'CCRN4L', 'SEPT14', 'HKR1', 'C1orf112', 'LOC100270710', '\n",
      "13 input query terms found dup hits:\t[('OR6W1P', 3), ('LYPLA2P1', 6), ('RPL23AP53', 2), ('TRPC2', 2), ('RBMY2FP', 2), ('BAGE2', 2), ('POM\n",
      "150 input query terms found no hit:\t['SIP1', 'FAM129C', 'GIF', 'TMCO7', 'CXorf61', 'CXorf64', 'ZNF192', 'SEPP1', 'KIRREL', 'MGC16121', '\n",
      "18 input query terms found dup hits:\t[('ISCA1P1', 2), ('SNORD116-5', 2), ('PCDHB19P', 3), ('NAPSB', 2), ('WASH7P', 2), ('TTTY11', 2), ('H\n",
      "135 input query terms found no hit:\t['PPYR1', 'FAM82A2', 'FLJ37453', 'FAM82A1', 'KIAA0947', 'MOBKL2B', 'MOBKL2C', 'MOBKL2A', 'CMAH', 'GR\n",
      "8 input query terms found dup hits:\t[('SNORD12B', 2), ('SNORD116-8', 2), ('SNORD116-4', 2), ('SNORD116-1', 2), ('SNORD116-3', 2), ('SNOR\n",
      "78 input query terms found no hit:\t['C14orf174', 'C14orf176', 'C14orf177', 'C14orf179', 'PTPLB', 'SGEF', 'LOC400752', 'GRLF1', 'SPANXE'\n"
     ]
    }
   ],
   "source": [
    "import mygene\n",
    "\n",
    "if NORMALIZE_GENE:\n",
    "    genetic_data = normalize_gene_symbols_in_index(genetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:38:18.108889749Z",
     "start_time": "2024-01-10T21:38:18.021199718Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adrenocortical Cancer</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ARHGEF10L</th>\n",
       "      <th>HIF3A</th>\n",
       "      <th>RNF17</th>\n",
       "      <th>RNF10</th>\n",
       "      <th>RNF11</th>\n",
       "      <th>RNF13</th>\n",
       "      <th>GTF2IP1</th>\n",
       "      <th>...</th>\n",
       "      <th>SLC7A10</th>\n",
       "      <th>PLA2G2C</th>\n",
       "      <th>TULP2</th>\n",
       "      <th>NPY5R</th>\n",
       "      <th>GNGT2</th>\n",
       "      <th>GNGT1</th>\n",
       "      <th>TULP3</th>\n",
       "      <th>BCL6B</th>\n",
       "      <th>GSTK1</th>\n",
       "      <th>SELP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampleID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-OR-A5J1-01</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.641092</td>\n",
       "      <td>-0.325826</td>\n",
       "      <td>-0.531035</td>\n",
       "      <td>1.266428</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>0.03719</td>\n",
       "      <td>0.243706</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.520186</td>\n",
       "      <td>-0.086682</td>\n",
       "      <td>-0.182978</td>\n",
       "      <td>-0.615817</td>\n",
       "      <td>-0.281533</td>\n",
       "      <td>3.02111</td>\n",
       "      <td>-0.927577</td>\n",
       "      <td>-1.006227</td>\n",
       "      <td>1.119905</td>\n",
       "      <td>-2.185533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-OR-A5J2-01</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.864792</td>\n",
       "      <td>2.766674</td>\n",
       "      <td>0.321165</td>\n",
       "      <td>1.000728</td>\n",
       "      <td>0.836122</td>\n",
       "      <td>0.35439</td>\n",
       "      <td>-0.436694</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.318586</td>\n",
       "      <td>1.056018</td>\n",
       "      <td>0.393822</td>\n",
       "      <td>2.366583</td>\n",
       "      <td>-0.955033</td>\n",
       "      <td>-1.28139</td>\n",
       "      <td>1.020723</td>\n",
       "      <td>1.226373</td>\n",
       "      <td>1.164005</td>\n",
       "      <td>0.265067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-OR-A5J3-01</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.723192</td>\n",
       "      <td>-0.362926</td>\n",
       "      <td>-0.531035</td>\n",
       "      <td>0.639828</td>\n",
       "      <td>-0.199578</td>\n",
       "      <td>-0.48331</td>\n",
       "      <td>0.143606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.574486</td>\n",
       "      <td>-0.086682</td>\n",
       "      <td>-0.748878</td>\n",
       "      <td>-0.113317</td>\n",
       "      <td>-3.803333</td>\n",
       "      <td>-0.61009</td>\n",
       "      <td>0.397623</td>\n",
       "      <td>-0.675227</td>\n",
       "      <td>1.196005</td>\n",
       "      <td>-3.161633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-OR-A5J5-01</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.576792</td>\n",
       "      <td>-2.086226</td>\n",
       "      <td>2.463765</td>\n",
       "      <td>1.382228</td>\n",
       "      <td>-1.115678</td>\n",
       "      <td>-1.23621</td>\n",
       "      <td>0.615806</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.279486</td>\n",
       "      <td>-0.086682</td>\n",
       "      <td>0.078622</td>\n",
       "      <td>1.095983</td>\n",
       "      <td>-0.908533</td>\n",
       "      <td>-1.28139</td>\n",
       "      <td>0.661823</td>\n",
       "      <td>0.458273</td>\n",
       "      <td>0.839605</td>\n",
       "      <td>-5.525533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-OR-A5J6-01</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.311992</td>\n",
       "      <td>5.225974</td>\n",
       "      <td>-0.531035</td>\n",
       "      <td>0.967928</td>\n",
       "      <td>-0.393778</td>\n",
       "      <td>-0.38231</td>\n",
       "      <td>-0.060194</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.090786</td>\n",
       "      <td>1.607218</td>\n",
       "      <td>2.481122</td>\n",
       "      <td>-0.946617</td>\n",
       "      <td>-0.570533</td>\n",
       "      <td>-1.28139</td>\n",
       "      <td>-0.425177</td>\n",
       "      <td>0.938573</td>\n",
       "      <td>0.495005</td>\n",
       "      <td>-1.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17342 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Adrenocortical Cancer  Age  Gender  ARHGEF10L     HIF3A  \\\n",
       "sampleID                                                                   \n",
       "TCGA-OR-A5J1-01                      1   58       1  -0.641092 -0.325826   \n",
       "TCGA-OR-A5J2-01                      1   44       0  -1.864792  2.766674   \n",
       "TCGA-OR-A5J3-01                      1   23       0  -0.723192 -0.362926   \n",
       "TCGA-OR-A5J5-01                      1   30       1  -1.576792 -2.086226   \n",
       "TCGA-OR-A5J6-01                      1   29       0  -2.311992  5.225974   \n",
       "\n",
       "                    RNF17     RNF10     RNF11    RNF13   GTF2IP1  ...  \\\n",
       "sampleID                                                          ...   \n",
       "TCGA-OR-A5J1-01 -0.531035  1.266428  0.355422  0.03719  0.243706  ...   \n",
       "TCGA-OR-A5J2-01  0.321165  1.000728  0.836122  0.35439 -0.436694  ...   \n",
       "TCGA-OR-A5J3-01 -0.531035  0.639828 -0.199578 -0.48331  0.143606  ...   \n",
       "TCGA-OR-A5J5-01  2.463765  1.382228 -1.115678 -1.23621  0.615806  ...   \n",
       "TCGA-OR-A5J6-01 -0.531035  0.967928 -0.393778 -0.38231 -0.060194  ...   \n",
       "\n",
       "                  SLC7A10   PLA2G2C     TULP2     NPY5R     GNGT2    GNGT1  \\\n",
       "sampleID                                                                     \n",
       "TCGA-OR-A5J1-01 -1.520186 -0.086682 -0.182978 -0.615817 -0.281533  3.02111   \n",
       "TCGA-OR-A5J2-01 -0.318586  1.056018  0.393822  2.366583 -0.955033 -1.28139   \n",
       "TCGA-OR-A5J3-01 -0.574486 -0.086682 -0.748878 -0.113317 -3.803333 -0.61009   \n",
       "TCGA-OR-A5J5-01 -0.279486 -0.086682  0.078622  1.095983 -0.908533 -1.28139   \n",
       "TCGA-OR-A5J6-01 -2.090786  1.607218  2.481122 -0.946617 -0.570533 -1.28139   \n",
       "\n",
       "                    TULP3     BCL6B     GSTK1      SELP  \n",
       "sampleID                                                 \n",
       "TCGA-OR-A5J1-01 -0.927577 -1.006227  1.119905 -2.185533  \n",
       "TCGA-OR-A5J2-01  1.020723  1.226373  1.164005  0.265067  \n",
       "TCGA-OR-A5J3-01  0.397623 -0.675227  1.196005 -3.161633  \n",
       "TCGA-OR-A5J5-01  0.661823  0.458273  0.839605 -5.525533  \n",
       "TCGA-OR-A5J6-01 -0.425177  0.938573  0.495005 -1.733333  \n",
       "\n",
       "[5 rows x 17342 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = selected_clinical_data.join(genetic_data.T).dropna()\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_and_remove_biased_features(df, trait, trait_type):\n",
    "    assert trait_type in [\"binary\", \"continuous\"], f\"The trait must be either a binary or a continuous variable!\"\n",
    "    if trait_type == \"binary\":\n",
    "        trait_biased = judge_binary_variable_biased(df, trait)\n",
    "    else:\n",
    "        trait_biased = judge_continuous_variable_biased(df, trait)\n",
    "    if trait_biased:\n",
    "        print(f\"The distribution of the feature \\'{trait}\\' in this dataset is severely biased.\\n\")\n",
    "    else:\n",
    "        print(f\"The distribution of the feature \\'{trait}\\' in this dataset is fine.\\n\")\n",
    "    if \"Age\" in df.columns:\n",
    "        age_biased = judge_continuous_variable_biased(df, 'Age')\n",
    "        if age_biased:\n",
    "            print(f\"The distribution of the feature \\'Age\\' in this dataset is severely biased.\\n\")\n",
    "            df = df.drop(columns='Age')\n",
    "        else:\n",
    "            print(f\"The distribution of the feature \\'Age\\' in this dataset is fine.\\n\")\n",
    "    if \"Gender\" in df.columns:\n",
    "        gender_biased = judge_binary_variable_biased(df, 'Gender')\n",
    "        if gender_biased:\n",
    "            print(f\"The distribution of the feature \\'Gender\\' in this dataset is severely biased.\\n\")\n",
    "            df = df.drop(columns='Gender')\n",
    "        else:\n",
    "            print(f\"The distribution of the feature \\'Gender\\' in this dataset is fine.\\n\")\n",
    "\n",
    "    return trait_biased, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_binary_variable_biased(dataframe, col_name, min_proportion=0.1, min_num=5):\n",
    "    \"\"\"\n",
    "    Check if the distribution of a binary variable in the dataset is too biased to be usable for analysis\n",
    "    :param dataframe:\n",
    "    :param col_name:\n",
    "    :param min_proportion:\n",
    "    :param min_num:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    label_counter = dataframe[col_name].value_counts()\n",
    "    total_samples = len(dataframe)\n",
    "    rare_label_num = label_counter.min()\n",
    "    rare_label = label_counter.idxmin()\n",
    "    rare_label_proportion = rare_label_num / total_samples\n",
    "\n",
    "    print(\n",
    "        f\"For the feature \\'{col_name}\\', the least common label is '{rare_label}' with {rare_label_num} occurrences. This represents {rare_label_proportion:.2%} of the dataset.\")\n",
    "\n",
    "    biased = (len(label_counter) < 2) or ((rare_label_proportion < min_proportion) and (rare_label_num < min_num))\n",
    "    return bool(biased)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_continuous_variable_biased(dataframe, col_name):\n",
    "    \"\"\"Check if the distribution of a continuous variable in the dataset is too biased to be usable for analysis.\n",
    "    As a starting point, we consider it biased if all values are the same. For the next step, maybe ask GPT to judge\n",
    "    based on quartile statistics combined with its common sense knowledge about this feature.\n",
    "    \"\"\"\n",
    "    quartiles = dataframe[col_name].quantile([0.25, 0.5, 0.75])\n",
    "    min_value = dataframe[col_name].min()\n",
    "    max_value = dataframe[col_name].max()\n",
    "\n",
    "    # Printing quartile information\n",
    "    print(f\"Quartiles for '{col_name}':\")\n",
    "    print(f\"  25%: {quartiles[0.25]}\")\n",
    "    print(f\"  50% (Median): {quartiles[0.5]}\")\n",
    "    print(f\"  75%: {quartiles[0.75]}\")\n",
    "    print(f\"Min: {min_value}\")\n",
    "    print(f\"Max: {max_value}\")\n",
    "\n",
    "    biased = min_value == max_value\n",
    "\n",
    "    return bool(biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:38:18.112793384Z",
     "start_time": "2024-01-10T21:38:18.107415526Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged dataset contains 79 samples.\n",
      "For the feature 'Adrenocortical Cancer', the least common label is '1' with 79 occurrences. This represents 100.00% of the dataset.\n",
      "The distribution of the feature 'Adrenocortical Cancer' in this dataset is severely biased.\n",
      "\n",
      "Quartiles for 'Age':\n",
      "  25%: 35.0\n",
      "  50% (Median): 49.0\n",
      "  75%: 59.5\n",
      "Min: 14\n",
      "Max: 77\n",
      "The distribution of the feature 'Age' in this dataset is fine.\n",
      "\n",
      "For the feature 'Gender', the least common label is '1' with 31 occurrences. This represents 39.24% of the dataset.\n",
      "The distribution of the feature 'Gender' in this dataset is fine.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The merged dataset contains {len(merged_data)} samples.\")\n",
    "is_trait_biased, merge_data = judge_and_remove_biased_features(merged_data, TRAIT, trait_type=trait_type)\n",
    "is_trait_biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:38:31.377898533Z",
     "start_time": "2024-01-10T21:38:18.111417452Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data.head()\n",
    "if not is_trait_biased:\n",
    "    merge_data.to_csv(os.path.join(OUTPUT_DIR, cohort + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, List, Tuple, Union, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cohort_info(cohort: str, info_path: str, is_available: bool, is_biased: Optional[bool] = None,\n",
    "                     df: Optional[pd.DataFrame] = None, note: str = '') -> None:\n",
    "    \"\"\"\n",
    "    Add or update information about the usability and quality of a dataset for statistical analysis.\n",
    "\n",
    "    Parameters:\n",
    "    cohort (str): A unique identifier for the dataset.\n",
    "    info_path (str): File path to the JSON file where records are stored.\n",
    "    is_available (bool): Indicates whether both the genetic data and trait data are available in the dataset, and can be\n",
    "     preprocessed into a dataframe.\n",
    "    is_biased (bool, optional): Indicates whether the dataset is too biased to be usable.\n",
    "        Required if `is_available` is True.\n",
    "    df (pandas.DataFrame, optional): The preprocessed dataset. Required if `is_available` is True.\n",
    "    note (str, optional): Additional notes about the dataset.\n",
    "\n",
    "    Returns:\n",
    "    None: The function does not return a value but updates or creates a record in the specified JSON file.\n",
    "    \"\"\"\n",
    "    if is_available:\n",
    "        assert (df is not None) and (is_biased is not None), \"'df' and 'is_biased' should be provided if this cohort \" \\\n",
    "                                                             \"is relevant.\"\n",
    "    is_usable = is_available and (not is_biased)\n",
    "    new_record = {\"is_usable\": is_usable,\n",
    "                  \"is_available\": is_available,\n",
    "                  \"is_biased\": is_biased if is_available else None,\n",
    "                  \"has_age\": \"Age\" in df.columns if is_available else None,\n",
    "                  \"has_gender\": \"Gender\" in df.columns if is_available else None,\n",
    "                  \"sample_size\": len(df) if is_available else None,\n",
    "                  \"note\": note}\n",
    "    \n",
    "    if not os.path.exists(info_path):\n",
    "        with open(info_path, 'w') as file:\n",
    "            json.dump({}, file)\n",
    "        print(f\"A new JSON file was created at: {info_path}\")\n",
    "\n",
    "    with open(info_path, \"r\") as file:\n",
    "        records = json.load(file)\n",
    "    records[cohort] = new_record\n",
    "\n",
    "    temp_path = info_path + \".tmp\"\n",
    "    try:\n",
    "        with open(temp_path, 'w') as file:\n",
    "            json.dump(records, file)\n",
    "        os.replace(temp_path, info_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:38:31.425336629Z",
     "start_time": "2024-01-10T21:38:31.419043732Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "save_cohort_info(cohort, JSON_PATH, is_available, is_trait_biased, merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T21:28:38.028916303Z",
     "start_time": "2023-12-28T21:28:38.016245426Z"
    },
    "collapsed": false
   },
   "source": [
    "## 2.2. The GEO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:25:23.253882615Z",
     "start_time": "2023-12-31T03:25:23.244062710Z"
    },
    "collapsed": false
   },
   "source": [
    "In GEO, there may be one or multiple cohorts for a trait. Each cohort is identified by an accession number. We iterate over all accession numbers in the corresponding subdirectory, preprocess the cohort data, and save them to csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:38:31.425592571Z",
     "start_time": "2024-01-10T21:38:31.419137625Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GSE33371',\n",
       " 'GSE49280',\n",
       " 'GSE143383',\n",
       " '.DS_Store',\n",
       " 'GSE90713',\n",
       " 'GSE36353',\n",
       " 'GSE19776',\n",
       " 'GSE35066',\n",
       " 'GSE19856',\n",
       " 'GSE32206',\n",
       " 'GSE75415',\n",
       " 'GSE68950',\n",
       " 'GSE19750',\n",
       " 'GSE108089',\n",
       " 'GSE49277',\n",
       " 'GSE49276',\n",
       " 'GSE52296',\n",
       " 'GSE108088',\n",
       " 'GSE49278',\n",
       " 'GSE76019',\n",
       " 'GSE169253',\n",
       " 'GSE67766',\n",
       " 'GSE68606',\n",
       " 'GSE21660']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'GEO'\n",
    "trait_subdir = \"Adrenocortical-Cancer\"\n",
    "\n",
    "trait_path = os.path.join(DATA_ROOT, dataset, trait_subdir)\n",
    "os.listdir(trait_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:39:42.634870142Z",
     "start_time": "2023-12-31T03:39:42.534093295Z"
    },
    "collapsed": false
   },
   "source": [
    "Repeat the below steps for all the accession numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_filepaths(cohort_dir):\n",
    "    \"\"\"Find the file paths of a SOFT file and a matrix file from the given data directory of a cohort.\n",
    "    If there are multiple SOFT files or matrix files, simply choose the first one. May be replaced by better\n",
    "    strategies later.\n",
    "    \"\"\"\n",
    "    files = os.listdir(cohort_dir)\n",
    "    soft_files = [f for f in files if 'soft' in f.lower()]\n",
    "    matrix_files = [f for f in files if 'matrix' in f.lower()]\n",
    "    assert len(soft_files) > 0 and len(matrix_files) > 0\n",
    "    soft_file_path = os.path.join(cohort_dir, soft_files[0])\n",
    "    matrix_file_path = os.path.join(cohort_dir, matrix_files[0])\n",
    "\n",
    "    return soft_file_path, matrix_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:39:02.935079426Z",
     "start_time": "2024-01-10T21:39:02.923698385Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE33371/GSE33371_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE33371/GSE33371_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE33371\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE49280/GSE49280_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE49280/GSE49280-GPL8887_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE49280\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE143383/GSE143383_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE143383/GSE143383_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE143383\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE90713/GSE90713_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE90713/GSE90713_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE90713\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE36353/GSE36353_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE36353/GSE36353_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE36353\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE19776/GSE19776_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE19776/GSE19776-GPL887_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE19776\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE35066/GSE35066_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE35066/GSE35066-GPL8887_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE35066\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE19856/GSE19856_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE19856/GSE19856_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE19856\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE32206/GSE32206_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE32206/GSE32206-GPL6985_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE32206\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE75415/GSE75415_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE75415/GSE75415_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE75415\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE68950/GSE68950_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE68950/GSE68950_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE68950\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE19750/GSE19750_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE19750/GSE19750_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE19750\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE108089/GSE108089_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE108089/GSE108089-GPL570_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE108089\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE49277/GSE49277_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE49277/GSE49277_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE49277\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE49276/GSE49276_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE49276/GSE49276-GPL8887_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE49276\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE52296/GSE52296_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE52296/GSE52296_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE52296\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE108088/GSE108088_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE108088/GSE108088_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE108088\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE49278/GSE49278_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE49278/GSE49278_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE49278\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE76019/GSE76019_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE76019/GSE76019_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE76019\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE169253/GSE169253_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE169253/GSE169253_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE169253\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE67766/GSE67766_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE67766/GSE67766-GPL14622_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE67766\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE68606/GSE68606_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE68606/GSE68606_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE68606\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE21660/GSE21660_family.soft.gz',\n",
       " '/Users/zhangmianchen/Downloads/DATA/GEO/Adrenocortical-Cancer/GSE21660/GSE21660_series_matrix.txt.gz')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = accession_num = \"GSE21660\"\n",
    "cohort_dir = os.path.join(trait_path, accession_num)\n",
    "soft_file, matrix_file = get_relevant_filepaths(cohort_dir)\n",
    "soft_file, matrix_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Initial filtering and clinical data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_generator(source, source_type):\n",
    "    \"\"\"Generator that yields lines from a file or a string.\n",
    "\n",
    "    Parameters:\n",
    "    - source: File path or string content.\n",
    "    - source_type: 'file' or 'string'.\n",
    "    \"\"\"\n",
    "    if source_type == 'file':\n",
    "        with gzip.open(source, 'rt') as f:\n",
    "            for line in f:\n",
    "                yield line.strip()\n",
    "    elif source_type == 'string':\n",
    "        for line in source.split('\\n'):\n",
    "            yield line.strip()\n",
    "    else:\n",
    "        raise ValueError(\"source_type must be 'file' or 'string'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_content_by_prefix(\n",
    "    source: str,\n",
    "    prefixes_a: List[str],\n",
    "    prefixes_b: Optional[List[str]] = None,\n",
    "    unselect: bool = False,\n",
    "    source_type: str = 'file',\n",
    "    return_df_a: bool = True,\n",
    "    return_df_b: bool = True\n",
    ") -> Tuple[Union[str, pd.DataFrame], Optional[Union[str, pd.DataFrame]]]:\n",
    "    \"\"\"\n",
    "    Filters rows from a file or a list of strings based on specified prefixes.\n",
    "\n",
    "    Parameters:\n",
    "    - source (str): File path or string content to filter.\n",
    "    - prefixes_a (List[str]): Primary list of prefixes to filter by.\n",
    "    - prefixes_b (Optional[List[str]]): Optional secondary list of prefixes to filter by.\n",
    "    - unselect (bool): If True, selects rows that do not start with the specified prefixes.\n",
    "    - source_type (str): 'file' if source is a file path, 'string' if source is a string of text.\n",
    "    - return_df_a (bool): If True, returns filtered content for prefixes_a as a pandas DataFrame.\n",
    "    - return_df_b (bool): If True, and if prefixes_b is provided, returns filtered content for prefixes_b as a pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple: A tuple where the first element is the filtered content for prefixes_a, and the second element is the filtered content for prefixes_b.\n",
    "    \"\"\"\n",
    "    filtered_lines_a = []\n",
    "    filtered_lines_b = []\n",
    "    prefix_set_a = set(prefixes_a)\n",
    "    if prefixes_b is not None:\n",
    "        prefix_set_b = set(prefixes_b)\n",
    "\n",
    "    # Use generator to get lines\n",
    "    for line in line_generator(source, source_type):\n",
    "        matched_a = any(line.startswith(prefix) for prefix in prefix_set_a)\n",
    "        if matched_a != unselect:\n",
    "            filtered_lines_a.append(line)\n",
    "        if prefixes_b is not None:\n",
    "            matched_b = any(line.startswith(prefix) for prefix in prefix_set_b)\n",
    "            if matched_b != unselect:\n",
    "                filtered_lines_b.append(line)\n",
    "\n",
    "    filtered_content_a = '\\n'.join(filtered_lines_a)\n",
    "    if return_df_a:\n",
    "        filtered_content_a = pd.read_csv(io.StringIO(filtered_content_a), delimiter='\\t', low_memory=False, on_bad_lines='skip')\n",
    "    filtered_content_b = None\n",
    "    if filtered_lines_b:\n",
    "        filtered_content_b = '\\n'.join(filtered_lines_b)\n",
    "        if return_df_b:\n",
    "            filtered_content_b = pd.read_csv(io.StringIO(filtered_content_b), delimiter='\\t', low_memory=False, on_bad_lines='skip')\n",
    "\n",
    "    return filtered_content_a, filtered_content_b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background_and_clinical_data(file_path,\n",
    "                                     prefixes_a=['!Series_title', '!Series_summary', '!Series_overall_design'],\n",
    "                                     prefixes_b=['!Sample_geo_accession', '!Sample_characteristics_ch1']):\n",
    "    \"\"\"Extract from a matrix file the background information about the dataset, and sample characteristics data\"\"\"\n",
    "    background_info, clinical_data = filter_content_by_prefix(file_path, prefixes_a, prefixes_b, unselect=False,\n",
    "                                                              source_type='file',\n",
    "                                                              return_df_a=False, return_df_b=True)\n",
    "    return background_info, clinical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:39:03.718770427Z",
     "start_time": "2024-01-10T21:39:03.677006442Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!Series_title\t\"Advancing a Clinically Relevant Perspective of the Clonal Nature of Cancer\"\n",
      "!Series_summary\t\"We used DNA content-based flow cytometry to distinguish and isolate nuclei from clonal populations in primary tissues from three disparate cancers with variable clinical histories. We then developed a methodology to adapt flow cytometrically purified nuclei samples for use with whole genome technologies including aCGH and next generation sequencing (NGS). Our results demonstrate that selected aberrations in the genomes of distinct clonal populations in each patient create clinically relevant contexts at least with respect to the cancer types profiled in this study.\"\n",
      "!Series_overall_design\t\"We applied DNA content based flow sorting to isolate the nuclei of clonal populations from tumor biopsies. Genomic DNA from each sorted population was amplified with phi29 polymerase. A 1ug aliquot of each amplified sample was digested with DNAse 1 then labeled with Cy5 using a Klenow-based commercial kit (Invitrogen). Each sample was hybridized with a pooled normal (46,XX) reference (Promega) to Agilent 244k CGH arrays. The use of highly purified objectively defined flow sorted populations provides high definition genomic profiles of clonal populations from pancreatic adenocarcinomas (PA), adrenal cortical carcinomas (ACC), and prostate adenocarcinomas (PC).\"\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "background_prefixes = ['!Series_title', '!Series_summary', '!Series_overall_design']\n",
    "clinical_prefixes = ['!Sample_geo_accession', '!Sample_characteristics_ch1']\n",
    "\n",
    "background_info, clinical_data = get_background_and_clinical_data(matrix_file, background_prefixes, clinical_prefixes)\n",
    "print(background_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:39:04.022548957Z",
     "start_time": "2024-01-10T21:39:04.008519515Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!Sample_geo_accession</th>\n",
       "      <th>GSM540550</th>\n",
       "      <th>GSM540551</th>\n",
       "      <th>GSM540552</th>\n",
       "      <th>GSM540553</th>\n",
       "      <th>GSM540554</th>\n",
       "      <th>GSM540555</th>\n",
       "      <th>GSM540556</th>\n",
       "      <th>GSM540557</th>\n",
       "      <th>GSM540558</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM540601</th>\n",
       "      <th>GSM540602</th>\n",
       "      <th>GSM540603</th>\n",
       "      <th>GSM540604</th>\n",
       "      <th>GSM540605</th>\n",
       "      <th>GSM540606</th>\n",
       "      <th>GSM540607</th>\n",
       "      <th>GSM540608</th>\n",
       "      <th>GSM540609</th>\n",
       "      <th>GSM540610</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!Sample_characteristics_ch1</td>\n",
       "      <td>tissue: Pancreatic Ductal Adenocarcinoma</td>\n",
       "      <td>tissue: Pancreatic Ductal Adenocarcinoma</td>\n",
       "      <td>tissue: Pancreatic Ductal Adenocarcinoma</td>\n",
       "      <td>tissue: Pancreatic Ductal Adenocarcinoma</td>\n",
       "      <td>tissue: Pancreatic Ductal Adenocarcinoma</td>\n",
       "      <td>tissue: Pancreatic Ductal Adenocarcinoma</td>\n",
       "      <td>tissue: Pancreatic Ductal Adenocarcinoma</td>\n",
       "      <td>tissue: Pancreatic Ductal Adenocarcinoma</td>\n",
       "      <td>tissue: Pancreatic Ductal Adenocarcinoma</td>\n",
       "      <td>...</td>\n",
       "      <td>tissue: Adrenal Cortical Carcinoma</td>\n",
       "      <td>tissue: Adrenal Cortical Carcinoma</td>\n",
       "      <td>tissue: Adrenal Cortical Carcinoma</td>\n",
       "      <td>tissue: Prostate Carcinoma</td>\n",
       "      <td>tissue: Prostate Carcinoma</td>\n",
       "      <td>tissue: Prostate Carcinoma</td>\n",
       "      <td>tissue: Prostate Carcinoma</td>\n",
       "      <td>tissue: Prostate Carcinoma</td>\n",
       "      <td>tissue: Prostate Carcinoma</td>\n",
       "      <td>tissue: Prostate Carcinoma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         !Sample_geo_accession                                 GSM540550  \\\n",
       "0  !Sample_characteristics_ch1  tissue: Pancreatic Ductal Adenocarcinoma   \n",
       "\n",
       "                                  GSM540551  \\\n",
       "0  tissue: Pancreatic Ductal Adenocarcinoma   \n",
       "\n",
       "                                  GSM540552  \\\n",
       "0  tissue: Pancreatic Ductal Adenocarcinoma   \n",
       "\n",
       "                                  GSM540553  \\\n",
       "0  tissue: Pancreatic Ductal Adenocarcinoma   \n",
       "\n",
       "                                  GSM540554  \\\n",
       "0  tissue: Pancreatic Ductal Adenocarcinoma   \n",
       "\n",
       "                                  GSM540555  \\\n",
       "0  tissue: Pancreatic Ductal Adenocarcinoma   \n",
       "\n",
       "                                  GSM540556  \\\n",
       "0  tissue: Pancreatic Ductal Adenocarcinoma   \n",
       "\n",
       "                                  GSM540557  \\\n",
       "0  tissue: Pancreatic Ductal Adenocarcinoma   \n",
       "\n",
       "                                  GSM540558  ...  \\\n",
       "0  tissue: Pancreatic Ductal Adenocarcinoma  ...   \n",
       "\n",
       "                            GSM540601                           GSM540602  \\\n",
       "0  tissue: Adrenal Cortical Carcinoma  tissue: Adrenal Cortical Carcinoma   \n",
       "\n",
       "                            GSM540603                   GSM540604  \\\n",
       "0  tissue: Adrenal Cortical Carcinoma  tissue: Prostate Carcinoma   \n",
       "\n",
       "                    GSM540605                   GSM540606  \\\n",
       "0  tissue: Prostate Carcinoma  tissue: Prostate Carcinoma   \n",
       "\n",
       "                    GSM540607                   GSM540608  \\\n",
       "0  tissue: Prostate Carcinoma  tissue: Prostate Carcinoma   \n",
       "\n",
       "                    GSM540609                   GSM540610  \n",
       "0  tissue: Prostate Carcinoma  tissue: Prostate Carcinoma  \n",
       "\n",
       "[1 rows x 62 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values_by_row(dataframe, max_len=30):\n",
    "    \"\"\"\n",
    "    Organize the unique values in each row of the given dataframe, to get a dictionary\n",
    "    :param dataframe:\n",
    "    :param max_len:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if '!Sample_geo_accession' in dataframe.columns:\n",
    "        dataframe = dataframe.drop(columns=['!Sample_geo_accession'])\n",
    "    unique_values_dict = {}\n",
    "    for index, row in dataframe.iterrows():\n",
    "        unique_values = list(row.unique())[:max_len]\n",
    "        unique_values_dict[index] = unique_values\n",
    "    return unique_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:39:04.307639583Z",
     "start_time": "2024-01-10T21:39:04.289352075Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['tissue: Pancreatic Ductal Adenocarcinoma',\n",
       "  'tissue: Adrenal Cortical Carcinoma',\n",
       "  'tissue: Prostate Carcinoma']}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data_unique = get_unique_values_by_row(clinical_data)\n",
    "clinical_data_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:04.978204446Z",
     "start_time": "2023-12-31T03:58:04.922270095Z"
    },
    "collapsed": false
   },
   "source": [
    "Analyze the metadata to determine data relevance and find ways to extract the clinical data.\n",
    "Reference prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:39:04.854586192Z",
     "start_time": "2024-01-10T21:39:04.836283516Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a biomedical research team, we are selecting datasets to study the association between the human trait \\'Adrenocortical Cancer\\' and genetic factors, optionally considering the influence of age and gender. After searching the GEO database and parsing the matrix file of a series, we obtained background information and sample characteristics data. We will provide textual information about the dataset background, and a Python dictionary storing a list of unique values for each field of the sample characteristics data. Please carefully review the provided information and answer the following questions about this dataset:\\n1. Does this dataset contain gene expression data? (Note: Pure miRNA data is not suitable.)\\n2. For each of the traits \\'Adrenocortical Cancer\\', \\'age\\', and \\'gender\\', please address these points:\\n   (1) Is there human data available for this trait?\\n   (2) If so, identify the key in the sample characteristics dictionary where unique values of this trait is recorded. The key is an integer. The trait information might be explicitly recorded, or can be inferred from the field with some biomedical knowledge or understanding about the data collection process.\\n   (3) Choose an appropriate data type (either \\'continuous\\' or \\'binary\\') for each trait. Write a Python function to convert any given value of the trait to this data type. The function should handle inference about the trait value and convert unknown values to None.\\n   Name the functions \\'convert_trait\\', \\'convert_age\\', and \\'convert_gender\\', respectively.\\n\\nBackground information about the dataset:\\n!Series_title\\t\"Advancing a Clinically Relevant Perspective of the Clonal Nature of Cancer\"\\n!Series_summary\\t\"We used DNA content-based flow cytometry to distinguish and isolate nuclei from clonal populations in primary tissues from three disparate cancers with variable clinical histories. We then developed a methodology to adapt flow cytometrically purified nuclei samples for use with whole genome technologies including aCGH and next generation sequencing (NGS). Our results demonstrate that selected aberrations in the genomes of distinct clonal populations in each patient create clinically relevant contexts at least with respect to the cancer types profiled in this study.\"\\n!Series_overall_design\\t\"We applied DNA content based flow sorting to isolate the nuclei of clonal populations from tumor biopsies. Genomic DNA from each sorted population was amplified with phi29 polymerase. A 1ug aliquot of each amplified sample was digested with DNAse 1 then labeled with Cy5 using a Klenow-based commercial kit (Invitrogen). Each sample was hybridized with a pooled normal (46,XX) reference (Promega) to Agilent 244k CGH arrays. The use of highly purified objectively defined flow sorted populations provides high definition genomic profiles of clonal populations from pancreatic adenocarcinomas (PA), adrenal cortical carcinomas (ACC), and prostate adenocarcinomas (PC).\"\\n\\nSample characteristics dictionary (from \"!Sample_characteristics_ch1\", converted to a Python dictionary that stores the unique values for each field):\\n{0: [\\'tissue: Pancreatic Ductal Adenocarcinoma\\', \\'tissue: Adrenal Cortical Carcinoma\\', \\'tissue: Prostate Carcinoma\\']}\\n'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'''As a biomedical research team, we are selecting datasets to study the association between the human trait \\'{TRAIT}\\' and genetic factors, optionally considering the influence of age and gender. After searching the GEO database and parsing the matrix file of a series, we obtained background information and sample characteristics data. We will provide textual information about the dataset background, and a Python dictionary storing a list of unique values for each field of the sample characteristics data. Please carefully review the provided information and answer the following questions about this dataset:\n",
    "1. Does this dataset contain gene expression data? (Note: Pure miRNA data is not suitable.)\n",
    "2. For each of the traits \\'{TRAIT}\\', 'age', and 'gender', please address these points:\n",
    "   (1) Is there human data available for this trait?\n",
    "   (2) If so, identify the key in the sample characteristics dictionary where unique values of this trait is recorded. The key is an integer. The trait information might be explicitly recorded, or can be inferred from the field with some biomedical knowledge or understanding about the data collection process.\n",
    "   (3) Choose an appropriate data type (either 'continuous' or 'binary') for each trait. Write a Python function to convert any given value of the trait to this data type. The function should handle inference about the trait value and convert unknown values to None.\n",
    "   Name the functions 'convert_trait', 'convert_age', and 'convert_gender', respectively.\n",
    "\n",
    "Background information about the dataset:\n",
    "{background_info}\n",
    "\n",
    "Sample characteristics dictionary (from \"!Sample_characteristics_ch1\", converted to a Python dictionary that stores the unique values for each field):\n",
    "{clinical_data_unique}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:04.978240504Z",
     "start_time": "2023-12-31T03:58:04.922365324Z"
    },
    "collapsed": false
   },
   "source": [
    "Understand and verify the answer from GPT, to assign values to the below variables. Assign None to the 'row_id' variables if relevant data row was not found.\n",
    "Later we need to let GPT format its answer to automatically do these. But given the complexity of this step, let's grow some insight from the free-text answers for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:39:05.366304590Z",
     "start_time": "2024-01-10T21:39:05.356983082Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_row = gender_row = None\n",
    "convert_age = convert_gender = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:09.324053151Z",
     "start_time": "2024-01-10T21:40:09.251131090Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_gene_availabe = True\n",
    "trait_row = 0\n",
    "age_row = None\n",
    "gender_row = None\n",
    "\n",
    "trait_type = 'binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:09.912115984Z",
     "start_time": "2024-01-10T21:40:09.907913460Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_available = is_gene_availabe and (trait_row is not None)\n",
    "if not is_available:\n",
    "    save_cohort_info(cohort, JSON_PATH, is_available)\n",
    "    print(\"This cohort is not usable. Please skip the following steps and jump to the next accession number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:10.982148317Z",
     "start_time": "2024-01-10T21:40:10.967368918Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify and use the functions generated by GPT\n",
    "\n",
    "def convert_trait(tissue_type):\n",
    "    \"\"\"\n",
    "    Convert tissue type to epilepsy presence (binary).\n",
    "    Assuming epilepsy presence for 'Hippocampus' tissue.\n",
    "    \"\"\"\n",
    "    if tissue_type == 'tissue: Pancreatic Ductal Adenocarcinoma':\n",
    "        return 1  # Epilepsy present\n",
    "    else:\n",
    "        return 0  # Epilepsy not present\n",
    "\n",
    "\n",
    "def convert_age(age_string):\n",
    "    \"\"\"\n",
    "    Convert age string to a continuous numerical value.\n",
    "    Unknown values are converted to None.\n",
    "    \"\"\"\n",
    "    if age_string.lower() == 'n.a.':\n",
    "        return None\n",
    "    try:\n",
    "        # Extract age as an integer from the string\n",
    "        age = int(age_string.split(': ')[1])\n",
    "        return age\n",
    "    except (ValueError, IndexError):\n",
    "        # In case of any format error or unexpected string structure\n",
    "        return None\n",
    "\n",
    "\n",
    "# It sometimes maps 'female' to 0, and sometimes 1. Does it matter?\n",
    "def convert_gender(gender_string):\n",
    "    \"\"\"\n",
    "    Convert gender string to a binary value.\n",
    "    'female' is represented as 1, 'male' as 0.\n",
    "    Unknown values are converted to None.\n",
    "    \"\"\"\n",
    "    if gender_string.lower() == 'sex: female':\n",
    "        return 1\n",
    "    elif gender_string.lower() == 'sex: male':\n",
    "        return 0\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_data(clinical_df, row_id, feature, convert_fn):\n",
    "    \"\"\"select the row corresponding to a feature in the sample characteristics dataframe, and convert the feature into\n",
    "    a binary or continuous variable\"\"\"\n",
    "    clinical_df = clinical_df.iloc[row_id:row_id + 1].drop(columns=['!Sample_geo_accession'], errors='ignore')\n",
    "    clinical_df.index = [feature]\n",
    "    clinical_df = clinical_df.applymap(convert_fn)\n",
    "\n",
    "    return clinical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_select_clinical_features(clinical_df: pd.DataFrame, trait: str, trait_row: int,\n",
    "                                 convert_trait: Callable,\n",
    "                                 age_row: Optional[int] = None,\n",
    "                                 convert_age: Optional[Callable] = None,\n",
    "                                 gender_row: Optional[int] = None,\n",
    "                                 convert_gender: Optional[Callable] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts and processes specific clinical features from a DataFrame representing\n",
    "    sample characteristics in the GEO database series.\n",
    "\n",
    "    Parameters:\n",
    "    - clinical_df (pd.DataFrame): DataFrame containing clinical data.\n",
    "    - trait (str): The trait of interest.\n",
    "    - trait_row (int): Row identifier for the trait in the DataFrame.\n",
    "    - convert_trait (Callable): Function to convert trait data into a desired format.\n",
    "    - age_row (int, optional): Row identifier for age data. Default is None.\n",
    "    - convert_age (Callable, optional): Function to convert age data. Default is None.\n",
    "    - gender_row (int, optional): Row identifier for gender data. Default is None.\n",
    "    - convert_gender (Callable, optional): Function to convert gender data. Default is None.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the selected and processed clinical features.\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "\n",
    "    trait_data = get_feature_data(clinical_df, trait_row, trait, convert_trait)\n",
    "    feature_list.append(trait_data)\n",
    "    if age_row is not None:\n",
    "        age_data = get_feature_data(clinical_df, age_row, 'Age', convert_age)\n",
    "        feature_list.append(age_data)\n",
    "    if gender_row is not None:\n",
    "        gender_data = get_feature_data(clinical_df, gender_row, 'Gender', convert_gender)\n",
    "        feature_list.append(gender_data)\n",
    "\n",
    "    selected_clinical_df = pd.concat(feature_list, axis=0)\n",
    "    return selected_clinical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:11.684556802Z",
     "start_time": "2024-01-10T21:40:11.665079581Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSM540550</th>\n",
       "      <th>GSM540551</th>\n",
       "      <th>GSM540552</th>\n",
       "      <th>GSM540553</th>\n",
       "      <th>GSM540554</th>\n",
       "      <th>GSM540555</th>\n",
       "      <th>GSM540556</th>\n",
       "      <th>GSM540557</th>\n",
       "      <th>GSM540558</th>\n",
       "      <th>GSM540559</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM540601</th>\n",
       "      <th>GSM540602</th>\n",
       "      <th>GSM540603</th>\n",
       "      <th>GSM540604</th>\n",
       "      <th>GSM540605</th>\n",
       "      <th>GSM540606</th>\n",
       "      <th>GSM540607</th>\n",
       "      <th>GSM540608</th>\n",
       "      <th>GSM540609</th>\n",
       "      <th>GSM540610</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adrenocortical Cancer</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       GSM540550  GSM540551  GSM540552  GSM540553  GSM540554  \\\n",
       "Adrenocortical Cancer          1          1          1          1          1   \n",
       "\n",
       "                       GSM540555  GSM540556  GSM540557  GSM540558  GSM540559  \\\n",
       "Adrenocortical Cancer          1          1          1          1          1   \n",
       "\n",
       "                       ...  GSM540601  GSM540602  GSM540603  GSM540604  \\\n",
       "Adrenocortical Cancer  ...          0          0          0          0   \n",
       "\n",
       "                       GSM540605  GSM540606  GSM540607  GSM540608  GSM540609  \\\n",
       "Adrenocortical Cancer          0          0          0          0          0   \n",
       "\n",
       "                       GSM540610  \n",
       "Adrenocortical Cancer          0  \n",
       "\n",
       "[1 rows x 61 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_clinical_data = geo_select_clinical_features(clinical_data, TRAIT, trait_row, convert_trait, age_row=age_row,\n",
    "                                                      convert_age=convert_age, gender_row=gender_row,\n",
    "                                                      convert_gender=convert_gender)\n",
    "selected_clinical_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:04.978664193Z",
     "start_time": "2023-12-31T03:58:04.966117261Z"
    },
    "collapsed": false
   },
   "source": [
    "### Genetic data preprocessing and final filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genetic_data(file_path):\n",
    "    \"\"\"Read the gene expression data into a dataframe, and adjust its format\"\"\"\n",
    "    genetic_data = pd.read_csv(file_path, compression='gzip', skiprows=52, comment='!', delimiter='\\t')\n",
    "    genetic_data = genetic_data.dropna()\n",
    "    genetic_data = genetic_data.rename(columns={'ID_REF': 'ID'}).astype({'ID': 'str'})\n",
    "    genetic_data.set_index('ID', inplace=True)\n",
    "\n",
    "    return genetic_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:13.509252107Z",
     "start_time": "2024-01-10T21:40:13.468235630Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSM540550</th>\n",
       "      <th>GSM540551</th>\n",
       "      <th>GSM540552</th>\n",
       "      <th>GSM540553</th>\n",
       "      <th>GSM540554</th>\n",
       "      <th>GSM540555</th>\n",
       "      <th>GSM540556</th>\n",
       "      <th>GSM540557</th>\n",
       "      <th>GSM540558</th>\n",
       "      <th>GSM540559</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM540601</th>\n",
       "      <th>GSM540602</th>\n",
       "      <th>GSM540603</th>\n",
       "      <th>GSM540604</th>\n",
       "      <th>GSM540605</th>\n",
       "      <th>GSM540606</th>\n",
       "      <th>GSM540607</th>\n",
       "      <th>GSM540608</th>\n",
       "      <th>GSM540609</th>\n",
       "      <th>GSM540610</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.00599</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>-0.0779</td>\n",
       "      <td>0.01020</td>\n",
       "      <td>-0.00558</td>\n",
       "      <td>-0.0871</td>\n",
       "      <td>-0.0895</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.00695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.00207</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.00841</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>-0.0128</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>-0.0148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.1730</td>\n",
       "      <td>-0.43800</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.6140</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.5670</td>\n",
       "      <td>-0.004620</td>\n",
       "      <td>-0.4700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.2000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.3190</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.4420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.6850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.19900</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.01230</td>\n",
       "      <td>0.13200</td>\n",
       "      <td>0.0682</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.03560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.36400</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>-0.24800</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>-0.0865</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.0337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.1050</td>\n",
       "      <td>-0.06010</td>\n",
       "      <td>-0.1140</td>\n",
       "      <td>-0.1780</td>\n",
       "      <td>-0.00527</td>\n",
       "      <td>0.00652</td>\n",
       "      <td>-0.1610</td>\n",
       "      <td>-0.1200</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.02830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>-0.0738</td>\n",
       "      <td>-0.05840</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>-0.06350</td>\n",
       "      <td>-0.1470</td>\n",
       "      <td>-0.2470</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>-0.115000</td>\n",
       "      <td>0.0135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    GSM540550  GSM540551  GSM540552  GSM540553  GSM540554  GSM540555  \\\n",
       "ID                                                                     \n",
       "1      0.0201    0.00599     0.0117    -0.0779    0.01020   -0.00558   \n",
       "2      0.0000    0.00000     0.0000    -0.1730   -0.43800    0.00000   \n",
       "3     -0.2000    0.00000     0.0000     0.0000    0.00000    0.00000   \n",
       "4      0.1210    0.19900     0.1570     0.2230    0.01230    0.13200   \n",
       "5     -0.1050   -0.06010    -0.1140    -0.1780   -0.00527    0.00652   \n",
       "\n",
       "    GSM540556  GSM540557  GSM540558  GSM540559  ...  GSM540601  GSM540602  \\\n",
       "ID                                              ...                         \n",
       "1     -0.0871    -0.0895     -0.114   -0.00695  ...     0.0592     0.0563   \n",
       "2      0.0000    -0.6140     -0.019    0.00000  ...     0.0000     0.0000   \n",
       "3      0.0000    -0.3190      0.000    0.00000  ...     0.0000     0.0000   \n",
       "4      0.0682     0.1330      0.148    0.03560  ...     0.1920     0.3650   \n",
       "5     -0.1610    -0.1200     -0.152   -0.02830  ...     0.0991    -0.0738   \n",
       "\n",
       "    GSM540603  GSM540604  GSM540605  GSM540606  GSM540607  GSM540608  \\\n",
       "ID                                                                     \n",
       "1     0.00207     0.0208    0.00841     0.0122    -0.0128     0.0748   \n",
       "2     0.00000     0.0000    0.00000     0.0000     0.0000    -0.5670   \n",
       "3     0.00000     0.0000    0.00000     0.0000     0.0000    -0.4420   \n",
       "4     0.36400     0.0321   -0.24800     0.0240    -0.0865     0.0336   \n",
       "5    -0.05840     0.0120   -0.06350    -0.1470    -0.2470     0.1170   \n",
       "\n",
       "    GSM540609  GSM540610  \n",
       "ID                        \n",
       "1   -0.000229    -0.0148  \n",
       "2   -0.004620    -0.4700  \n",
       "3    0.000000    -0.6850  \n",
       "4    0.167000     0.0337  \n",
       "5   -0.115000     0.0135  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genetic_data = get_genetic_data(matrix_file)\n",
    "genetic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:14.107050774Z",
     "start_time": "2024-01-10T21:40:14.090977173Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_row_ids = genetic_data.index[:20].tolist()\n",
    "gene_row_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:30:41.595335164Z",
     "start_time": "2023-12-31T03:30:41.513232329Z"
    },
    "collapsed": false
   },
   "source": [
    "Check if the gene dataset requires mapping to get the gene symbols corresponding to each data row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Reference prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:16.445692615Z",
     "start_time": "2024-01-10T21:40:16.435117932Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBelow are the row headers of a gene expression dataset in GEO. Based on your biomedical knowledge, are they human gene symbols, or are they some other identifiers that need to be mapped to gene symbols? Your answer should be concluded by starting a new line and strictly following this format:\\nrequires_gene_mapping = (True or False)\\n\\nRow headers:\\n['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '13', '14', '15', '16', '17', '18', '19', '20', '21']\\n\""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'''\n",
    "Below are the row headers of a gene expression dataset in GEO. Based on your biomedical knowledge, are they human gene symbols, or are they some other identifiers that need to be mapped to gene symbols? Your answer should be concluded by starting a new line and strictly following this format:\n",
    "requires_gene_mapping = (True or False)\n",
    "\n",
    "Row headers:\n",
    "{gene_row_ids}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "If not required, jump directly to the gene normalization step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:17.098774002Z",
     "start_time": "2024-01-10T21:40:17.094437169Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "requires_gene_mapping = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:17.399324928Z",
     "start_time": "2024-01-10T21:40:17.381475568Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if requires_gene_mapping:\n",
    "    gene_annotation = get_gene_annotation(soft_file)\n",
    "    gene_annotation_summary = preview_df(gene_annotation)\n",
    "    print(gene_annotation_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:04.978931927Z",
     "start_time": "2023-12-31T03:58:04.966328339Z"
    },
    "collapsed": false
   },
   "source": [
    "Observe the first few cells in the ID column of the gene annotation dataframe, to find the names of columns that store the gene probe IDs and gene symbols respectively.\n",
    "Reference prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:17.944343822Z",
     "start_time": "2024-01-10T21:40:17.933815553Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if requires_gene_mapping:\n",
    "    print(f'''\n",
    "    As a biomedical research team, we are analyzing a gene expression dataset, and find that its row headers are some identifiers related to genes:\n",
    "    {gene_row_ids}\n",
    "    To get the mapping from those identifiers to actual gene symbols, we extracted the gene annotation data from a series in the GEO database, and saved it to a Python dictionary. Please read the dictionary, and decide which key stores the identifiers, and which key stores the gene symbols. Please strictly follow this format in your answer:\n",
    "    identifier_key = 'key_name1'\n",
    "    gene_symbol_key = 'key_name2'\n",
    "\n",
    "    Gene annotation dictionary:\n",
    "    {gene_annotation_summary}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:18.245811669Z",
     "start_time": "2024-01-10T21:40:18.234480277Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if requires_gene_mapping:\n",
    "    identifier_key = 'ID'\n",
    "    gene_symbol_key = 'UCSC_RefGene_Name'\n",
    "    gene_mapping = get_gene_mapping(gene_annotation, identifier_key, gene_symbol_key)\n",
    "    genetic_data = apply_gene_mapping(genetic_data, gene_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.559860684Z",
     "start_time": "2024-01-10T21:40:18.521711414Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000 input query terms found no hit:\t['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '13', '14', '15', '16', '17', '18', '19', \n",
      "1000 input query terms found no hit:\t['1002', '1003', '1004', '1005', '1006', '1007', '1008', '1009', '1010', '1011', '1012', '1013', '10\n",
      "1000 input query terms found no hit:\t['2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '20\n",
      "1000 input query terms found no hit:\t['3005', '3006', '3007', '3008', '3009', '3010', '3011', '3012', '3013', '3014', '3015', '3016', '30\n",
      "1000 input query terms found no hit:\t['4005', '4006', '4007', '4008', '4009', '4010', '4011', '4012', '4013', '4014', '4015', '4016', '40\n",
      "1000 input query terms found no hit:\t['5005', '5006', '5007', '5008', '5009', '5010', '5011', '5012', '5013', '5014', '5015', '5016', '50\n",
      "1000 input query terms found no hit:\t['6005', '6006', '6007', '6008', '6009', '6010', '6011', '6012', '6013', '6014', '6015', '6016', '60\n",
      "1000 input query terms found no hit:\t['7006', '7007', '7008', '7009', '7010', '7011', '7012', '7013', '7014', '7015', '7016', '7017', '70\n",
      "1000 input query terms found no hit:\t['8006', '8007', '8008', '8009', '8010', '8011', '8012', '8013', '8014', '8015', '8016', '8017', '80\n",
      "1000 input query terms found no hit:\t['9007', '9008', '9009', '9010', '9011', '9012', '9013', '9014', '9015', '9016', '9017', '9018', '90\n",
      "1000 input query terms found no hit:\t['10007', '10008', '10009', '10010', '10011', '10012', '10013', '10014', '10015', '10016', '10017', \n",
      "1000 input query terms found no hit:\t['11007', '11008', '11009', '11010', '11011', '11012', '11013', '11014', '11015', '11016', '11017', \n",
      "1000 input query terms found no hit:\t['12008', '12009', '12010', '12011', '12012', '12013', '12014', '12015', '12016', '12017', '12018', \n",
      "1000 input query terms found no hit:\t['13008', '13009', '13010', '13011', '13012', '13013', '13014', '13015', '13016', '13017', '13018', \n",
      "1000 input query terms found no hit:\t['14009', '14010', '14011', '14012', '14013', '14014', '14015', '14016', '14017', '14018', '14019', \n",
      "1000 input query terms found no hit:\t['15010', '15011', '15012', '15013', '15014', '15015', '15016', '15017', '15018', '15019', '15020', \n",
      "1000 input query terms found no hit:\t['16011', '16012', '16013', '16014', '16015', '16016', '16017', '16018', '16019', '16020', '16021', \n",
      "1000 input query terms found no hit:\t['17011', '17012', '17013', '17014', '17015', '17016', '17017', '17018', '17019', '17020', '17021', \n",
      "1000 input query terms found no hit:\t['18011', '18012', '18013', '18014', '18015', '18016', '18017', '18018', '18019', '18020', '18021', \n",
      "1000 input query terms found no hit:\t['19011', '19012', '19013', '19014', '19015', '19016', '19017', '19018', '19019', '19020', '19021', \n",
      "1000 input query terms found no hit:\t['20011', '20012', '20013', '20014', '20015', '20016', '20017', '20018', '20019', '20020', '20021', \n",
      "1000 input query terms found no hit:\t['21012', '21013', '21014', '21015', '21016', '21017', '21018', '21019', '21020', '21021', '21022', \n",
      "1000 input query terms found no hit:\t['22013', '22014', '22015', '22016', '22017', '22018', '22019', '22020', '22021', '22022', '22023', \n",
      "1000 input query terms found no hit:\t['23013', '23014', '23015', '23016', '23017', '23018', '23019', '23020', '23021', '23022', '23023', \n",
      "1000 input query terms found no hit:\t['24013', '24014', '24015', '24016', '24017', '24018', '24019', '24020', '24021', '24022', '24023', \n",
      "1000 input query terms found no hit:\t['25013', '25014', '25015', '25016', '25017', '25018', '25019', '25020', '25021', '25022', '25023', \n",
      "1000 input query terms found no hit:\t['26013', '26014', '26015', '26016', '26017', '26018', '26019', '26020', '26021', '26022', '26023', \n",
      "1000 input query terms found no hit:\t['27013', '27014', '27015', '27016', '27017', '27018', '27019', '27020', '27021', '27022', '27023', \n",
      "1000 input query terms found no hit:\t['28013', '28014', '28015', '28016', '28017', '28018', '28019', '28020', '28021', '28022', '28023', \n",
      "1000 input query terms found no hit:\t['29015', '29016', '29017', '29018', '29019', '29020', '29021', '29022', '29023', '29024', '29025', \n",
      "1000 input query terms found no hit:\t['30015', '30016', '30017', '30018', '30019', '30020', '30021', '30022', '30023', '30024', '30025', \n",
      "1000 input query terms found no hit:\t['31015', '31016', '31017', '31018', '31019', '31020', '31021', '31022', '31023', '31024', '31025', \n",
      "1000 input query terms found no hit:\t['32015', '32016', '32017', '32018', '32019', '32020', '32021', '32022', '32023', '32024', '32025', \n",
      "1000 input query terms found no hit:\t['33015', '33016', '33017', '33018', '33019', '33020', '33021', '33022', '33023', '33024', '33025', \n",
      "1000 input query terms found no hit:\t['34015', '34016', '34017', '34018', '34019', '34020', '34021', '34022', '34023', '34024', '34025', \n",
      "1000 input query terms found no hit:\t['35015', '35016', '35017', '35018', '35019', '35020', '35021', '35022', '35023', '35024', '35025', \n",
      "1000 input query terms found no hit:\t['36015', '36016', '36017', '36018', '36019', '36020', '36021', '36022', '36023', '36024', '36025', \n",
      "1000 input query terms found no hit:\t['37016', '37017', '37018', '37019', '37020', '37021', '37022', '37023', '37024', '37025', '37026', \n",
      "1000 input query terms found no hit:\t['38016', '38017', '38018', '38019', '38020', '38021', '38022', '38023', '38024', '38025', '38026', \n",
      "1000 input query terms found no hit:\t['39017', '39018', '39019', '39020', '39021', '39022', '39023', '39024', '39025', '39026', '39027', \n",
      "1000 input query terms found no hit:\t['40017', '40018', '40019', '40020', '40021', '40022', '40023', '40024', '40025', '40026', '40027', \n",
      "1000 input query terms found no hit:\t['41017', '41018', '41019', '41020', '41021', '41022', '41023', '41024', '41025', '41026', '41027', \n",
      "1000 input query terms found no hit:\t['42017', '42018', '42019', '42020', '42021', '42022', '42023', '42024', '42025', '42026', '42027', \n",
      "1000 input query terms found no hit:\t['43017', '43018', '43019', '43020', '43021', '43022', '43023', '43024', '43025', '43026', '43027', \n",
      "1000 input query terms found no hit:\t['44017', '44018', '44019', '44020', '44021', '44022', '44023', '44024', '44025', '44026', '44027', \n",
      "1000 input query terms found no hit:\t['45017', '45018', '45019', '45020', '45021', '45022', '45023', '45024', '45025', '45026', '45027', \n",
      "1000 input query terms found no hit:\t['46017', '46018', '46019', '46020', '46021', '46022', '46023', '46024', '46025', '46026', '46027', \n",
      "1000 input query terms found no hit:\t['47017', '47018', '47019', '47020', '47021', '47022', '47023', '47024', '47025', '47026', '47027', \n",
      "1000 input query terms found no hit:\t['48017', '48018', '48019', '48020', '48021', '48022', '48023', '48024', '48025', '48026', '48027', \n",
      "1000 input query terms found no hit:\t['49017', '49018', '49019', '49020', '49021', '49022', '49023', '49024', '49025', '49026', '49027', \n",
      "1000 input query terms found no hit:\t['50017', '50018', '50019', '50020', '50021', '50022', '50023', '50024', '50025', '50026', '50027', \n",
      "1000 input query terms found no hit:\t['51017', '51018', '51019', '51020', '51021', '51022', '51023', '51024', '51025', '51026', '51027', \n",
      "1000 input query terms found no hit:\t['52017', '52018', '52019', '52020', '52021', '52022', '52023', '52024', '52025', '52026', '52027', \n",
      "1000 input query terms found no hit:\t['53017', '53018', '53019', '53020', '53021', '53022', '53023', '53024', '53025', '53026', '53027', \n",
      "1000 input query terms found no hit:\t['54018', '54019', '54020', '54021', '54022', '54023', '54024', '54025', '54026', '54027', '54028', \n",
      "1000 input query terms found no hit:\t['55018', '55019', '55020', '55021', '55022', '55023', '55024', '55025', '55026', '55027', '55028', \n",
      "1000 input query terms found no hit:\t['56018', '56019', '56020', '56021', '56022', '56023', '56024', '56025', '56026', '56027', '56028', \n",
      "1000 input query terms found no hit:\t['57019', '57020', '57021', '57022', '57023', '57024', '57025', '57026', '57027', '57028', '57029', \n",
      "1000 input query terms found no hit:\t['58019', '58020', '58021', '58022', '58023', '58024', '58025', '58026', '58027', '58028', '58029', \n",
      "1000 input query terms found no hit:\t['59019', '59020', '59021', '59022', '59023', '59024', '59025', '59026', '59027', '59028', '59029', \n",
      "1000 input query terms found no hit:\t['60019', '60020', '60021', '60022', '60023', '60024', '60025', '60026', '60027', '60028', '60029', \n",
      "1000 input query terms found no hit:\t['61019', '61020', '61021', '61022', '61023', '61024', '61025', '61026', '61027', '61028', '61029', \n",
      "1000 input query terms found no hit:\t['62019', '62020', '62021', '62022', '62023', '62024', '62025', '62026', '62027', '62028', '62029', \n",
      "1000 input query terms found no hit:\t['63019', '63020', '63021', '63022', '63023', '63024', '63025', '63026', '63027', '63028', '63029', \n",
      "1000 input query terms found no hit:\t['64019', '64020', '64021', '64022', '64023', '64024', '64025', '64026', '64027', '64028', '64029', \n",
      "1000 input query terms found no hit:\t['65019', '65020', '65021', '65022', '65023', '65024', '65025', '65026', '65027', '65028', '65029', \n",
      "1000 input query terms found no hit:\t['66019', '66020', '66021', '66022', '66023', '66024', '66025', '66026', '66027', '66028', '66029', \n",
      "1000 input query terms found no hit:\t['67019', '67020', '67021', '67022', '67023', '67024', '67025', '67026', '67027', '67028', '67029', \n",
      "1000 input query terms found no hit:\t['68020', '68021', '68022', '68023', '68024', '68025', '68026', '68027', '68028', '68029', '68030', \n",
      "1000 input query terms found no hit:\t['69020', '69021', '69022', '69023', '69024', '69025', '69026', '69027', '69028', '69029', '69030', \n",
      "1000 input query terms found no hit:\t['70021', '70022', '70023', '70024', '70025', '70026', '70027', '70028', '70029', '70030', '70031', \n",
      "1000 input query terms found no hit:\t['71021', '71022', '71023', '71024', '71025', '71026', '71027', '71028', '71029', '71030', '71031', \n",
      "1000 input query terms found no hit:\t['72022', '72023', '72024', '72025', '72026', '72027', '72028', '72029', '72030', '72031', '72032', \n",
      "1000 input query terms found no hit:\t['73022', '73023', '73024', '73025', '73026', '73027', '73028', '73029', '73030', '73031', '73032', \n",
      "1000 input query terms found no hit:\t['74022', '74023', '74024', '74025', '74026', '74027', '74028', '74029', '74030', '74031', '74032', \n",
      "1000 input query terms found no hit:\t['75022', '75023', '75024', '75025', '75026', '75027', '75028', '75029', '75030', '75031', '75032', \n",
      "1000 input query terms found no hit:\t['76023', '76024', '76025', '76026', '76027', '76028', '76029', '76030', '76031', '76032', '76033', \n",
      "1000 input query terms found no hit:\t['77023', '77024', '77025', '77026', '77027', '77028', '77029', '77030', '77031', '77032', '77033', \n",
      "1000 input query terms found no hit:\t['78023', '78024', '78025', '78026', '78027', '78028', '78029', '78030', '78031', '78032', '78033', \n",
      "1000 input query terms found no hit:\t['79023', '79024', '79025', '79026', '79027', '79028', '79029', '79030', '79031', '79032', '79033', \n",
      "1000 input query terms found no hit:\t['80023', '80024', '80025', '80026', '80027', '80028', '80029', '80030', '80031', '80032', '80033', \n",
      "1000 input query terms found no hit:\t['81023', '81024', '81025', '81026', '81027', '81028', '81029', '81030', '81031', '81032', '81033', \n",
      "1000 input query terms found no hit:\t['82023', '82024', '82025', '82026', '82027', '82028', '82029', '82030', '82031', '82032', '82033', \n",
      "1000 input query terms found no hit:\t['83024', '83025', '83026', '83027', '83028', '83029', '83030', '83031', '83032', '83033', '83034', \n",
      "1000 input query terms found no hit:\t['84024', '84025', '84026', '84027', '84028', '84029', '84030', '84031', '84032', '84033', '84034', \n",
      "1000 input query terms found no hit:\t['85025', '85026', '85027', '85028', '85029', '85030', '85031', '85032', '85033', '85034', '85035', \n",
      "1000 input query terms found no hit:\t['86025', '86026', '86027', '86028', '86029', '86030', '86031', '86032', '86033', '86034', '86035', \n",
      "1000 input query terms found no hit:\t['87025', '87026', '87027', '87028', '87029', '87030', '87031', '87032', '87033', '87034', '87035', \n",
      "1000 input query terms found no hit:\t['88025', '88026', '88027', '88028', '88029', '88030', '88031', '88032', '88033', '88034', '88035', \n",
      "1000 input query terms found no hit:\t['89025', '89026', '89027', '89028', '89029', '89030', '89031', '89032', '89033', '89034', '89035', \n",
      "1000 input query terms found no hit:\t['90025', '90026', '90027', '90028', '90029', '90030', '90031', '90032', '90033', '90034', '90035', \n",
      "1000 input query terms found no hit:\t['91026', '91027', '91028', '91029', '91030', '91031', '91032', '91033', '91034', '91035', '91036', \n",
      "1000 input query terms found no hit:\t['92027', '92028', '92029', '92030', '92031', '92032', '92033', '92034', '92035', '92036', '92037', \n",
      "1000 input query terms found no hit:\t['93027', '93028', '93029', '93030', '93031', '93032', '93033', '93034', '93035', '93036', '93037', \n",
      "1000 input query terms found no hit:\t['94027', '94028', '94029', '94030', '94031', '94032', '94033', '94034', '94035', '94036', '94037', \n",
      "1000 input query terms found no hit:\t['95027', '95028', '95029', '95030', '95031', '95032', '95033', '95034', '95035', '95036', '95037', \n",
      "1000 input query terms found no hit:\t['96027', '96028', '96029', '96030', '96031', '96032', '96033', '96034', '96035', '96036', '96037', \n",
      "1000 input query terms found no hit:\t['97027', '97028', '97029', '97030', '97031', '97032', '97033', '97034', '97035', '97036', '97037', \n",
      "1000 input query terms found no hit:\t['98027', '98028', '98029', '98030', '98031', '98032', '98033', '98034', '98035', '98036', '98037', \n",
      "1000 input query terms found no hit:\t['99027', '99028', '99029', '99030', '99031', '99032', '99033', '99034', '99035', '99036', '99037', \n",
      "1000 input query terms found no hit:\t['100027', '100028', '100029', '100030', '100031', '100032', '100033', '100034', '100035', '100036',\n",
      "1000 input query terms found no hit:\t['101027', '101028', '101029', '101030', '101031', '101032', '101033', '101034', '101035', '101036',\n",
      "1000 input query terms found no hit:\t['102027', '102028', '102029', '102030', '102031', '102032', '102033', '102034', '102035', '102036',\n",
      "1000 input query terms found no hit:\t['103027', '103028', '103029', '103030', '103031', '103032', '103033', '103034', '103035', '103036',\n",
      "1000 input query terms found no hit:\t['104027', '104028', '104029', '104030', '104031', '104032', '104033', '104034', '104035', '104036',\n",
      "1000 input query terms found no hit:\t['105027', '105028', '105029', '105030', '105031', '105032', '105033', '105034', '105035', '105036',\n",
      "1000 input query terms found no hit:\t['106027', '106028', '106029', '106030', '106031', '106032', '106033', '106034', '106035', '106036',\n",
      "1000 input query terms found no hit:\t['107028', '107029', '107030', '107031', '107032', '107033', '107034', '107035', '107036', '107037',\n",
      "1000 input query terms found no hit:\t['108028', '108029', '108030', '108031', '108032', '108033', '108034', '108035', '108036', '108037',\n",
      "1000 input query terms found no hit:\t['109028', '109029', '109030', '109031', '109032', '109033', '109034', '109035', '109036', '109037',\n",
      "1000 input query terms found no hit:\t['110028', '110029', '110030', '110031', '110032', '110033', '110034', '110035', '110036', '110037',\n",
      "1000 input query terms found no hit:\t['111029', '111030', '111031', '111032', '111033', '111034', '111035', '111036', '111037', '111038',\n",
      "1000 input query terms found no hit:\t['112029', '112030', '112031', '112032', '112033', '112034', '112035', '112036', '112037', '112038',\n",
      "1000 input query terms found no hit:\t['113029', '113030', '113031', '113032', '113033', '113034', '113035', '113036', '113037', '113038',\n",
      "1000 input query terms found no hit:\t['114031', '114032', '114033', '114034', '114035', '114036', '114037', '114038', '114039', '114040',\n",
      "1000 input query terms found no hit:\t['115031', '115032', '115033', '115034', '115035', '115036', '115037', '115038', '115039', '115040',\n",
      "1000 input query terms found no hit:\t['116031', '116032', '116033', '116034', '116035', '116036', '116037', '116038', '116039', '116040',\n",
      "1000 input query terms found no hit:\t['117031', '117032', '117033', '117034', '117035', '117036', '117037', '117038', '117039', '117040',\n",
      "1000 input query terms found no hit:\t['118031', '118032', '118033', '118034', '118035', '118036', '118037', '118038', '118039', '118040',\n",
      "1000 input query terms found no hit:\t['119032', '119033', '119034', '119035', '119036', '119037', '119038', '119039', '119040', '119041',\n",
      "1000 input query terms found no hit:\t['120032', '120033', '120034', '120035', '120036', '120037', '120038', '120039', '120040', '120041',\n",
      "1000 input query terms found no hit:\t['121032', '121033', '121034', '121035', '121036', '121037', '121038', '121039', '121040', '121041',\n",
      "1000 input query terms found no hit:\t['122033', '122034', '122035', '122036', '122037', '122038', '122039', '122040', '122041', '122042',\n",
      "1000 input query terms found no hit:\t['123033', '123034', '123035', '123036', '123037', '123038', '123039', '123040', '123041', '123042',\n",
      "1000 input query terms found no hit:\t['124034', '124035', '124036', '124037', '124038', '124039', '124040', '124041', '124042', '124043',\n",
      "1000 input query terms found no hit:\t['125036', '125037', '125038', '125039', '125040', '125041', '125042', '125043', '125044', '125045',\n",
      "1000 input query terms found no hit:\t['126037', '126038', '126039', '126040', '126041', '126042', '126043', '126044', '126045', '126046',\n",
      "1000 input query terms found no hit:\t['127037', '127038', '127039', '127040', '127041', '127042', '127043', '127044', '127045', '127046',\n",
      "1000 input query terms found no hit:\t['128037', '128038', '128039', '128040', '128041', '128042', '128043', '128044', '128045', '128046',\n",
      "1000 input query terms found no hit:\t['129037', '129038', '129039', '129040', '129041', '129042', '129043', '129044', '129045', '129046',\n",
      "1000 input query terms found no hit:\t['130037', '130038', '130039', '130040', '130041', '130042', '130043', '130044', '130045', '130046',\n",
      "1000 input query terms found no hit:\t['131038', '131039', '131040', '131041', '131042', '131043', '131044', '131045', '131046', '131047',\n",
      "1000 input query terms found no hit:\t['132038', '132039', '132040', '132041', '132042', '132043', '132044', '132045', '132046', '132047',\n",
      "1000 input query terms found no hit:\t['133038', '133039', '133040', '133041', '133042', '133043', '133044', '133045', '133046', '133047',\n",
      "1000 input query terms found no hit:\t['134040', '134041', '134042', '134043', '134044', '134045', '134046', '134047', '134048', '134049',\n",
      "1000 input query terms found no hit:\t['135040', '135041', '135042', '135043', '135044', '135045', '135046', '135047', '135048', '135049',\n",
      "1000 input query terms found no hit:\t['136040', '136041', '136042', '136043', '136044', '136045', '136046', '136047', '136048', '136049',\n",
      "1000 input query terms found no hit:\t['137040', '137041', '137042', '137043', '137044', '137045', '137046', '137047', '137048', '137049',\n",
      "1000 input query terms found no hit:\t['138040', '138041', '138042', '138043', '138044', '138045', '138046', '138047', '138048', '138049',\n",
      "1000 input query terms found no hit:\t['139040', '139041', '139042', '139043', '139044', '139045', '139046', '139047', '139048', '139049',\n",
      "1000 input query terms found no hit:\t['140040', '140041', '140042', '140043', '140044', '140045', '140046', '140047', '140048', '140049',\n",
      "1000 input query terms found no hit:\t['141041', '141042', '141043', '141044', '141045', '141046', '141047', '141048', '141049', '141050',\n",
      "1000 input query terms found no hit:\t['142042', '142043', '142044', '142045', '142046', '142047', '142048', '142049', '142050', '142051',\n",
      "1000 input query terms found no hit:\t['143042', '143043', '143044', '143045', '143046', '143047', '143048', '143049', '143050', '143051',\n",
      "1000 input query terms found no hit:\t['144043', '144044', '144045', '144046', '144047', '144048', '144049', '144050', '144051', '144052',\n",
      "1000 input query terms found no hit:\t['145043', '145044', '145045', '145046', '145047', '145048', '145049', '145050', '145051', '145052',\n",
      "1000 input query terms found no hit:\t['146043', '146044', '146045', '146046', '146047', '146048', '146049', '146050', '146051', '146052',\n",
      "1000 input query terms found no hit:\t['147044', '147045', '147046', '147047', '147048', '147049', '147050', '147051', '147052', '147053',\n",
      "1000 input query terms found no hit:\t['148044', '148045', '148046', '148047', '148048', '148049', '148050', '148051', '148052', '148053',\n",
      "1000 input query terms found no hit:\t['149046', '149047', '149048', '149049', '149050', '149051', '149052', '149053', '149054', '149055',\n",
      "1000 input query terms found no hit:\t['150046', '150047', '150048', '150049', '150050', '150051', '150052', '150053', '150054', '150055',\n",
      "1000 input query terms found no hit:\t['151046', '151047', '151048', '151049', '151050', '151051', '151052', '151053', '151054', '151055',\n",
      "1000 input query terms found no hit:\t['152047', '152048', '152049', '152050', '152051', '152052', '152053', '152054', '152055', '152056',\n",
      "1000 input query terms found no hit:\t['153048', '153049', '153050', '153051', '153052', '153053', '153054', '153055', '153056', '153057',\n",
      "1000 input query terms found no hit:\t['154048', '154049', '154050', '154051', '154052', '154053', '154054', '154055', '154056', '154057',\n",
      "1000 input query terms found no hit:\t['155048', '155049', '155050', '155051', '155052', '155053', '155054', '155055', '155056', '155057',\n",
      "1000 input query terms found no hit:\t['156048', '156049', '156050', '156051', '156052', '156053', '156054', '156055', '156056', '156057',\n",
      "1000 input query terms found no hit:\t['157048', '157049', '157050', '157051', '157052', '157053', '157054', '157055', '157056', '157057',\n",
      "1000 input query terms found no hit:\t['158048', '158049', '158050', '158051', '158052', '158053', '158054', '158055', '158056', '158057',\n",
      "1000 input query terms found no hit:\t['159049', '159050', '159051', '159052', '159053', '159054', '159055', '159056', '159057', '159058',\n",
      "1000 input query terms found no hit:\t['160050', '160051', '160052', '160053', '160054', '160055', '160056', '160057', '160058', '160059',\n",
      "1000 input query terms found no hit:\t['161050', '161051', '161052', '161053', '161054', '161055', '161056', '161057', '161058', '161059',\n",
      "1000 input query terms found no hit:\t['162050', '162051', '162052', '162053', '162054', '162055', '162056', '162057', '162058', '162059',\n",
      "1000 input query terms found no hit:\t['163050', '163051', '163052', '163053', '163054', '163055', '163056', '163057', '163058', '163059',\n",
      "1000 input query terms found no hit:\t['164050', '164051', '164052', '164053', '164054', '164055', '164056', '164057', '164058', '164059',\n",
      "1000 input query terms found no hit:\t['165050', '165051', '165052', '165053', '165054', '165055', '165056', '165057', '165058', '165059',\n",
      "1000 input query terms found no hit:\t['166052', '166053', '166054', '166055', '166056', '166057', '166058', '166059', '166060', '166061',\n",
      "1000 input query terms found no hit:\t['167052', '167053', '167054', '167055', '167056', '167057', '167058', '167059', '167060', '167061',\n",
      "1000 input query terms found no hit:\t['168053', '168054', '168055', '168056', '168057', '168058', '168059', '168060', '168061', '168062',\n",
      "1000 input query terms found no hit:\t['169054', '169055', '169056', '169057', '169058', '169059', '169060', '169061', '169062', '169063',\n",
      "1000 input query terms found no hit:\t['170054', '170055', '170056', '170057', '170058', '170059', '170060', '170061', '170062', '170063',\n",
      "1000 input query terms found no hit:\t['171054', '171055', '171056', '171057', '171058', '171059', '171060', '171061', '171062', '171063',\n",
      "1000 input query terms found no hit:\t['172055', '172056', '172057', '172058', '172059', '172060', '172061', '172062', '172063', '172064',\n",
      "1000 input query terms found no hit:\t['173055', '173056', '173057', '173058', '173059', '173060', '173061', '173062', '173063', '173064',\n",
      "1000 input query terms found no hit:\t['174055', '174056', '174057', '174058', '174059', '174060', '174061', '174062', '174063', '174064',\n",
      "1000 input query terms found no hit:\t['175056', '175057', '175058', '175059', '175060', '175061', '175062', '175063', '175064', '175065',\n",
      "1000 input query terms found no hit:\t['176056', '176057', '176058', '176059', '176060', '176061', '176062', '176063', '176064', '176065',\n",
      "1000 input query terms found no hit:\t['177056', '177057', '177058', '177059', '177060', '177061', '177062', '177063', '177064', '177065',\n",
      "1000 input query terms found no hit:\t['178056', '178057', '178058', '178059', '178060', '178061', '178062', '178063', '178064', '178065',\n",
      "1000 input query terms found no hit:\t['179056', '179057', '179058', '179059', '179060', '179061', '179062', '179063', '179064', '179065',\n",
      "1000 input query terms found no hit:\t['180056', '180057', '180058', '180059', '180060', '180061', '180062', '180063', '180064', '180065',\n",
      "1000 input query terms found no hit:\t['181056', '181057', '181058', '181059', '181060', '181061', '181062', '181063', '181064', '181065',\n",
      "1000 input query terms found no hit:\t['182057', '182058', '182059', '182060', '182061', '182062', '182063', '182064', '182065', '182066',\n",
      "1000 input query terms found no hit:\t['183057', '183058', '183059', '183060', '183061', '183062', '183063', '183064', '183065', '183066',\n",
      "1000 input query terms found no hit:\t['184057', '184058', '184059', '184060', '184061', '184062', '184063', '184064', '184065', '184066',\n",
      "1000 input query terms found no hit:\t['185057', '185058', '185059', '185060', '185061', '185062', '185063', '185064', '185065', '185066',\n",
      "1000 input query terms found no hit:\t['186057', '186058', '186059', '186060', '186061', '186062', '186063', '186064', '186065', '186066',\n",
      "1000 input query terms found no hit:\t['187057', '187058', '187059', '187060', '187061', '187062', '187063', '187064', '187065', '187066',\n",
      "1000 input query terms found no hit:\t['188058', '188059', '188060', '188061', '188062', '188063', '188064', '188065', '188066', '188067',\n",
      "1000 input query terms found no hit:\t['189058', '189059', '189060', '189061', '189062', '189063', '189064', '189065', '189066', '189067',\n",
      "1000 input query terms found no hit:\t['190058', '190059', '190060', '190061', '190062', '190063', '190064', '190065', '190066', '190067',\n",
      "1000 input query terms found no hit:\t['191060', '191061', '191062', '191063', '191064', '191065', '191066', '191067', '191068', '191069',\n",
      "1000 input query terms found no hit:\t['192060', '192061', '192062', '192063', '192064', '192065', '192066', '192067', '192068', '192069',\n",
      "1000 input query terms found no hit:\t['193060', '193061', '193062', '193063', '193064', '193065', '193066', '193067', '193068', '193069',\n",
      "1000 input query terms found no hit:\t['194060', '194061', '194062', '194063', '194064', '194065', '194066', '194067', '194068', '194069',\n",
      "1000 input query terms found no hit:\t['195061', '195062', '195063', '195064', '195065', '195066', '195067', '195068', '195069', '195070',\n",
      "1000 input query terms found no hit:\t['196061', '196062', '196063', '196064', '196065', '196066', '196067', '196068', '196069', '196070',\n",
      "1000 input query terms found no hit:\t['197062', '197063', '197064', '197065', '197066', '197067', '197068', '197069', '197070', '197071',\n",
      "1000 input query terms found no hit:\t['198063', '198064', '198065', '198066', '198067', '198068', '198069', '198070', '198071', '198072',\n",
      "1000 input query terms found no hit:\t['199063', '199064', '199065', '199066', '199067', '199068', '199069', '199070', '199071', '199072',\n",
      "1000 input query terms found no hit:\t['200063', '200064', '200065', '200066', '200067', '200068', '200069', '200070', '200071', '200072',\n",
      "1000 input query terms found no hit:\t['201064', '201065', '201066', '201067', '201068', '201069', '201070', '201071', '201072', '201073',\n",
      "1000 input query terms found no hit:\t['202064', '202065', '202066', '202067', '202068', '202069', '202070', '202071', '202072', '202073',\n",
      "1000 input query terms found no hit:\t['203065', '203066', '203067', '203068', '203069', '203070', '203071', '203072', '203073', '203074',\n",
      "1000 input query terms found no hit:\t['204065', '204066', '204067', '204068', '204069', '204070', '204071', '204072', '204073', '204074',\n",
      "1000 input query terms found no hit:\t['205066', '205067', '205068', '205069', '205070', '205071', '205072', '205073', '205074', '205075',\n",
      "1000 input query terms found no hit:\t['206066', '206067', '206068', '206069', '206070', '206071', '206072', '206073', '206074', '206075',\n",
      "1000 input query terms found no hit:\t['207066', '207067', '207068', '207069', '207070', '207071', '207072', '207073', '207074', '207075',\n",
      "1000 input query terms found no hit:\t['208066', '208067', '208068', '208069', '208070', '208071', '208072', '208073', '208074', '208075',\n",
      "1000 input query terms found no hit:\t['209066', '209067', '209068', '209069', '209070', '209071', '209072', '209073', '209074', '209075',\n",
      "1000 input query terms found no hit:\t['210066', '210067', '210068', '210069', '210070', '210071', '210072', '210073', '210074', '210075',\n",
      "1000 input query terms found no hit:\t['211066', '211067', '211068', '211069', '211070', '211071', '211072', '211073', '211074', '211075',\n",
      "1000 input query terms found no hit:\t['212067', '212068', '212069', '212070', '212071', '212072', '212073', '212074', '212075', '212076',\n",
      "1000 input query terms found no hit:\t['213068', '213069', '213070', '213071', '213072', '213073', '213074', '213075', '213076', '213077',\n",
      "1000 input query terms found no hit:\t['214068', '214069', '214070', '214071', '214072', '214073', '214074', '214075', '214076', '214077',\n",
      "1000 input query terms found no hit:\t['215068', '215069', '215070', '215071', '215072', '215073', '215074', '215075', '215076', '215077',\n",
      "1000 input query terms found no hit:\t['216068', '216069', '216070', '216071', '216072', '216073', '216074', '216075', '216076', '216077',\n",
      "1000 input query terms found no hit:\t['217068', '217069', '217070', '217071', '217072', '217073', '217074', '217075', '217076', '217077',\n",
      "1000 input query terms found no hit:\t['218068', '218069', '218070', '218071', '218072', '218073', '218074', '218075', '218076', '218077',\n",
      "1000 input query terms found no hit:\t['219069', '219070', '219071', '219072', '219073', '219074', '219075', '219076', '219077', '219078',\n",
      "1000 input query terms found no hit:\t['220070', '220071', '220072', '220073', '220074', '220075', '220076', '220077', '220078', '220079',\n",
      "1000 input query terms found no hit:\t['221071', '221072', '221073', '221074', '221075', '221076', '221077', '221078', '221079', '221080',\n",
      "1000 input query terms found no hit:\t['222071', '222072', '222073', '222074', '222075', '222076', '222077', '222078', '222079', '222080',\n",
      "1000 input query terms found no hit:\t['223071', '223072', '223073', '223074', '223075', '223076', '223077', '223078', '223079', '223080',\n",
      "1000 input query terms found no hit:\t['224071', '224072', '224073', '224074', '224075', '224076', '224077', '224078', '224079', '224080',\n",
      "1000 input query terms found no hit:\t['225071', '225072', '225073', '225074', '225075', '225076', '225077', '225078', '225079', '225080',\n",
      "1000 input query terms found no hit:\t['226071', '226072', '226073', '226074', '226075', '226076', '226077', '226078', '226079', '226080',\n",
      "1000 input query terms found no hit:\t['227071', '227072', '227073', '227074', '227075', '227076', '227077', '227078', '227079', '227080',\n",
      "1000 input query terms found no hit:\t['228071', '228072', '228073', '228074', '228075', '228076', '228077', '228078', '228079', '228080',\n",
      "1000 input query terms found no hit:\t['229071', '229072', '229073', '229074', '229075', '229076', '229077', '229078', '229079', '229080',\n",
      "1000 input query terms found no hit:\t['230072', '230073', '230074', '230075', '230076', '230077', '230078', '230079', '230080', '230081',\n",
      "1000 input query terms found no hit:\t['231073', '231074', '231075', '231076', '231077', '231078', '231079', '231080', '231081', '231082',\n",
      "1000 input query terms found no hit:\t['232074', '232075', '232076', '232077', '232078', '232079', '232080', '232081', '232082', '232083',\n",
      "1000 input query terms found no hit:\t['233074', '233075', '233076', '233077', '233078', '233079', '233080', '233081', '233082', '233083',\n",
      "1000 input query terms found no hit:\t['234075', '234076', '234077', '234078', '234079', '234080', '234081', '234082', '234083', '234084',\n",
      "1000 input query terms found no hit:\t['235075', '235076', '235077', '235078', '235079', '235080', '235081', '235082', '235083', '235084',\n",
      "1000 input query terms found no hit:\t['236076', '236077', '236078', '236079', '236080', '236081', '236082', '236083', '236084', '236085',\n",
      "1000 input query terms found no hit:\t['237076', '237077', '237078', '237079', '237080', '237081', '237082', '237083', '237084', '237085',\n",
      "1000 input query terms found no hit:\t['238076', '238077', '238078', '238079', '238080', '238081', '238082', '238083', '238084', '238085',\n",
      "1000 input query terms found no hit:\t['239076', '239077', '239078', '239079', '239080', '239081', '239082', '239083', '239084', '239085',\n",
      "1000 input query terms found no hit:\t['240076', '240077', '240078', '240079', '240080', '240081', '240082', '240083', '240084', '240085',\n",
      "1000 input query terms found no hit:\t['241076', '241077', '241078', '241079', '241080', '241081', '241082', '241083', '241084', '241085',\n",
      "1000 input query terms found no hit:\t['242076', '242077', '242078', '242079', '242080', '242081', '242082', '242083', '242084', '242085',\n",
      "429 input query terms found no hit:\t['243076', '243077', '243078', '243079', '243080', '243081', '243082', '243083', '243084', '243085',\n"
     ]
    }
   ],
   "source": [
    "if NORMALIZE_GENE:\n",
    "    genetic_data = normalize_gene_symbols_in_index(genetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_merge_clinical_genetic_data(clinical_df, genetic_df):\n",
    "    \"\"\"\n",
    "    Merge the clinical features and gene expression features from two dataframes into one dataframe\n",
    "    \"\"\"\n",
    "    if 'ID' in genetic_df.columns:\n",
    "        genetic_df = genetic_df.rename(columns={'ID': 'Gene'})\n",
    "    if 'Gene' in genetic_df.columns:\n",
    "        genetic_df = genetic_df.set_index('Gene')\n",
    "    merged_data = pd.concat([clinical_df, genetic_df], axis=0).T.dropna()\n",
    "    return merged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.572778564Z",
     "start_time": "2024-01-10T21:40:20.565101065Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data = geo_merge_clinical_genetic_data(selected_clinical_data, genetic_data)\n",
    "# The preprocessing runs through, which means is_available should be True\n",
    "is_available = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.595385887Z",
     "start_time": "2024-01-10T21:40:20.574630883Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged dataset contains 61 samples.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The merged dataset contains {len(merged_data)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.595934649Z",
     "start_time": "2024-01-10T21:40:20.580408525Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the feature 'Adrenocortical Cancer', the least common label is '1.0' with 29 occurrences. This represents 47.54% of the dataset.\n",
      "The distribution of the feature 'Adrenocortical Cancer' in this dataset is fine.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_trait_biased, merged_data = judge_and_remove_biased_features(merged_data, TRAIT, trait_type=trait_type)\n",
    "is_trait_biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.596022151Z",
     "start_time": "2024-01-10T21:40:20.588443384Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if is_available:\n",
    "    save_cohort_info(cohort, JSON_PATH, is_available, is_trait_biased, merged_data, note='')\n",
    "else:\n",
    "    save_cohort_info(cohort, JSON_PATH, is_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.681345468Z",
     "start_time": "2024-01-10T21:40:20.591286171Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_data.head()\n",
    "if not is_trait_biased:\n",
    "    merged_data.to_csv(os.path.join(OUTPUT_DIR, cohort + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T03:58:22.271683755Z",
     "start_time": "2023-12-31T03:58:22.246557674Z"
    },
    "id": "-MTPhRGxJV7I"
   },
   "source": [
    "### 3. Do regression & Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_to_dataframe(json_file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a JSON file and converts it into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "    json_file (str): The path to the JSON file containing the data.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A pandas DataFrame with the JSON data.\n",
    "    \"\"\"\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return pd.DataFrame.from_dict(data, orient='index').reset_index().rename(columns={'index': 'cohort_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_rank_cohorts(json_file: str, condition: Union[str, None] = None) -> Tuple[\n",
    "    Union[str, None], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Reads a JSON file, filters cohorts based on usability and an optional condition, then ranks them by sample size.\n",
    "\n",
    "    Args:\n",
    "    json_file (str): The path to the JSON file containing the data.\n",
    "    condition (str, optional): An additional condition for filtering. If None, only 'is_usable' is considered.\n",
    "\n",
    "    Returns:\n",
    "    Tuple: A tuple containing the best cohort ID (str or None if no suitable cohort is found) and\n",
    "           the filtered and ranked DataFrame.\n",
    "    \"\"\"\n",
    "    # Read the JSON file into a DataFrame\n",
    "    df = read_json_to_dataframe(json_file)\n",
    "\n",
    "    if condition:\n",
    "        filtered_df = df[(df['is_usable'] == True) & (df[condition] == True)]\n",
    "    else:\n",
    "        filtered_df = df[df['is_usable'] == True]\n",
    "\n",
    "    ranked_df = filtered_df.sort_values(by='sample_size', ascending=False)\n",
    "    best_cohort_id = ranked_df.iloc[0]['cohort_id'] if not ranked_df.empty else None\n",
    "\n",
    "    return best_cohort_id, ranked_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.694597045Z",
     "start_time": "2024-01-10T21:40:20.642161512Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>is_usable</th>\n",
       "      <th>is_available</th>\n",
       "      <th>is_biased</th>\n",
       "      <th>has_age</th>\n",
       "      <th>has_gender</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSE21660</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>61</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cohort_id  is_usable  is_available  is_biased  has_age  has_gender  \\\n",
       "1  GSE21660       True          True      False    False       False   \n",
       "\n",
       "   sample_size note  \n",
       "1           61       "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the information of usable cohorts\n",
    "best_cohort, ranked_df = filter_and_rank_cohorts(JSON_PATH)\n",
    "ranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:20.907514912Z",
     "start_time": "2024-01-10T21:40:20.907178250Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If both age and gender have available cohorts, select 'age' as the condition.\n",
    "condition = 'Age'\n",
    "filter_column = 'has_' + condition.lower()\n",
    "\n",
    "condition_best_cohort, condition_ranked_df = filter_and_rank_cohorts(JSON_PATH, filter_column)\n",
    "condition_best_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:21.120075804Z",
     "start_time": "2024-01-10T21:40:21.109376558Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>is_usable</th>\n",
       "      <th>is_available</th>\n",
       "      <th>is_biased</th>\n",
       "      <th>has_age</th>\n",
       "      <th>has_gender</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [cohort_id, is_usable, is_available, is_biased, has_age, has_gender, sample_size, note]\n",
       "Index: []"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_ranked_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:27.295070023Z",
     "start_time": "2024-01-10T21:40:21.338515691Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [136]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTPUT_DIR, \u001b[43mcondition_best_cohort\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m))\n\u001b[1;32m      2\u001b[0m merged_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "merged_data = pd.read_csv(os.path.join(OUTPUT_DIR, condition_best_cohort + '.csv'))\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:27.358779256Z",
     "start_time": "2024-01-10T21:40:27.271337819Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove the other condition to prevent interference.\n",
    "merged_data = merged_data.drop(columns=['Gender'], errors='ignore').astype('float')\n",
    "\n",
    "X = merged_data.drop(columns=[TRAIT, condition]).values\n",
    "Y = merged_data[TRAIT].values\n",
    "Z = merged_data[condition].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Select the appropriate regression model depending on whether the dataset shows batch effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:27.546590575Z",
     "start_time": "2024-01-10T21:40:27.298495045Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "has_batch_effect = detect_batch_effect(X)\n",
    "has_batch_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:27.546733889Z",
     "start_time": "2024-01-10T21:40:27.535249532Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select appropriate models based on whether the dataset has batch effect.\n",
    "# We experiment on two models for each branch. We will decide which one to choose later.\n",
    "\n",
    "if has_batch_effect:\n",
    "    model_constructor1 = VariableSelection\n",
    "    model_params1 = {'modified': True, 'lamda': 3e-4}\n",
    "    model_constructor2 = VariableSelection\n",
    "    model_params2 = {'modified': False}\n",
    "else:\n",
    "    model_constructor1 = Lasso\n",
    "    model_params1 = {'alpha': 1.0, 'random_state': 42}\n",
    "    model_constructor2 = VariableSelection\n",
    "    model_params2 = {'modified': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:30.570471636Z",
     "start_time": "2024-01-10T21:40:27.546295159Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_type = 'binary'  # Remember to set this properly, either 'binary' or 'continuous'\n",
    "cv_mean1, cv_std1 = cross_validation(X, Y, Z, model_constructor1, model_params1, target_type=trait_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:47.575878022Z",
     "start_time": "2024-01-10T21:40:30.570907992Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_mean2, cv_std2 = cross_validation(X, Y, Z, model_constructor2, model_params2, target_type=trait_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:51.663737008Z",
     "start_time": "2024-01-10T21:40:47.576021186Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_X, _ = normalize_data(X)\n",
    "normalized_Z, _ = normalize_data(Z)\n",
    "\n",
    "# Train regression model on the whole dataset to identify significant genes\n",
    "model1 = ResidualizationRegressor(model_constructor1, model_params1)\n",
    "model1.fit(normalized_X, Y, normalized_Z)\n",
    "\n",
    "model2 = ResidualizationRegressor(model_constructor2, model_params2)\n",
    "model2.fit(normalized_X, Y, normalized_Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T04:50:59.072075075Z",
     "start_time": "2023-10-14T04:50:38.739499998Z"
    },
    "id": "EjJrxbvb4nlj"
   },
   "source": [
    "### 4. Discussion and report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:51.673565176Z",
     "start_time": "2024-01-10T21:40:51.665291317Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_cols = merged_data.columns.tolist()\n",
    "feature_cols.remove(TRAIT)\n",
    "\n",
    "threshold = 0.05\n",
    "interpret_result(model1, feature_cols, TRAIT, condition, threshold=threshold, save_output=True,\n",
    "                 output_dir=OUTPUT_DIR, model_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T21:40:51.730825913Z",
     "start_time": "2024-01-10T21:40:51.675049728Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interpret_result(model2, feature_cols, TRAIT, condition, threshold=threshold, save_output=True,\n",
    "                 output_dir=OUTPUT_DIR, model_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
